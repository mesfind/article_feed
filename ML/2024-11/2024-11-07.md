# Bringing music back to our children: Greater exposure to music can benefit language learning in infants

## 将音乐带回我们的孩子: 更多地接触音乐可以有益于婴儿的语言学习

Link: https://www.science.org/doi/abs/10.1126/science.ads7364?af=R

Science, Volume 386, Issue 6722, Page 632-632, November 2024. <br />


---
# Initiation of pericentric heterochromatin: From non-conserved sequences to conserved machinery

## 周着地异染色质的起始: 从非保守序列到保守机制

Link: https://www.sciencedirect.com/science/article/pii/S2095927324006443?dgcid=rss_sd_all

<p>Publication date: 15 November 2024</p><p><b>Source:</b> Science Bulletin, Volume 69, Issue 21</p><p>Author(s): Jun Chen, Jiyu Chen, Haiyan Lin, Guohong Li</p>


---
# Neural network enabled molecular dynamics study of ${\mathrm{HfO}}_{2}$ phase transitions

## 基于神经网络的 ${\ mathrm{HfO }}_{ 2}$ 相变分子动力学研究

Link: http://link.aps.org/doi/10.1103/PhysRevB.110.174105

Author(s): Sebastian Bichelmaier, Jesús Carrete, and Georg K. H. Madsen<br /><p>The advances of machine-learned force fields have opened up molecular dynamics (MD) simulations for compounds for which <i>ab initio</i> MD is too resource intensive and phenomena for which classical force fields are insufficient. Here we describe a neural-network force field parametrized to reproduce the …</p><br />[Phys. Rev. B 110, 174105] Published Thu Nov 07, 2024


---
# Robust quantum dots charge autotuning using neural network uncertainty

## 使用神经网络不确定性的鲁棒量子点电荷自动调谐

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad88d5

This study presents a machine learning-based procedure to automate the charge tuning of semiconductor spin qubits with minimal human intervention, addressing one of the significant challenges in scaling up quantum dot technologies. This method exploits artificial neural networks to identify noisy transition lines in stability diagrams, guiding a robust exploration strategy leveraging neural network uncertainty estimations. Tested across three distinct offline experimental datasets representing different single-quantum-dot technologies, this approach achieves a tuning success rate of over 99% in optimal cases, where more than 10% of the success is directly attributable to uncertainty exploitation. The challenging constraints of small training sets containing high diagram-to-diagram variability allowed us to evaluate the capabilities and limits of the proposed procedure.


---
# Observation impact explanation in atmospheric state estimation using hierarchical message-passing graph neural networks *

## 使用分层消息传递图神经网络在大气状态估计中的观测影响解释 *

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad8981

The impact of meteorological observations on weather forecasting varies with the sensor type, location, time, and other environmental factors. Thus, the quantitative analysis of observation impacts is crucial for the effective and efficient development of weather forecasting systems. However, existing impact analysis methods are dependent on specific forecast systems, because system-specific adjoint models are used and the sensitivity of the observation to the forecast is measured. This study investigates the impact of observations on atmospheric state estimation in weather forecasting systems by developing a novel graph neural network (GNN) model specialized for analyzing the heterogeneous relations between observations and atmospheric states. The observation impact can then be assessed by applying explainable methods to the proposed GNN model, which is independent of forecasting systems. Further, we develop a novel application called ‘CloudNine,’ a system that provides impact analysis for individual observations with visualization. Our GNN model comprises hierarchical message-passing modules that separately analyze spatial correlations between observations at close locations and atmospheric states at close locations and then examine correlations between observations and atmospheric states. To consider the different factors influencing these correlations, we utilized geo-coordinates and types of observations in the attention mechanism of the modules with their feature vectors. We then applied gradient-based explainability methods to quantify the significance of the different observations in the estimation. Evaluated using data from 11 satellites and land-based observations, the results highlight the effectiveness of the proposed model and the visualization of observation impacts, enhancing the understanding and optimization of observational data in weather forecasting.


---
# Federated learning with tensor networks: a quantum AI framework for healthcare

## 基于张量网络的联邦学习: 用于医疗保健的量子AI框架

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad8c11

The healthcare industry frequently handles sensitive and proprietary data, and due to strict privacy regulations, it is often reluctant to share it directly. In today’s context, Federated Learning (FL) stands out as a crucial remedy, facilitating the rapid advancement of distributed machine learning while effectively managing critical concerns regarding data privacy and governance. The fusion of federated learning and quantum computing represents a groundbreaking interdisciplinary approach with immense potential to revolutionize various industries, from healthcare to finance. In this work, we propose a federated learning framework based on quantum tensor networks (QTNs) that takes advantage of the principles of many-body quantum physics. Currently, there are no known classical tensor networks (TNs) implemented in federated settings. Furthermore, we investigated the effectiveness and feasibility of the proposed framework by conducting a differential privacy analysis to ensure the security of sensitive data across healthcare institutions. Experiments on popular medical image datasets show that the federated quantum tensor network (FedQTNs) model achieved a mean receiver-operator characteristic area under the curve of 91%–98%, outperforming several state-of-the-art federated learning methods. Moreover, QTN models require fewer parameters in FL settings compared to traditional classical models, which often suffer from over-parameterization. This reduction in parameters not only improves the efficiency of the communication process but also significantly decreases data consumption during training. As a result, QTN models facilitate a more effective and resource-efficient approach to training in decentralized environments with limited communication bandwidth. The FedQTN models demonstrate a smaller performance drop even when using strong differential privacy settings, maintaining higher accuracy compared to classical models under similar privacy constraints. Experimental results demonstrate that the quantum federated global model, consisting of highly entangled TN structures, showed better generalization and robustness and achieved higher testing accuracy, surpassing the performance of locally trained clients under unbalanced data distributions among healthcare institutions.


---
# Automated, LLM enabled extraction of synthesis details for reticular materials from scientific literature

## 自动化，LLM支持从科学文献中提取网状材料的合成细节

Link: https://arxiv.org/abs/2411.03484

arXiv:2411.03484v1 Announce Type: new 
Abstract: Automated knowledge extraction from scientific literature can potentially accelerate materials discovery. We have investigated an approach for extracting synthesis protocols for reticular materials from scientific literature using large language models (LLMs). To that end, we introduce a Knowledge Extraction Pipeline (KEP) that automatizes LLM-assisted paragraph classification and information extraction. By applying prompt engineering with in-context learning (ICL) to a set of open-source LLMs, we demonstrate that LLMs can retrieve chemical information from PDF documents, without the need for fine-tuning or training and at a reduced risk of hallucination. By comparing the performance of five open-source families of LLMs in both paragraph classification and information extraction tasks, we observe excellent model performance even if only few example paragraphs are included in the ICL prompts. The results show the potential of the KEP approach for reducing human annotations and data curation efforts in automated scientific knowledge extraction.


---
# Estimation of spatial and time scales of collective behaviors of active matters through learning hydrodynamic equations from particle dynamics

## 通过从粒子动力学中学习流体动力学方程来估计活动物质集体行为的空间和时间尺度

Link: https://arxiv.org/abs/2411.03783

arXiv:2411.03783v1 Announce Type: new 
Abstract: We present a data-driven framework for learning hydrodynamic equations from particle-based simulations of active matter. Our method leverages coarse-graining in both space and time to bridge microscopic particle dynamics with macroscopic continuum models. By employing spectral representations and sparse regression, we efficiently estimate partial differential equations (PDEs) that capture collective behaviors such as flocking and phase separation. This approach, validated using hydrodynamic descriptions of the Vicsek model and Active Brownian particles, demonstrates the potential of data-driven strategies to uncover the universal features of collective dynamics in active matter systems.


---
# Unified Approach to Power-Efficiency Trade-Off of Generic Thermal Machines

## 通用热机能效权衡的统一方法

Link: https://arxiv.org/abs/2411.03849

arXiv:2411.03849v1 Announce Type: new 
Abstract: Due to the diverse functionalities of different thermal machines, their optimization relies on a case-by-case basis, lacking unified results. In this work, we propose a general approach to determine power-efficiency trade-off relation (PETOR) for any thermal machine. For cases where cycle (of duration $\tau$) irreversibility satisfies the typical $1/\tau$-scaling, we provide a unified PETOR which is applicable to heat engines, refrigerators, heat exchangers and heat pumps. It is shown that, some typical PETORs, such as those for low-dissipation Carnot cycles (including heat engine and refrigerator cycles) and the steady-state heat engines operating between finite-sized reservoirs are naturally recovered.


---
# Holographic deep thermalization

## 全息深度热化

Link: https://arxiv.org/abs/2411.03587

arXiv:2411.03587v1 Announce Type: cross 
Abstract: Random quantum states play a critical role in quantum information processing. While random quantum circuits typically provide pseudo-random states, deep thermalization introduces quantum measurement to generate genuinely random states. However, the requirement of large ancillae in conventional deep thermalization poses a challenge to scale up the system size. We introduce holographic deep thermalization to substantially reduce the required ancillae to a system-size independent constant. Our circuit design trades space with time, via adopting a sequential application of an scrambling-measure-reset process on a small number of ancillae. Via tuning the ancilla size and number of time steps, holographic deep thermalization allows a continuous trade-off between the total quantum circuit size and the ancilla size. In the case of finite-size systems, we further enhance the performance of holographic deep thermalization via generative quantum machine learning, which leads to constant-factor advantages in the convergence towards Haar random. The theoretical predictions are verified with IBM Quantum noisy simulations.


---
# Neural Network Ground State from the Neural Tangent Kernel Perspective: The Sign Bias

## 从神经切线核角度看神经网络基态: 符号偏差

Link: https://arxiv.org/abs/2411.03980

arXiv:2411.03980v1 Announce Type: cross 
Abstract: Neural networks has recently attracted much interest as useful representations of quantum many body ground states, which might help address the infamous sign problem. Most attention was directed at their representability properties, while possible limitations on finding the desired optimal state have not been suitably explored. By leveraging well-established results applicable in the context of infinite width, specifically regarding the renowned neural tangent kernel and conjugate kernel, a comprehensive analysis of the convergence and initialization characteristics of the method is conducted. We reveal the dependence of these characteristics on the interplay among these kernels, the Hamiltonian, and the basis used for its representation. We introduce and motivate novel performance metrics and explore the condition for their optimization. By leveraging these findings, we elucidate a substantial dependence of the effectiveness of this approach on the selected basis, demonstrating that so-called stoquastic Hamiltonians are more amenable to solution through neural networks than those suffering from a sign problem.


---
# Ab-initio variational wave functions for the time-dependent many-electron Schr\"odinger equation

## 时变多电子Schr \ “odinger方程的Ab-initio变分波函数

Link: https://arxiv.org/abs/2403.07447

arXiv:2403.07447v3 Announce Type: replace 
Abstract: Understanding the real-time evolution of many-electron quantum systems is essential for studying dynamical properties in condensed matter, quantum chemistry, and complex materials, yet it poses a significant theoretical and computational challenge. Our work introduces a variational approach for fermionic time-dependent wave functions, surpassing mean-field approximations by accurately capturing many-body correlations. Therefore, we employ time-dependent Jastrow factors and backflow transformations, which are enhanced through neural networks parameterizations. To compute the optimal time-dependent parameters, we utilize the time-dependent variational Monte Carlo technique and a new method based on Taylor-root expansions of the propagator, enhancing the accuracy of our simulations. The approach is demonstrated in three distinct systems. In all cases, we show clear signatures of many-body correlations in the dynamics. The results showcase the ability of our variational approach to accurately capture the time evolution, providing insight into the quantum dynamics of interacting electronic systems, beyond the capabilities of mean-field.


---
# Machine Learning Enhanced Electrochemical Simulations for Dendrites Nucleation in Li Metal Battery

## Li金属电池枝晶成核的机器学习增强电化学模拟

Link: https://arxiv.org/abs/2406.14025

arXiv:2406.14025v4 Announce Type: replace 
Abstract: Uncontrollable dendrites growth during electrochemical cycles leads to low Coulombic efficiency and critical safety issues in Li metal batteries. Hence, a comprehensive understanding of the dendrite formation mechanism is essential for further enhancing the performance of Li metal batteries. Machine learning accelerated molecular dynamics (MD) simulations can provide atomic-scale resolution for various key processes at an ab-initio level accuracy. However, traditional MD simulation tools hardly capture Li electrochemical depositions, due to lack of an electrochemical constant potential (ConstP) condition. In this work, we propose a ConstP approach that combines a machine learning force field with the charge equilibration method to reveal the dynamic process of dendrites nucleation at Li metal anode surfaces. Our simulations show that inhomogeneous Li depositions, following Li aggregations in amorphous inorganic components of solid electrolyte interphases, can initiate dendrites nucleation, accompanied by dead Li cluster formation. Our study provides microscopic insights for Li dendrites formations in Li metal anodes. More importantly, we present an efficient and accurate simulation method for modeling realistic ConstP conditions, which holds considerable potential for broader applications in modeling complex electrochemical interfaces.


---
# A Robust and Efficient Multi-physics Numerical System for Intensive Blast Wave Propagation in Complex Environments

## 复杂环境中密集爆炸波传播的鲁棒高效多物理场数值系统

Link: https://arxiv.org/abs/2411.02407

arXiv:2411.02407v1 Announce Type: new 
Abstract: We establish a high-resolution, high-performance, and high-confidence compressible multiphysics system in a Cartesian grid with irregular boundary topologies to simulate intensive blast waves propagating in large-scale and extremely complex environments. The multiphysics system is modeled by a multi-component model solved using a generalized Godunov method and a classical material point method in a combination of Lagrangian particles and a rigid material model. An artificial neural network equation of state (EOS) is proposed based on experimental data to simulate the intensive explosion products and real gas under extreme pressure and temperature. To improve computational accuracy and efficiency, a deepMTBVD reconstruction scheme of our previous work is extended to the multiphysics system. With the aid of high-performance parallel computation, several large-scale blast wave applications, such as blast wave propagating in a local and entire urban city, are simulated in a reasonable time period, which can validate numerical schemes and lead to more practical engineering applications.


---
# SK-PINN: Accelerated physics-informed deep learning by smoothing kernel gradients

## Sk-pinn: 通过平滑核梯度加速物理通知深度学习

Link: https://arxiv.org/abs/2411.02411

arXiv:2411.02411v1 Announce Type: new 
Abstract: The automatic differentiation (AD) in the vanilla physics-informed neural networks (PINNs) is the computational bottleneck for the high-efficiency analysis. The concept of derivative discretization in smoothed particle hydrodynamics (SPH) can provide an accelerated training method for PINNs. In this paper, smoothing kernel physics-informed neural networks (SK-PINNs) are established, which solve differential equations using smoothing kernel discretization. It is a robust framework capable of solving problems in the computational mechanics of complex domains. When the number of collocation points gradually increases, the training speed of SK-PINNs significantly surpasses that of vanilla PINNs. In cases involving large collocation point sets or higher-order problems, SK-PINN training can be up to tens of times faster than vanilla PINN. Additionally, analysis using neural tangent kernel (NTK) theory shows that the convergence rates of SK-PINNs are consistent with those of vanilla PINNs. The superior performance of SK-PINNs is demonstrated through various examples, including regular and complex domains, as well as forward and inverse problems in fluid dynamics and solid mechanics.


---
# An Efficient Monte Carlo Simulation for Radiation Transport Based on Global Optimal Reference Field

## 基于全局最优参考场的高效蒙特卡罗辐射输运模拟

Link: https://arxiv.org/abs/2411.02415

arXiv:2411.02415v1 Announce Type: new 
Abstract: The reference field method, known as the difference formulation, is a key variance reduction technique for Monte Carlo simulations of thermal radiation transport problems. When the material temperature is relatively high and the spatial temperature gradient is moderate, this method demonstrates significant advantages in reducing variance compared to classical Monte Carlo methods. However, in problems with larger temperature gradients, this method has not only been found ineffective at reducing statistical noise, but in some cases, it even increases noise compared to classical Monte Carlo methods. The global optimal reference field method, a recently proposed variance reduction technique, effectively reduces the average energy weight of Monte Carlo particles, thereby decreasing variance. Its effectiveness has been validated both theoretically and numerically, demonstrating a significant reduction in statistical errors for problems with large temperature gradients. In our previous work, instead of computing the exact global optimal reference field, we developed an approximate, physically motivated method to find a relatively better reference field using a selection scheme. In this work, we reformulate the problem of determining the global optimal reference field as a linear programming problem and solve it exactly. To further enhance computational efficiency, we use the MindOpt solver, which leverages graph neural network methods. Numerical experiments demonstrate that the MindOpt solver not only solves linear programming problems accurately but also significantly outperforms the Simplex and interior-point methods in terms of computational efficiency. The global optimal reference field method combined with the MindOpt solver not only improves computational efficiency but also substantially reduces statistical errors.


---
# An Efficient Hierarchical Preconditioner-Learner Architecture for Reconstructing Multi-scale Basis Functions of High-dimensional Subsurface Fluid Flow

## 一种有效的分层预处理器-学习器体系结构，用于重建高维地下流体流的多尺度基函数

Link: https://arxiv.org/abs/2411.02431

arXiv:2411.02431v1 Announce Type: new 
Abstract: Modeling subsurface fluid flow in porous media is crucial for applications such as oil and gas exploration. However, the inherent heterogeneity and multi-scale characteristics of these systems pose significant challenges in accurately reconstructing fluid flow behaviors. To address this issue, we proposed Fourier Preconditioner-based Hierarchical Multiscale Net (FP-HMsNet), an efficient hierarchical preconditioner-learner architecture that combines Fourier Neural Operators (FNO) with multi-scale neural networks to reconstruct multi-scale basis functions of high-dimensional subsurface fluid flow. Using a dataset comprising 102,757 training samples, 34,252 validation samples, and 34,254 test samples, we ensured the reliability and generalization capability of the model. Experimental results showed that FP-HMsNet achieved an MSE of 0.0036, an MAE of 0.0375, and an R2 of 0.9716 on the testing set, significantly outperforming existing models and demonstrating exceptional accuracy and generalization ability. Additionally, robustness tests revealed that the model maintained stability under various levels of noise interference. Ablation studies confirmed the critical contribution of the preconditioner and multi-scale pathways to the model's performance. Compared to current models, FP-HMsNet not only achieved lower errors and higher accuracy but also demonstrated faster convergence and improved computational efficiency, establishing itself as the state-of-the-art (SOTA) approach. This model offers a novel method for efficient and accurate subsurface fluid flow modeling, with promising potential for more complex real-world applications.


---
# First observations of the seiche that shook the world

## 震撼世界的seiche的第一次观察

Link: https://arxiv.org/abs/2411.02469

arXiv:2411.02469v1 Announce Type: new 
Abstract: On September 16th, 2023, an anomalous 10.88 mHz seismic signal was observed globally, persisting for 9 days. One month later an identical signal appeared, lasting for another week. Several studies have theorized that these signals were produced by seiches which formed after two landslide generated mega-tsunamis in an East-Greenland fjord. This theory is supported by seismic inversions, and analytical and numerical modeling, but no direct observations have been made -- until now. Using data from the new Surface Water Ocean Topography mission, we present the first observations of this phenomenon. By ruling out other oceanographic processes, we validate the seiche theory of previous authors and independently estimate its initial amplitude at 7.9 m using Bayesian machine learning and seismic data. This study demonstrates the value of satellite altimetry for studying extreme events, while also highlighting the need for specialized methods to address the altimetric data's limitations, namely temporal sparsity. These data and approaches will help in understanding future unseen extremes driven by climate change.


---
# Computing critical exponents in 3D Ising model via pattern recognition/deep learning approach

## 通过模式识别/深度学习方法在3D Ising模型中计算关键指数

Link: https://arxiv.org/abs/2411.02604

arXiv:2411.02604v1 Announce Type: new 
Abstract: In this study, we computed three critical exponents ($\alpha, \beta, \gamma$) for the 3D Ising model with Metropolis Algorithm using Finite-Size Scaling Analysis on six cube length scales (L=20,30,40,60,80,90), and performed a supervised Deep Learning (DL) approach (3D Convolutional Neural Network or CNN) to train a neural network on specific conformations of spin states. We find one can effectively reduce the information in thermodynamic ensemble-averaged quantities vs. reduced temperature t (magnetization per spin $<m>(t)$, specific heat per spin $(t)$, magnetic susceptibility per spin $<\chi>(t)$) to \textit{six} latent classes. We also demonstrate our CNN on a subset of L=20 conformations and achieve a train/test accuracy of 0.92 and 0.6875, respectively. However, more work remains to be done to quantify the feasibility of computing critical exponents from the output class labels (binned $m, c, \chi$) from this approach and interpreting the results from DL models trained on systems in Condensed Matter Physics in general.


---
# Towards more efficient agricultural practices via transformer-based crop type classification

## 通过基于变压器的作物类型分类实现更有效的农业实践

Link: https://arxiv.org/abs/2411.02627

arXiv:2411.02627v1 Announce Type: new 
Abstract: Machine learning has great potential to increase crop production and resilience to climate change. Accurate maps of where crops are grown are a key input to a number of downstream policy and research applications. In this proposal, we present preliminary work showing that it is possible to accurately classify crops from time series derived from Sentinel 1 and 2 satellite imagery in Mexico using a pixel-based binary crop/non-crop time series transformer model. We also find preliminary evidence that meta-learning approaches supplemented with data from similar agro-ecological zones may improve model performance. Due to these promising results, we propose further development of this method with the goal of accurate multi-class crop classification in Jalisco, Mexico via meta-learning with a dataset comprising similar agro-ecological zones.


---
# Generalization vs. Hallucination

## 泛化与幻觉

Link: https://arxiv.org/abs/2411.02893

arXiv:2411.02893v1 Announce Type: new 
Abstract: With fast developments in computational power and algorithms, deep learning has made breakthroughs and been applied in many fields. However, generalization remains to be a critical challenge, and the limited generalization capability severely constrains its practical applications. Hallucination issue is another unresolved conundrum haunting deep learning and large models. By leveraging a physical model of imaging through scattering media, we studied the lack of generalization to system response functions in deep learning, identified its cause, and proposed a universal solution. The research also elucidates the creation process of a hallucination in image prediction and reveals its cause, and the common relationship between generalization and hallucination is discovered and clarified. Generally speaking, it enhances the interpretability of deep learning from a physics-based perspective, and builds a universal physical framework for deep learning in various fields. It may pave a way for direct interaction between deep learning and the real world, facilitating the transition of deep learning from a demo model to a practical tool in diverse applications.


---
# Adaptive-precision potentials for large-scale atomistic simulations

## 大规模原子模拟的自适应精度潜力

Link: https://arxiv.org/abs/2411.03002

arXiv:2411.03002v1 Announce Type: new 
Abstract: Large-scale atomistic simulations rely on interatomic potentials providing an efficient representation of atomic energies and forces. Modern machine-learning (ML) potentials provide the most precise representation compared to electronic structure calculations while traditional potentials provide a less precise, but computationally much faster representation and thus allow simulations of larger systems. We present a method to combine a traditional and a ML potential to a multi-resolution description, leading to an adaptive-precision potential with an optimum of performance and precision in large complex atomistic systems. The required precision is determined per atom by a local structure analysis and updated automatically during simulation. We use copper as demonstrator material with an embedded atom model as classical force field and an atomic cluster expansion (ACE) as ML potential, but in principle a broader class of potential combinations can be coupled by this method. The approach is developed for the molecular-dynamics simulator LAMMPS and includes a load-balancer to prevent problems due to the atom dependent force-calculation times, which makes it suitable for large-scale atomistic simulations. The developed adaptive-precision copper potential represents the ACE-forces and -energies with a precision of 10 meV/{\AA} and 0 meV for the precisely calculated atoms in a nanoindentation of 4 million atoms calculated for 100 ps and shows a speedup of 11.3 compared with a full ACE simulation.


---
# MA^2: A Self-Supervised and Motion Augmenting Autoencoder for Gait-Based Automatic Disease Detection

## MA ^ 2: 用于基于步态的自动疾病检测的自监督和运动增强自动编码器

Link: https://arxiv.org/abs/2411.03129

arXiv:2411.03129v1 Announce Type: new 
Abstract: Ground reaction force (GRF) is the force exerted by the ground on a body in contact with it. GRF-based automatic disease detection (ADD) has become an emerging medical diagnosis method, which aims to learn and identify disease patterns corresponding to different gait pressures based on deep learning methods. Although existing ADD methods can save doctors time in making diagnoses, training deep models still struggles with the cost caused by the labeling engineering for a large number of gait diagnostic data for subjects. On the other hand, the accuracy of the deep model under the unified benchmark GRF dataset and the generalization ability on scalable gait datasets need to be further improved. To address these issues, we propose MA2, a GRF-based self-supervised and motion augmenting auto-encoder, which models the ADD task as an encoder-decoder paradigm. In the encoder, we introduce an embedding block including the 3-layer 1D convolution for extracting the token and a mask generator to randomly mask out the sequence of tokens to maximize the model's potential to capture high-level, discriminative, intrinsic representations. whereafter, the decoder utilizes this information to reconstruct the pixel sequence of the origin input and calculate the reconstruction loss to optimize the network. Moreover, the backbone of an auto-encoder is multi-head self-attention that can consider the global information of the token from the input, not just the local neighborhood. This allows the model to capture generalized contextual information. Extensive experiments demonstrate MA2 has SOTA performance of 90.91% accuracy on 1% limited pathological GRF samples with labels, and good generalization ability of 78.57% accuracy on scalable Parkinson disease dataset.


---
# A data-driven study on Implicit LES using a spectral difference method

## 基于数据驱动的谱差法隐式LES研究

Link: https://arxiv.org/abs/2411.03211

arXiv:2411.03211v1 Announce Type: new 
Abstract: In this paper, we introduce a data-driven filter to analyze the relationship between Implicit Large-Eddy Simulations (ILES) and Direct Numerical Simulations (DNS) in the context of the Spectral Difference method. The proposed filter is constructed from a linear combination of sharp-modal filters where the weights are given by a convolutional neural network trained to replicate ILES results from filtered DNS data. In order to preserve the compactness of the discretization, the filter is local in time and acts at the elementary cell level. The neural network is trained on the data generated from the Taylor-Green Vortex test-case at Re=1600. In order to mitigate the temporal effects and highlight the influence of the spatial discretization, the ILES are periodically restarted from DNS data for different time windows. Smaller time windows result in higher cross-correlations between ILES and the filtered DNS snapshots using the data-driven filters. The modal decay of the filter for the smallest time window considered aligns with classical eigenanalysis, showing better energy conservation for higher orders of approximation. Similarly, an analysis of the filter's kernel in the Fourier space confirms that higher polynomial orders are less dissipative compared to lower orders. As large time windows are considered, the trained filter encounters difficulties in representing the data due to significant non linear effects. Additionally, the impact of the data-driven filter on the resolved kinetic energy has been assessed through the evaluation of the sub-grid production term which results in both direct and inverse cascades with the former being more likely on average. The presence of backscatter suggests that ILES based on Discontinuous Spectral Element Methods might be equipped with an intrinsic mechanisms to transfer energy in both directions with a predominance of direct kinetic energy cascade.


---
# Automatic solid form classification in pharmaceutical drug development

## 药物开发中的自动固体形式分类

Link: https://arxiv.org/abs/2411.03308

arXiv:2411.03308v1 Announce Type: new 
Abstract: In materials and pharmaceutical development, rapidly and accurately determining the similarity between X-ray powder diffraction (XRPD) measurements is crucial for efficient solid form screening and analysis. We present SMolNet, a classifier based on a Siamese network architecture, designed to automate the comparison of XRPD patterns. Our results show that training SMolNet on loss functions from the self-supervised learning domain yields a substantial boost in performance with respect to class separability and precision, specifically when classifying phases of previously unseen compounds. The application of SMolNet demonstrates significant improvements in screening efficiency across multiple active pharmaceutical ingredients, providing a powerful tool for scientists to discover and categorize measurements with reliable accuracy.


---
# The Fundamental Limit of Jet Tagging

## 射流标记的基本极限

Link: https://arxiv.org/abs/2411.02628

arXiv:2411.02628v1 Announce Type: cross 
Abstract: Identifying the origin of high-energy hadronic jets ('jet tagging') has been a critical benchmark problem for machine learning in particle physics. Jets are ubiquitous at colliders and are complex objects that serve as prototypical examples of collections of particles to be categorized. Over the last decade, machine learning-based classifiers have replaced classical observables as the state of the art in jet tagging. Increasingly complex machine learning models are leading to increasingly more effective tagger performance. Our goal is to address the question of convergence -- are we getting close to the fundamental limit on jet tagging or is there still potential for computational, statistical, and physical insights for further improvements? We address this question using state-of-the-art generative models to create a realistic, synthetic dataset with a known jet tagging optimum. Various state-of-the-art taggers are deployed on this dataset, showing that there is a significant gap between their performance and the optimum. Our dataset and software are made public to provide a benchmark task for future developments in jet tagging and other areas of particle physics.


---
# Transferable polychromatic optical encoder for neural networks

## 用于神经网络的可转移多色光学编码器

Link: https://arxiv.org/abs/2411.02697

arXiv:2411.02697v1 Announce Type: cross 
Abstract: Artificial neural networks (ANNs) have fundamentally transformed the field of computer vision, providing unprecedented performance. However, these ANNs for image processing demand substantial computational resources, often hindering real-time operation. In this paper, we demonstrate an optical encoder that can perform convolution simultaneously in three color channels during the image capture, effectively implementing several initial convolutional layers of a ANN. Such an optical encoding results in ~24,000 times reduction in computational operations, with a state-of-the art classification accuracy (~73.2%) in free-space optical system. In addition, our analog optical encoder, trained for CIFAR-10 data, can be transferred to the ImageNet subset, High-10, without any modifications, and still exhibits moderate accuracy. Our results evidence the potential of hybrid optical/digital computer vision system in which the optical frontend can pre-process an ambient scene to reduce the energy and latency of the whole computer vision system.


---
# An information-matching approach to optimal experimental design and active learning

## 优化实验设计和主动学习的信息匹配方法

Link: https://arxiv.org/abs/2411.02740

arXiv:2411.02740v1 Announce Type: cross 
Abstract: The efficacy of mathematical models heavily depends on the quality of the training data, yet collecting sufficient data is often expensive and challenging. Many modeling applications require inferring parameters only as a means to predict other quantities of interest (QoI). Because models often contain many unidentifiable (sloppy) parameters, QoIs often depend on a relatively small number of parameter combinations. Therefore, we introduce an information-matching criterion based on the Fisher Information Matrix to select the most informative training data from a candidate pool. This method ensures that the selected data contain sufficient information to learn only those parameters that are needed to constrain downstream QoIs. It is formulated as a convex optimization problem, making it scalable to large models and datasets. We demonstrate the effectiveness of this approach across various modeling problems in diverse scientific fields, including power systems and underwater acoustics. Finally, we use information-matching as a query function within an Active Learning loop for material science applications. In all these applications, we find that a relatively small set of optimal training data can provide the necessary information for achieving precise predictions. These results are encouraging for diverse future applications, particularly active learning in large machine learning models.


---
# Utilizing a machine-learned potential to explore enhanced radiation tolerance in the MoNbTaVW high-entropy alloy

## 利用机器学习的潜力来探索MoNbTaVW高熵合金中增强的辐射耐受性

Link: https://arxiv.org/abs/2411.02834

arXiv:2411.02834v1 Announce Type: cross 
Abstract: High-entropy alloys (HEAs) based on tungsten (W) have emerged as promising candidates for plasma-facing components in future fusion reactors, owing to their excellent irradiation resistance. In this study, we construct an efficient machine-learned interatomic potential for the MoNbTaVW quinary system. This potential achieves computational speeds comparable to the embedded-atom method (EAM) potential, allowing us to conduct a comprehensive investigation of the primary radiation damage through molecular dynamics simulations. Threshold displacement energies (TDEs) in the MoNbTaVW HEA are investigated and compared with pure metals. A series of displacement cascade simulations at primary knock-on atom energies ranging from 10 to 150 keV reveal significant differences in defect generation and clustering between MoNbTaVW HEA and pure W. In HEAs, we observe more surviving Frenkel pairs (FPs) but fewer and smaller interstitial clusters compared to W, indicating superior radiation tolerance. We propose extended damage models to quantify the radiation dose in the MoNbTaVW HEA, and suggest that one reason for their enhanced resistance is subcascade splitting, which reduces the formation of interstitial clusters. Our findings provide critical insights into the fundamental irradiation resistance mechanisms in refractory body-centered cubic alloys, offering guidance for the design of future radiation-tolerant materials.


---
# Quantum machine learning for multiclass classification beyond kernel methods

## 超越核方法的多分类量子机器学习

Link: https://arxiv.org/abs/2411.02913

arXiv:2411.02913v1 Announce Type: cross 
Abstract: Quantum machine learning is considered one of the current research fields with immense potential. In recent years, Havl\'i\v{c}ek et al. [Nature 567, 209-212 (2019)] have proposed a quantum machine learning algorithm with quantum-enhanced feature spaces, which effectively addressed a binary classification problem on a superconducting processor and offered a potential pathway to achieving quantum advantage. However, a straightforward binary classification algorithm falls short in solving multiclass classification problems. In this paper, we propose a quantum algorithm that rigorously demonstrates that quantum kernel methods enhance the efficiency of multiclass classification in real-world applications, providing a clear quantum advantage. To demonstrate quantum advantage, we design six distinct quantum kernels within the quantum algorithm to map input data into quantum state spaces and estimate the corresponding quantum kernel matrices. The results from quantum simulations reveal that the quantum algorithm outperforms its classical counterpart in handling six real-world multiclass classification problems. Furthermore, we leverage a family of performance metrics to comprehensively evaluate the classification performance of the quantum algorithm. The results indicate that the quantum algorithm achieves satisfactory classification accuracy and excels in terms of precision, recall, and F1 score for macroaverage, microaverage, and weighted average methods.


---
# A scalable generative model for dynamical system reconstruction from neuroimaging data

## 用于从神经影像数据重建动态系统的可扩展生成模型

Link: https://arxiv.org/abs/2411.02949

arXiv:2411.02949v1 Announce Type: cross 
Abstract: Data-driven inference of the generative dynamics underlying a set of observed time series is of growing interest in machine learning and the natural sciences. In neuroscience, such methods promise to alleviate the need to handcraft models based on biophysical principles and allow to automatize the inference of inter-individual differences in brain dynamics. Recent breakthroughs in training techniques for state space models (SSMs) specifically geared toward dynamical systems (DS) reconstruction (DSR) enable to recover the underlying system including its geometrical (attractor) and long-term statistical invariants from even short time series. These techniques are based on control-theoretic ideas, like modern variants of teacher forcing (TF), to ensure stable loss gradient propagation while training. However, as it currently stands, these techniques are not directly applicable to data modalities where current observations depend on an entire history of previous states due to a signal's filtering properties, as common in neuroscience (and physiology more generally). Prominent examples are the blood oxygenation level dependent (BOLD) signal in functional magnetic resonance imaging (fMRI) or Ca$^{2+}$ imaging data. Such types of signals render the SSM's decoder model non-invertible, a requirement for previous TF-based methods. Here, exploiting the recent success of control techniques for training SSMs, we propose a novel algorithm that solves this problem and scales exceptionally well with model dimensionality and filter length. We demonstrate its efficiency in reconstructing dynamical systems, including their state space geometry and long-term temporal properties, from just short BOLD time series.


---
# Reweighting simulated events using machine-learning techniques in the CMS experiment

## 在CMS实验中使用机器学习技术对模拟事件进行重新加权

Link: https://arxiv.org/abs/2411.03023

arXiv:2411.03023v1 Announce Type: cross 
Abstract: Data analyses in particle physics rely on an accurate simulation of particle collisions and a detailed simulation of detector effects to extract physics knowledge from the recorded data. Event generators together with a GEANT-based simulation of the detectors are used to produce large samples of simulated events for analysis by the LHC experiments. These simulations come at a high computational cost, where the detector simulation and reconstruction algorithms have the largest CPU demands. This article describes how machine-learning (ML) techniques are used to reweight simulated samples obtained with a given set of model parameters to samples with different parameters or samples obtained from entirely different models. The ML reweighting method avoids the need for simulating the detector response multiple times by incorporating the relevant information in a single sample through event weights. Results are presented for reweighting to model variations and higher-order calculations in simulated top quark pair production at the LHC. This ML-based reweighting is an important element of the future computing model of the CMS experiment and will facilitate precision measurements at the High-Luminosity LHC.


---
# Chemifriction and Superlubricity: Friends or Foes?

## 化学和超润滑性: 朋友还是敌人？

Link: https://arxiv.org/abs/2411.03078

arXiv:2411.03078v1 Announce Type: cross 
Abstract: The mechanisms underlying chemifriction, i.e. the contribution of interfacial bonding to friction in defected twisted graphene interfaces are revealed using fully atomistic machine-learning molecular dynamics simulations. This involves stochastic events of consecutive bond formation and rupture, that are spatially separated but not necessarily independent. A unique shear-induced interlayer atomic transfer healing mechanism is discovered that can be harnessed to design a run-in procedure to restore superlubric sliding. This mechanism should be manifested as negative differential friction coefficients that are expected to emerge under moderate normal loads. A physically motivated phenomenological model is developed to predict the effects of chemifriction in experimentally relevant sliding velocity regimes. This allows us to identify a distinct transition between logarithmic increase and logarithmic decrease of frictional stress with increasing sliding velocity. While demonstrated for homogeneous graphene interfaces, a similar mechanism is expected to occur in other homogeneous or heterogeneous defected two-dimensional material interfaces.


---
# Extreme events at the onset of epileptic-like chimeras in small-world networks of FitzHugh-Nagumo neurons

## Fitzhugh-nagumo神经元的小世界网络中癫痫样嵌合体发作时的极端事件

Link: https://arxiv.org/abs/2411.03311

arXiv:2411.03311v1 Announce Type: cross 
Abstract: In this work, we investigate the dynamics of complex networks of FitzHugh-Nagumo excitable oscillators, focusing on the impact of coupling strength, network size, and randomness on their collective dynamics. Considering Watts-Strogatz small-world network connectivities, the system exhibits three distinct dynamical phases: chaotic, intermittent, and synchronized, with the intermittent phase displaying transient, epileptic-like chimera states. We analyse the transition to synchronisation by means of the master stability function, and show that peaks in the proportion of extreme events of synchronisation, which correlate with the behaviour of the largest Lyapunov exponent of the system, precede the transitions between the distinct dynamical regimes and mark the onset of epileptic-like chimera states. Our findings contribute to a broader understanding of synchronisation in excitable systems real neural networks and offer insights into the conditions that may lead to pathological epileptic-like states. Furthermore, we discus the potential use of extreme events to study real neural data.


---
# DeFault: Deep-learning-based Fault Delineation Using the IBDP Passive Seismic Data at the Decatur CO2 Storage Site

## 默认: 在Decatur CO2存储站点使用IBDP被动地震数据进行基于深度学习的断层描绘

Link: https://arxiv.org/abs/2311.04361

arXiv:2311.04361v3 Announce Type: replace 
Abstract: The carbon capture, utilization, and storage (CCUS) framework is an essential component in reducing greenhouse gas emissions, with its success hinging on the comprehensive knowledge of subsurface geology and geomechanics. Passive seismic event relocation and fault detection serve as indispensable tools, offering vital insights into subsurface structures and fluid migration pathways. Accurate identification and localization of seismic events, however, face significant challenges, including the necessity for high-quality seismic data and advanced computational methods. To address these challenges, we introduce a novel deep learning method, DeFault, specifically designed for passive seismic source relocation and fault delineating for passive seismic monitoring projects. By leveraging data domain-adaptation, DeFault allows us to train a neural network with labeled synthetic data and apply it directly to field data. Using DeFault, the passive seismic sources are automatically clustered based on their recording time and spatial locations, and subsequently, faults and fractures are delineated accordingly. We demonstrate the efficacy of DeFault on a field case study involving CO2 injection related microseismic data from the Decatur, Illinois area. Our approach accurately and efficiently relocated passive seismic events, identified faults and aided in the prevention of potential geological hazards. Our results highlight the potential of DeFault as a valuable tool for passive seismic monitoring, emphasizing its role in ensuring CCUS project safety. This research bolsters the understanding of subsurface characterization in CCUS, illustrating machine learning's capacity to refine these methods. Ultimately, our work bear significant implications for CCUS technology deployment, an essential strategy in combating climate change.


---
# Polarimetric compressed sensing with hollow, self-assembled diffractive films

## 具有中空自组装衍射膜的极化压缩传感

Link: https://arxiv.org/abs/2407.14722

arXiv:2407.14722v2 Announce Type: replace 
Abstract: Sensing light's polarization and wavefront direction enables surface curvature assessment, material identification, shadow differentiation, and improved image quality in turbid environments. Traditional polarization cameras utilize multiple sensor measurements per pixel and polarization-filtering optics, which result in reduced image resolution. We propose a nanophotonic pipeline that enables compressive sensing and reduces the sampling requirements with a low-refractive-index, self-assembled optical encoder. These nanostructures scatter light into lattice modes, which encode the wavefront direction and the polarization ellipticity in the linearly-polarized components of the diffracted, interference patterns. Combining optical encoders with a neural network, the system predicts pointing and polarization when the interference patterns are adequately sampled. A comparison of ``ordered'' and ``random'' optical encoders shows that the latter both blurs the interference patterns and achieves higher resolution. Our work centers on the unexpected modulation and spatial multiplexing of incident light polarization by self-assembled hollow nanocavity arrays as a class of materials distinct from traditional metasurfaces that will not only enable encoding for polarization and optical computing but also for compressed sensing and imaging.


---
# Waveguide-multiplexed photonic matrix-vector multiplication processor using multiport photodetectors

## 使用多端口光电探测器的波导复用光子矩阵矢量乘法处理器

Link: https://arxiv.org/abs/2410.05956

arXiv:2410.05956v3 Announce Type: replace 
Abstract: The slowing down of Moore's law has driven the development of application-specific processors for deep learning. Analog photonic processors offer a promising solution for accelerating matrix-vector multiplications (MVMs) in deep learning by leveraging parallel computations in the optical domain. Intensity-based photonic MVM processors, which do not utilize the phase information of light, are appealing due to their simplified operations. However, existing intensity-based schemes for such processors often employ wavelength multiplexing or mode multiplexing, both of which have limited scalability due to high insertion loss or wavelength crosstalk. In this work, we present a scalable intensity-based photonic MVM processor based on the concept of waveguide multiplexing. This scheme employs multiport photodetectors (PDs) to sum the intensities of multiple optical signals, eliminating the need for multiple wavelengths or modes. A 16-port Ge PD with a 3 dB bandwidth of 11.8 GHz at a bias voltage of -3 V is demonstrated, and it can be further scaled up to handle 250 ports while maintaining a 6.1 GHz operation bandwidth. A 4 $\times$ 4 circuit fabricated on a Si-on-insulator (SOI) platform is used to perform MVMs in a 3-layer neural network designed for classifying Iris flowers, achieving a classification accuracy of 93.3%. Furthermore, the performance of large-scale circuits in a convolutional neural network (CNN) for Fashion-MNIST is simulated, resulting in a classification accuracy of 90.53%. This work provides a simplified and scalable approach to photonic MVM, laying a foundation for large-scale and multi-dimensional photonic matrix-matrix multiplication in optical neural networks.


---
# Extreme Value Statistics of Community Detection in Complex Networks with Reduced Network Extremal Ensemble Learning (RenEEL)

## 具有简化网络极值集成学习 (RenEEL) 的复杂网络社区检测的极值统计

Link: https://arxiv.org/abs/2411.00977

arXiv:2411.00977v2 Announce Type: replace 
Abstract: Arguably, the most fundamental problem in Network Science is finding structure within a complex network. One approach is to partition the nodes into communities that are more densely connected than one expects in a random network. "The" community structure then corresponds to the partition that maximizes Modularity, an objective function that quantifies this idea. Finding the maximizing partition, however, is a computationally difficult, NP-Complete problem. We explore using a recently introduced machine-learning algorithmic scheme to find the structure of benchmark networks. The scheme, known as RenEEL, creates an ensemble of $K$ partitions and updates the ensemble by replacing its worst member with the best of $L$ partitions found by analyzing a simplified network. The updating continues until consensus is achieved within the ensemble. We perform an empirical study of three real-world networks to explore how the Modularity of the consensus partition depends on the values of $K$ and $L$ and relate the results to the extreme value statistics of record-breaking. We find that increasing $K$ is generally more effective than increasing $L$ for finding the best partition.


---
# A versatile framework for attitude tuning of beamlines at advanced light sources

## 一种用于高级光源的光束线姿态调整的通用框架

Link: https://arxiv.org/abs/2411.01278

arXiv:2411.01278v2 Announce Type: replace 
Abstract: Aside from regular beamline experiments at light sources, the preparation steps before these experiments are also worth systematic consideration in terms of automation; a representative category in these steps is attitude tuning, which typically appears in names like beam focusing, sample alignment etc. With the goal of saving time and manpower in both writing and using in mind, a Mamba-based attitude-tuning framework is created. It supports flexible input/output ports, easy integration of diverse evaluation functions, and free selection of optimisation algorithms; with the help from Mamba's infrastructure, machine learning (ML) and artificial intelligence (AI) technologies can also be readily integrated. The tuning of a polycapillary lens and of an X-ray emission spectrometer are given as examples for the general use of this framework, featuring powerful command-line interfaces (CLIs) and friendly graphical user interfaces (GUIs) that allow comfortable human-in-the-loop control. The tuning of a Raman spectrometer demonstrates more specialised use of the framework with customised optimisation algorithms. With similar applications in mind, our framework is estimated to be capable of fulfilling a majority of attitude-tuning needs. Also reported is a virtual-beamline mechanism based on easily customisable simulated detectors and motors, which facilitates both testing for developers and training for users.


---
# Predicting the Temperature-Dependent CMC of Surfactant Mixtures with Graph Neural Networks

## 用图神经网络预测表面活性剂混合物的温度相关CMC

Link: https://arxiv.org/abs/2411.02224

arXiv:2411.02224v2 Announce Type: replace 
Abstract: Surfactants are key ingredients in foaming and cleansing products across various industries such as personal and home care, industrial cleaning, and more, with the critical micelle concentration (CMC) being of major interest. Predictive models for CMC of pure surfactants have been developed based on recent ML methods, however, in practice surfactant mixtures are typically used due to to performance, environmental, and cost reasons. This requires accounting for synergistic/antagonistic interactions between surfactants; however, predictive ML models for a wide spectrum of mixtures are missing so far. Herein, we develop a graph neural network (GNN) framework for surfactant mixtures to predict the temperature-dependent CMC. We collect data for 108 surfactant binary mixtures, to which we add data for pure species from our previous work [Brozos et al. (2024), J. Chem. Theory Comput.]. We then develop and train GNNs and evaluate their accuracy across different prediction test scenarios for binary mixtures relevant to practical applications. The final GNN models demonstrate very high predictive performance when interpolating between different mixture compositions and for new binary mixtures with known species. Extrapolation to binary surfactant mixtures where either one or both surfactant species are not seen before, yields accurate results for the majority of surfactant systems. We further find superior accuracy of the GNN over a semi-empirical model based on activity coefficients, which has been widely used to date. We then explore if GNN models trained solely on binary mixture and pure species data can also accurately predict the CMCs of ternary mixtures. Finally, we experimentally measure the CMC of 4 commercial surfactants that contain up to four species and industrial relevant mixtures and find a very good agreement between measured and predicted CMC values.


---
# Strategic Data Re-Uploads: A Pathway to Improved Quantum Classification Data Re-Uploading Strategies for Improved Quantum Classifier Performance

## 用于提高量子分类器性能的数据重新上传策略

Link: https://arxiv.org/abs/2405.09377

arXiv:2405.09377v2 Announce Type: replace-cross 
Abstract: Quantum machine learning (QML) is a promising field that explores the applications of quantum computing to machine learning tasks. A significant hurdle in the advancement of quantum machine learning lies in the development of efficient and resilient quantum classifiers capable of accurately mapping input data to specific, discrete target outputs. In this paper, we propose a novel approach to improve quantum classifier performance by using a data re-uploading strategy. Re-uploading classical information into quantum states multiple times can enhance the accuracy of quantum classifiers. We investigate the effects of different cost functions, such as fidelity and trace distance, on the optimization process and the classification results. We demonstrate our approach to two classification patterns: a linear classification pattern (LCP) and a non-linear classification pattern (NLCP). We evaluate the efficacy of our approach by benchmarking it against four distinct optimization techniques: L-BFGS-B, COBYLA, Nelder-Mead, and SLSQP. Additionally, we study the different impacts of fixed datasets and random datasets. Our results show that our approach can achieve high classification accuracy and robustness and outperform the existing quantum classifier models.


---
# Prediction of intrinsic solubility for drug-like organic compounds using Automated Network Optimizer (ANO) for physicochemical feature and hyperparameter optimization

## 使用自动网络优化器 (ANO) 预测类药物有机化合物的内在溶解度，以进行物理化学特征和超参数优化

Link: https://dx.doi.org/10.26434/chemrxiv-2024-mp291?rft_dat=source%3Ddrss

Accurate prediction of aqueous solubility remains a critical challenge in the chemical and pharmaceutical industries, significantly influencing drug development and delivery. This study revisits this well-explored area by leveraging the advanced capabilities of modern computational resources. We apply an automated network optimizer model that integrates dual optimization processes for molecular features and hyperparameters, streamlining the traditionally complex hyperparameter search while providing an efficient interpretation of molecular properties. By employing feature optimization techniques, our deep neural network model demonstrates improvements in both the speed and accuracy of molecular property predictions, achieving an average performance of R2 = 0.991. This result outperforms conventional hyperparameter optimization methods such as grid search and random search in predicting the intrinsic solubility of 3,745 compounds across four external experimental datasets. Based on feature importance analysis, we identified key molecular features and structures that significantly influence solubility. Additionally, combining three molecular fingerprints (Morgan, MACCS key, and Avalon) with molecular descriptors enhances model performance, providing a deeper understanding of the relationship between molecular structure and solubility within the physicochemical feature optimization process. These findings underscore the potential of machine learning models to improve predictive modeling of physical properties, apply automated modeling and feature selection to new chemical datasets, and offer explainable insights into the principles driving solubility predictions.


---
# Adaptive Learning Reaction Pathways Search

## 自适应学习反应途径搜索

Link: https://dx.doi.org/10.26434/chemrxiv-2024-jc31g?rft_dat=source%3Ddrss

Computational simulations have become essential for understanding reaction mechanisms, identifying optimal catalysts, studying materials, and discovering chemical pathways. Even with the current advanced computational resources, determining competing reaction pathways and the associated transition states is extremely challenging. The problem is further exasperated as the system size increases due to the increasing number of comparable energy isomers and intermediates. In this work, we present a novel computational protocol to efficiently explore the potential energy surface and identify reaction pathways, by combining an adaptive learning global optimization procedure and neural networks for predicting transition states. For a given reaction, the global optimizer is first used to obtain putative low-lying minima in the basins of reactants and products. In the second step, generative adversarial networks (GAN) are used to estimate the transition states that connect any two initial and final states of a given reaction. This computational interface (GlobOptRx) can quickly identify the transition state structures along a reaction pathway and aid in the discovery of new reactions, determine generalized systems descriptors and facilitate the construction of kinetic models.


---
# Data Science-Driven Discovery of Optimal Conditions and a Condition-Selection Model for the Chan-Lam Coupling of Primary Sulfonamides

## 数据科学驱动的最佳条件发现和条件选择模型，用于主要磺胺类药物的Chan-Lam偶联

Link: https://dx.doi.org/10.26434/chemrxiv-2024-22jrq?rft_dat=source%3Ddrss

Secondary N-arylsulfonamides are common in pharmaceutical compounds owing to their valuable physicochemical properties. Direct N-arylation of primary sulfonamides presents a modular approach to this scaffold but remains a challenging disconnection for transition metal-catalyzed cross coupling broadly, including the Chan-Lam (CL) coupling of nucleophiles with (hetero)aryl boronic acids. Although the CL coupling reaction typically operates under mild conditions, it is also highly substrate-dependent and prone to over-arylation, limiting its generality and predictivity. To address these gaps, we employed data science tools in tandem with high-throughput experimentation to study and model the CL N-arylation of primary sulfonamides. To minimize bias in training set design, we applied un-supervised learning to systematically select a diverse set of primary sulfonamides for high-throughput data collection and modeling, resulting in a novel dataset of 3,904 reactions. This workflow enabled us to identify broadly applicable, highly selective conditions for the CL coupling of aliphatic and (hetero)aromatic primary sulfonamides with complex organoboron coupling partners. We also generated a regression model that not only successfully identifies high-yielding conditions for the CL coupling of various sulfonamides, but also sulfonamide features that dictate reaction outcome.


---
# A Simple Transfer Learning Approach for Assessing Small Datasets in Electrochemical Energy Cells Manufacturing

## 一种简单的转移学习方法，用于评估电化学能源电池制造中的小数据集

Link: https://dx.doi.org/10.26434/chemrxiv-2024-69t12?rft_dat=source%3Ddrss

The performance of electrochemical cells for energy storage and conversion, such as batteries and fuel cells, can be improved by optimizing their manufacturing processes. This can be very time consuming and costly through the conventional trial-and-error approaches. Machine Learning (ML) models can help to accelerate finding solutions to these types of problems. In academic research laboratories, manufacturing dataset sizes can be small, while ML models typically require large amounts of data. In this work, we propose a simple Transfer Learning (TL) approach where a Neural Network (NN) is trained in a vast dataset. Then, this NN is transferred to smaller datasets by freezing its weights and adding an extra trainable layer to improve the performance of this new TL-based NN. This novel approach is tested with pre-existing manufacturing experimental and stochastically generated datasets that were not acquired with the purpose of training ML models.


---
# The power of Hellmann-Feynman theorem: Kohn-Sham DFT energy derivatives with respect to the parameters of exchange-correlation functional at linear cost

## Hellmann-feynman定理的力量: 线性成本下关于交换相关函数参数的kohn-sham DFT能量导数

Link: https://dx.doi.org/10.26434/chemrxiv-2023-jp112-v4?rft_dat=source%3Ddrss

Efficient methods for computing derivatives with respect to the parameters of scientific models are crucial for applications in machine learning. These methods are important when training is done using gradient-based optimization algorithms or when the model is integrated with deep learning, as they help speed up calculations during the backpropagation pass. In the present work, we applied the Hellmann-Feynman theorem to calculate the derivatives of the Kohn-Sham DFT energies with respect to the parameters of the exchange-correlation functional. This approach was implemented in a prototype program on the basis of Python package PySCF. Using the LDA and GGA functionals as examples, we have shown that this approach scales approximately linear with the system size for a series of n-alkanes (CnH2n+2, n=4...64) with a double-zeta basis set.  We demonstrated a significant speedup in the derivative calculations in comparison with the widely used automatic differentiation approach such as pytorch based DQC, which has a computational complexity of O(n^2.0) - O(n^2.5).


---
# Activity Cliff-Informed Contrastive Learning
for Molecular Property Prediction

## 活动悬崖信息对比学习
用于分子性质预测

Link: https://dx.doi.org/10.26434/chemrxiv-2023-5cz7s-v2?rft_dat=source%3Ddrss

Modeling molecular activity and quantitative structure-activity relationships of chemical compounds is critical in drug design. Graph neural networks, which utilize molecular structures as frames, have shown success in assessing the biological activity of chemical compounds, guiding the selection and optimization of candidates for further development. However, current models often overlook activity cliffs (ACs)—cases where structurally similar molecules exhibit different bioactivities—due to latent spaces primarily optimized for structural features.
Here, we introduce AC-awareness (ACA), an inductive bias designed to enhance molecular representation learning for activity modeling. The ACA jointly optimizes metric learning in the latent space and task performance in the target space, making models more sensitive to ACs. We develop \name, an AC-informed contrastive learning approach that can be integrated with any graph neural network. Experiments on 39 benchmark datasets demonstrate that AC-informed representations of chemical compounds consistently outperform standard models in bioactivity prediction across both regression and classification tasks. AC-informed models show strong performance in predicting pharmacokinetic and safety-relevant molecular properties.
ACA paves the way toward activity-informed molecular representations, providing a valuable tool for the early stages of lead compound identification, refinement, and virtual screening.


---
# Practically significant method comparison protocols for machine learning in small molecule drug discovery.

## 小分子药物发现中机器学习的实际重要方法比较方案。

Link: https://dx.doi.org/10.26434/chemrxiv-2024-6dbwv-v2?rft_dat=source%3Ddrss

Machine Learning (ML) methods that relate molecular structure to properties are frequently proposed as in-silico surrogates for expensive or time-consuming experiments. In small molecule drug discovery, such methods inform high-stakes decisions like compound synthesis and in-vivo studies. This application lies at the intersection of multiple scientific disciplines. When comparing new ML methods
to baseline or state-of-the-art approaches, statistically rigorous method comparison protocols and domain-appropriate performance metrics are essential to
ensure replicability and ultimately the adoption of ML in small molecule drug discovery. This paper proposes a set of guidelines to incentivize rigorous and domain-appropriate techniques for method comparison tailored to small molecule property modeling. These guidelines, accompanied by annotated examples and open-source software tools, lay a foundation for robust ML benchmarking and thus the development of more impactful methods.


---
# Learning Pixel-wise Phase Unwrapping with Reinforcement Policy Gradient

## 用强化策略梯度学习逐像素相位展开

Link: https://www.researchsquare.com/article/rs-5342082/latest

This paper presents a novel method for pixel-wise phase unwrapping utilizing reinforcement learning (RL), addressing significant limitations of traditional techniques. Conventional phase unwrapping methods often struggle with noise and discontinuities, which can hinder their effectiveness in practical applications such as optical imaging and interferometry. In contrast, our approach employs Proximal Policy Optimization (PPO) to train an intelligent agent capable of making pixel-wise decisions based on the observed data, optimizing phase recovery without the need for extensive labeled datasets. We thoroughly evaluate our method on a variety of datasets, including both real and synthetic InSAR radar echo data, demonstrating its effectiveness across different scenarios. The experimental results reveal significant improvements in both accuracy and robustness compared to existing supervised learning techniques. Furthermore, our work not only advances the state-of-the-art in phase unwrapping but also underscores the potential of RL in solving complex imaging tasks. By paving the way for future applications in optical imaging and advanced interferometry, our research opens new avenues for exploring the capabilities of machine learning in handling intricate imaging challenges, thereby contributing to the broader field of computational imaging.


---
# Enhanced Prediction of Molecular Properties Using Transfer Learning on Sigma Profiles

## 使用Sigma轮廓上的迁移学习增强分子特性的预测

Link: https://www.researchsquare.com/article/rs-5278418/latest

The performance of machine learning techniques for the prediction of a wide range of molecular properties has seen rapid improvements in recent years due to developments in both molecular representations and deep learning modeling techniques. Sigma profiles, which are a computational descriptor representing the surface charge distribution of molecules, have shown promise as a molecular representation to support robust property prediction. Meanwhile, large-scale pretrained deep learning models based directly on molecular structure inputs, such as Uni-Mol, have demonstrated strong performance as general-purpose molecular representation learners. In this study, we seek to enhance the prediction of molecular properties by integrating information from sigma profiles with these advanced deep learning techniques. Our methodology involves fine-tuning the Uni-Mol model to accurately predict sigma profiles, which capture detailed molecular structural information important for determining molecular interactions. We then utilize transfer learning to apply the learned weights to predict specific molecular properties, replacing the final output layer to adapt to each new task. The results demonstrate improvements in predictive accuracy across various datasets, showcasing the effectiveness of combining sigma profiles with state-of-the-art machine learning models and demonstrating a path forward for leveraging theory-driven descriptor development to enhance large-scale data-driven molecular property modeling.


---
# Linear Regression with Fibonacci-Derived Polynomials for Temperature Prediction Model

## 温度预测模型的斐波那契多项式线性回归

Link: https://www.researchsquare.com/article/rs-5037119/latest

This research work explores the integration of Fibonacci-derived polynomial and linear equations from Fibonacci numbers into a machine learning framework for predictive modeling of environmental datasets, such as wind speed, temperature, and humidity. The research aims to evaluate the effectiveness of combining deterministic mathematical equations with traditional machine learning techniques to improve prediction accuracy and uncover hidden patterns in natural datasets. This novel approach was implemented on a number of models which showed a good result for further research. The linear and Fibonacci-derived polynomial equations showed features of machine learning and since the Fibonacci pattern have been adopted in natural science, this technique of using the deterministic mathematical equation for feature engineering became fitting for natural dataset, the option of working with time series and environmental dataset have shown encouraging result and an above average accuracy.


---
# Temperature field reconstruction of stirred friction welding based on deep learning work conditions features fusion

## 基于深度学习工况特征融合的搅拌摩擦焊温度场重建

Link: https://www.researchsquare.com/article/rs-5330339/latest

The evolution of the temperature field during the friction stir welding (FSW) process is critical to both weld seam quality and the realization of intelligent welding. Traditional finite element simulations, while accurate, are time-consuming and unsuitable for real-time correction, while neural network-based methods for reconstructing the temperature field often lack the efficiency required for real-time monitoring. To address these challenges, this paper proposes a temperature field reconstruction method for FSW that integrates deep learning and working condition feature fusion. The method utilises a generative adversarial network (UGAN) model to achieve the fusion of working condition features with temperature field images. The UGAN generator employs an encoder-decoder architecture with skip connections to enhance multi-scale feature extraction, while the Patch Generative Adversarial Network (PatchGAN) structure is used to improve the perception of image details. To further refine predictions, the Cuckoo Search (CS) algorithm is applied to correct the predicted temperature images, thereby establishing a correction model for the temperature field. This approach effectively combines deep learning techniques with working condition data to significantly enhance the accuracy of temperature field prediction and enable real-time reconstruction for FSW.


---
# Statistical Analysis and Prediction via Neural Networks of water quality in the Middle Para&iacute;ba do Sul (Rio de Janeiro State, Brazil) region in the period (2012 - 2022)

## 在此期间 (2012至2022)，通过神经网络对南帕拉伊巴中部 (巴西里约热内卢州) 地区的水质进行统计分析和预测

Link: https://www.researchsquare.com/article/rs-5210488/latest

This study presents a 10-year temporal assessment (2012&amp;ndash;2022) of water quality in the Middle Para&amp;iacute;ba do Sul hydrographic region, using the Water Quality Index (WQI) and statistical tools, with predictions via General Regression Neural Network (GRNN). The analysis, based on INEA data, highlights climatic events such as the 2014/2015 drought and differences between the WQI in rainy and dry seasons. The preservation of water quality in this region is crucial for public health, sustainability, and the economic development of the Rio de Janeiro metropolitan area, which relies on the Para&amp;iacute;ba do Sul River. Increasing urbanization, agricultural expansion, and climate change pose challenges to water quality. Statistical tools such as Principal Component Analysis (PCA) and Analysis of Variance (ANOVA) reveal significant variations between monitoring points, and GRNN predicts WQI trends for 2023. This predictive approach is vital for informed decision-making in water resource management, particularly as environmental pressures increase.


---
# Formation of Sense of Agency in Novel Motor Learning

## 新型运动学习中代理感的形成

Link: https://www.researchsquare.com/article/rs-5264882/latest

Sense of agency (SoA) refers to the sensation of controlling one&amp;rsquo;s body and the external environment. The traditional comparator model posits that SoA arises from a match between predicted and actual action outcomes. Yet, when learning new motor skills, individuals lack reliable predictions of outcomes. This study explored SoA development in novel motor learning where participants controlled a cursor via finger movements. Across learning phases, we evaluated participants&amp;rsquo; SoA for cursor movements that either conformed to the learned hand-to-screen mapping or incorporated spatial or temporal biases. Initially, temporal congruence between finger and cursor movements dictated SoA. As learning progressed, SoA increased for the cursor following the learned mapping over that with spatial discrepancies. Such changes did not occur by just memorizing the mapping in a gesture imitation task. These findings enrich existing SoA theories by elucidating the origin of the comparator process, highlighting the pivotal role of motor exploration.


---
# Explaining the Nurses&rsquo; Experiences of Caring for Children with Cerebral Palsy: A Qualitative Study

## 解释护士照顾脑瘫儿童的经验: 一项定性研究

Link: https://www.researchsquare.com/article/rs-5197864/latest

Background and Objective: Caring for children with cerebral palsy presents many challenges for nurses. Therefore, this study was conducted to explain the experiences of nurses in providing care to children with cerebral palsy.Method This study was carried out using content analysis and the Colaizzi method on 11 nurses working at Besat Hospital in Sanandaj city, Iran. Purposeful sampling was employed, and in-depth, semi-structured interviews were conducted with the nurses, starting with an open-ended question. Sampling continued until data saturation was reached. The technique of audio recording was utilized.Results The results of this study yielded 5 main categories and 12 subcategories, which included learning challenges (effective training, learning gaps), comprehensive care (physical care, health care), mental health challenges (psychological burden, uncertain future, emotional support), accompanying problems (associated diseases, movement disorders, cognitive impairments), and communication challenges (speech disorders, non-verbal interaction).Conclusion Caring for children with cerebral palsy is different from caring for other children, and nurses experience many challenges in this area. This highlights the need to pay attention to the needs of nurses to provide better and higher-quality care for these children.


---
# Reinforcement Learning-Based Government Bailout Strategies for Interbank Risk Contagion: A High-Dimensional Space Processing Approach

## 基于强化学习的银行间风险传染的政府救助策略: 高维空间处理方法

Link: https://www.researchsquare.com/article/rs-5340149/latest

The interbank business connections form a complex network structure, facilitating risk contagion channels that require governments to promptly provide necessary bailouts. Since the assets of each bank continuously change as the contagion evolves, determining the optimal bailout strategy throughout the entire contagion process becomes a dynamic problem. In order to consider not only the current contagion risks but also the subsequent evolution of the contagion, this paper introduces Reinforcement Learning (RL) to find the global optimal solution during the contagion process. However, when applying RL to the bailout problem, its reward function is difficult to design and can also lead to inefficient exploration and unstable strategies due to the high dimensionality of the task space caused by the large number of banks. To address these problems, this paper proposes a proximal policy optimization algorithm with high-dimensional space processing (HDSP-PPO), which enhances the reward signal by combining immediate and final rewards, constructs an action candidate set to accelerate action exploration efficiency, and improves the stability of the policy in unseen states through spatial decomposition and low-dimensional representation of the state. Finally, we developed a multi-agent interbank lending network system with realistic data and simulated the risk contagion. Through experiments in the contagion environment, it is validated that the HDSP-PPO can obtain a better global strategy than optimization algorithms and is superior to other mainstream reinforcement learning algorithms in terms of solution quality, convergence, and stability.


---
# Active Disruption Avoidance and Trajectory Design for Tokamak Ramp-downs with Neural Differential Equations and Reinforcement Learning

## 基于神经微分方程和强化学习的托卡马克斜降主动干扰规避和轨迹设计

Link: https://www.researchsquare.com/article/rs-4824183/latest

The tokamak offers a promising path to fusion energy, but disruptions pose a major economic risk, motivating advances in disruption avoidance. This work develops a reinforcement learning approach to this problem by training a policy to safely ramp-down the plasma current while avoiding limits on a number of quantities correlated with disruptions. The policy training environment is a hybrid physics and machine learning model trained on simulations of the SPARC primary reference discharge (PRD) ramp-down, an upcoming burning plasma scenario which we use as a testbed. To address physics uncertainty and model inaccuracies, the simulation is massively parallelized on GPU with randomized parameters during policy training. The trained policy is then transferred to a transport simulator where it successfully ramps down the plasma. We directly address the crucial issue of safety criticality by demonstrating that a constraint-conditioned policy can be a trajectory design assistant that designs a library of feed-forward trajectories to handle conditions and user settings, a promising approach for the safety-critical context of burning plasma tokamaks. Finally, we demonstrate that the training environment can be a useful platform for other feed-forward optimization approaches by using an evolutionary algorithm to optimize feed-forward trajectories that are robust to physics uncertainty.


---
# Aircraft Range Fuel Consumption Prediction Using CNN- LSTM Enhanced by CEEMDAN and Improved Arctic Puffin Optimization Algorithm

## 基于CEEMDAN和改进的Arctic Puffin优化算法的cnn-lstm飞机航程油耗预测

Link: https://www.researchsquare.com/article/rs-5343590/latest

To effectively predict the fuel consumption of civil aviation aircraft during their flight routes, enhance fuel economy, and promote energy conservation and emission reduction, we propose a hybrid model that combines adaptive noise complete empirical mode decomposition (CEEMDAN) with an improved arctic puffin optimization (IAPO) algorithm optimized convolutional long short-term memory neural network (CNN-LSTM). Initially, the Pearson coefficient is employed for correlation analysis to reduce the nine-dimensional factors influencing aircraft fuel consumption, transforming them into five principal components. Subsequently, CEEMDAN is utilized to decompose the original fuel consumption data, yielding more regular subsequences. Subsequently, the convolutional neural network (CNN) efficiently extracts data features, which are then input into the LSTM network. Furthermore, utilizing the SPM chaotic map strategy for population initialization. The introduction of the golden sine operator mutation strategy enhances the local search capability of the algorithm, while the adaptive dive switching strategy adjusts the search intensity, significantly improving the global search performance and convergence speed of the Arctic Puffin optimization algorithm. Ultimately, the multi-strategy improved Arctic Puffin Optimization algorithm is utilized to adaptively optimize the hyperparameters of the CNN-LSTM model, allowing for the superimposition of each subsequence to yield the final prediction result. Simulation results indicate that the CEEMDAN-IAPO-CNN-LSTM model outperforms other comparative models in terms of prediction accuracy and exhibits lower prediction error. This model presents a novel and efficient method for predicting fuel consumption in airlines, offering valuable insights for reducing aircraft fuel consumption.


---
# Quantum-Inspired Federated Learning for Privacy-Preserving and Communication- Efficient Healthcare IoT Systems

## 量子启发的联邦学习，用于隐私保护和通信高效的医疗保健物联网系统

Link: https://www.researchsquare.com/article/rs-5336868/latest

With the increasing deployment of healthcare IoT (HIoT) systems, it is crucial to solve the data privacy problem and avoid information leakage while ensuring communications efficiency. Traditional FL models are usually decentralized, but they often face high communication overhead and severe privacy risks. In this paper, we firstly propose a novel quantum-inspired FL model to mitigate the information leakage, reduce the energy consumption and communication cost in HIoT systems. Besides, we adopt quantum-inspired differential privacy mechanisms to prevent information leakage and quantum optimization techniques to minimize communication rounds and accelerate the convergence of FL training. To verify the performances of the proposed quantum-inspired FL model in a federated healthcare IoT environment, we conduct extensive experiments and the results show the proposed model can reduce the communication overhead by 22.1%, lower the energy consumption by 16.8%, and guarantee accurate prediction with high accuracy above 91.9% for both training and test groups, which outperforms the traditional methods. This estimated the gap between FL and QL and launched a promising vision of scalable and energy-efficient model for privacy-sensitive applications in HIoT systems.


---
# Mechanical and Thermal Insulation Properties of Hollow Glass Microspheres Coated with Al2O3 Polyester-based Composite Coatings

## 中空玻璃微球包覆Al2O3聚酯基复合涂层的力学性能和隔热性能

Link: https://www.researchsquare.com/article/rs-5336226/latest

In this study, Al2O3 as a filler was chemically plated on the surface of hollow glass microspheres, and composite coatings with filler contents ranging from 0&amp;ndash;35 wt% were prepared using polyester as the matrix. In addition, the structural characteristics of hollow glass microspheres were briefly described. The physical properties, morphology, structural composition, mechanical properties, and thermal insulation of the samples were characterized using a true density tester, scanning electron microscopy (SEM), thermogravimetric scanning calorimetry (DSC), a universal testing machine, and a thermal conductivity tester, respectively. The hollow glass microspheres coated with Al2O3 improved the mechanical and thermal insulation properties of the prepared composite coatings. Compared with that of the pure polyester coatings, the tensile strength increased by 7% at a 5 wt% filler content, and the thermal conductivity decreased by 41.7% to 0.404 W/m&amp;middot;K at a 25 wt% filler content.


---
# Students&rsquo; Satisfaction with Problem-Based Learning: An Academic Experience at International Maaref University

## 学生对基于问题的学习的满意度: 国际马雷夫大学的学术经验

Link: https://www.researchsquare.com/article/rs-5251584/latest

Background. Implementation of problem-based learning has proven difficult in the majority of Arabic higher education institutions, including International Maaref University (IMU) due to deficiencies in the secondary education system. This study aimed to explore the effect of problem-based learning (PBL) practices on students&rsquo; satisfaction at IMU, Libya.
Methods. An online questionnaire was prepared and distributed to the third and fourth semester students of faculty of medicine at IMU.
Results. It was observed that the majority of students were satisfied with the PBL and declared that PBL had enhanced their problem-solving abilities, critical thinking, and develop social skills. However, the impact of PBL on social skills and leadership roles shows variability among students, reflecting diverse experiences.
Conclusions. These findings indicated that PBL effectively develops certain competencies; however, there is room for growth in fostering a comprehensive skill set among students.


---
# OLTunes: Online learning-based Auto-tuning System for DL Inference in Heterogeneous GPU Cluster

## OLTunes: 异构GPU集群中基于在线学习的DL推理自动调优系统

Link: https://www.researchsquare.com/article/rs-5342517/latest

With rapid AI advancements, GPU accelerator technology is also evolving, increasing heterogeneous computing nodes in datacenters. This requires schedulers to recognize and optimally manage diverse resources to meet application needs dynamically. For latency-sensitive tasks like deep learning inference, lack of precise GPU scheduling leads to resource interference, degrading both application performance and overall GPU utilization. The rise of NLP and LLMs has intensified focus on models that balance throughput and latency, but dynamic loads on specific resources can degrade performance through head-of-line blocking. Thus, proactive resource management is essential for reducing costs while ensuring QoS and maintaining energy efficiency.This paper introduces OLTunes, a cluster-level scheduling system for deep learning inference models, which combines streaming and batch methods to efficiently handle online and offline models. Leveraging FM-FTML, an online learning technique, OLTunes optimizes runtime environments and resource selection to meet user SLA via prediction and optimization. It forms co-running groups based on job characteristics and model variants to reduce interference, ensuring complementary affinities between tasks. OLTunes also automatically tunes resources and settings to enhance performance and reduce resource fragmentation. Performance experiments on a heterogeneous GPU cluster showed an average GPU utilization improvement of 58%, reduced P99 tail latency by up to 49%, and increased throughput by 61%. It also achieved approximately 84.6% energy savings with a maximum accuracy loss of 4% and reduced latency-sensitive SLO violations by up to 92% compared to other baselines, ensuring end-to-end QoS.


---
# A QoS-Aware Uplink Resource Allocation Scheme for LTE-A/5G HetNets

## 一种基于QoS的lte-a/5g hetnet上行资源分配方案

Link: https://www.researchsquare.com/article/rs-5328558/latest

Resource constraints in Long Term Evolution-Advanced (LTE-A)/5G heterogeneous networks pose significant challenges to maintaining high-quality and real-time data transmission. Quality of Service (QoS) is crucial for ensuring user satisfaction across both real-time (RT) and non-real-time (NRT) applications. This paper proposes a novel scheduling and resource allocation scheme that employs a Smoothed Round-Robin (SRR) algorithm to classify traffic into real-time (RT) and non-real-time (NRT) classes. A power-constrained resource allocation method based on Deep Q-learning (DQL) is then applied to manage these traffic classes. Furthermore, we propose a handover mechanism that utilizes the Weighted Aggregated Sum Product Assessment (WASPAS) method to address mobility and inter-cell interference challenges. Simulation results demonstrate the superior performance of the proposed scheme compared to existing solutions, showcasing improvements in delay, throughput, fairness index, call drop rate, and packet loss rate. This research presents a novel, efficient approach to QoS-aware resource allocation in LTE-A/5G HetNets.


---
# Determinants of food insecurity: a text mining approach

## 粮食不安全的决定因素: 文本挖掘方法

Link: https://www.researchsquare.com/article/rs-5389116/latest

This study applies Natural Language Processing (NLP) and Machine Learning (ML) to investigate global historical trends in food security. Using USAID&rsquo;s Famine Early Warning Systems Network&rsquo;s (FEWS NET) comprehensive reports spanning over two dozen countries, it explores prevalent dimensions such as shocks, outcomes, and coping capacities, offering insights into long-term food security conditions. Results highlight the prevalence of market and climate impacts across the countries and period considered. Based on results from the topic classification, ML models were applied to determine the most important factors that predict food insecurity. The analysis confirmed market shocks as the main predictors of food insecurity, globally. The approach demonstrates the potential for extracting valuable insights from narrative sources that can support decision-making and strategic planning. This integrated approach not only enhances understanding of food security but also presents a versatile tool applicable beyond the context of humanitarian aid.


---
# &nbsp;Investigating user-friendly machine learning algorithm to forecast the gas hydrate formation temperature&nbsp;

## 天然气水合物生成温度预测的用户友好机器学习算法研究

Link: https://www.researchsquare.com/article/rs-5345505/latest

In pipelines and process equipment, especially in cold oceanic environments, gas hydrate development presents a serious problem to the petroleum industry. Getting around this problem efficiently requires an understanding of the chemical thermodynamics of gas hydrate formation. In order to forecast the temperature of gas hydrate formation, the current investigation compares the effectiveness of three different types of machine learning algorithms: Support Vector Regression (SVR), Artificial Neural Networks (ANNs), and Decision Tree Regression (DT). The research was conducted using Python 3.11.3 as the programming framework, which made use of its extensive ecosystem of open-source tools, including scikit-learn (version 1.2.2) and Keras with TensorFlow. With ANNs, there was no activation function in the output layer and the hyperbolic tangent function was used as the activation function in a hidden layer. The Radial Basis Function (rbf) was used as the Kernel function for Support Vector Regression (SVR). A maximum tree depth of 15 was imposed on the Decision Tree (DT) regression. Throughout the whole dataset, evaluation measures such as Root Mean Square Error (RMSE) and coefficient of determination (R2) were calculated. The findings showed that the R2/RMSE values for SVR, ANNs, and DT regression were, respectively, (0.9999, 0.0631), (0.9986, 0.5011), and (0.9278, 3.5606). In conclusion, the models' output was rated as follows in descending order: Support vector regression (SVR) is a subset of decision tree regression (DT) and artificial neural networks (ANNs). Following that, a Web User Interface (WUI) was created using the Decision Tree paradigm, which proved to be the most efficient. In theoretical terms, this work opens the door to further developments in gas engineering. The prediction capability of the models could potentially further improved by adding more experimental data to the dataset used for training.


---
# Modern Ransomware Detection Using Adaptive Flexible Temporal Feature Integration

## 使用自适应灵活的时间特征集成的现代勒索软件检测

Link: https://www.researchsquare.com/article/rs-5400328/latest

The evolution of ransomware attacks, with increasingly complex evasion tactics and multi-stage infection processes, poses severe challenges for traditional cybersecurity defenses that often rely on static, signature-based detection methods. Introducing a novel approach, Adaptive Temporal Feature Integration (ATFI) leverages temporal dynamics to distinguish ransomware activities from legitimate system operations, capturing critical behavioral transitions indicative of ransomware stages. Through adaptive learning mechanisms and the integration of machine learning techniques, including recurrent neural networks and support vector machines, the ATFI model dynamically adjusts feature importance based on temporal patterns, achieving superior detection accuracy and reducing false positives. Empirical findings indicate that ATFI demonstrates high precision and recall across diverse ransomware strains, establishing its robustness and scalability within various enterprise environments. Comparative analyses reveal that ATFI outperforms conventional models by successfully identifying evolving ransomware behaviors, confirming its practical relevance in modern cybersecurity frameworks. The resource-efficient design and scalability of ATFI demonstrate its viability for real-time deployment, making it an advanced tool in protecting digital infrastructures against ransomware threats.


---
# Directional Adaptive Metric Sampling Minimal Expected Loss: A Continuous Optimisation Method

## 定向自适应度量采样最小期望损失: 一种连续优化方法

Link: https://www.researchsquare.com/article/rs-5402563/latest

This paper presents an optimisation method called Directional Adaptive Metric Sampling Minimal Expected Loss (DAMSMEL) which uses a technique of minimising the expected value of the objective function across a sample of neighbourhood points in an iterative manner generated uniformly in a bidirectional configuration with respect to the vector basis with exponentially decaying distance of adjacent points as well as a reset mechanism, and this method does not rely on gradient information. DAMSMEL is intended to be a robust optimisation method which can escape local minima in non-convex landscapes, overcoming an inherent limitation associated with gradient-based methods. This paper presents the theoretical foundation of DAMSMEL within probability theory and functional analysis including a rigorous proof that DAMSMEL is convergent to a global minimum in convex optimisation landscapes. We have conducted tests on convex and non-convex optimisation problems, on a machine learning regression problem, as well as a non-linear problem, comparing DAMSMEL with GD, Stochastic Gradient Descent (SGD), Adaptive Moment Estimation (Adam) and Ordinary Least Squares (OLS). Results show that while both DAMSMEL and GD converge to the global minimum in the convex case, GD gets trapped in local minima for the non-convex problem, whereas DAMSMEL successfully converges to the global minimum, demonstrating DAMSMEL's robustness in non-convex optimisation. In the machine learning regression task, DAMSMEL, SGD, and OLS yield comparable accuracy. And in the non-linear problem, DAMSMEL outperforms GD, SGD and Adam as it provides the most accurate solution compared to GD, SGD and Adam with huge margins. However, DAMSMEL tends to require longer runtimes due to its computational complexity, making it currently more suitable for low to medium-scale optimisation problems.
MSC Classification: 65K10


---
# Test Bench for Economic Science: Stock Market Forecasting in &ldquo;n&rdquo; Dimensions

## 经济科学测试一下平台: “n” 个维度的股市预测

Link: https://www.researchsquare.com/article/rs-5320597/latest

Econophysics, supported by mathematics, has proven to be a promising field for studying complex economic systems. However, the absence of a general theory limits its applicability. This work proposes a novel framework based on fluid dynamics and artificial intelligence to jointly model and predict dependent economic events. After the model &ldquo;WAVES&rdquo;, the model termed &ldquo;ABE&rdquo; (Acceleration Balance Equation), defines a space with a potential field, where geodesics represent the trajectories of economic events (the &ldquo;GT&rdquo; Geodesic Trajectories model) as the metric is defined by the Hamiltonian action. Artificial intelligence is utilized to optimize the model and enhance its predictive accuracy based on existing projections, working with the model described as a neural network. Comprehensive tests are conducted to validate the proposed approach, both for individual events and sets of events. The results demonstrate the model's capability to capture underlying dynamics and predict future behavior with minimal uncertainty. This method holds significant potential for real-time applications, as well as short, medium, and long-term analyses. By minimizing or removing human intervention and leveraging the laws of physics, particularly through transport and diffusion phenomena, the proposed approach offers a robust, targeted solution for the joint modeling and forecasting of economic events, built on the foundation of the so-called natural dynamics of the economy. Consequently, a range of useful tools are defined, providing economists with means to regulate the economy and intervene appropriately at critical moments, even creating new structures. These tools enable decision-makers to design and implement effective public policies that promote economic and social welfare, as well as optimal equilibrium. The 2024 Nobel laureate in Economics59 proposes the proper identification of institutions and the economic structure necessary to achieve sustainable growth. This growth also requires effective cooperation among individuals, as well as the preservation of both individual and conditional freedom. This article offers a key tool to accomplish that goal.


---
# Application of problem based learning (PBL) and case based learning (CBL) in the teaching of ectopic pregnancy

## 以问题为基础的学习 (PBL) 和以案例为基础的学习 (CBL) 在异位妊娠教学中的应用

Link: https://www.researchsquare.com/article/rs-5031510/latest

Objective: The aim of this study is to explore the effectiveness of combining problem-based learning (PBL) and case-based learning (CBL) in clinical teaching of ectopic pregnanancy.&amp;nbsp;
Methods:Fifth-year students majoring in clinical medicine were recruited in the Department of Gynecology at the Hengyang Central Hospital and Hainan General Hospital from September 2023 to June 2024. The students were randomly assigned into either the combined PBL-CBL group or the traditional group. Students in the experimental group were trained using the combined PBL-CBL teaching method, while those in the traditional group were trained using a lecture based learning (LBL) teaching method. After the end of the class, both groups of students were required to complete a post-class quiz and an anonymous questionnaire.
Results: The basic knowledge score in the combined PBL-CBL group was significantly higher than in the traditional group (42.6 &plusmn; 3.6 vs 35.0 &plusmn; 2.3, p = 0.000).Similarly, the case analysis score was higher in the combined PBL-CBL group than in the traditional group (37.1 &plusmn; 6.2 versus 33.8 &plusmn; 5.7, P = 0.013). The scores for learning motivation, understanding, student-teacher interaction, communication skills, clinical thinking skills, self-learning skills, knowledge absorption, and satisfaction with the course in the combined PBL-CBL group were significantly higher than that in the traditional group (P &amp;lt;0.05 for all). However, the score for how much free time the course consumed in the combined PBL-CBL group was significantly higher than that in the traditional group (P &amp;lt;0.05).
Conclusion: The combined PBL-CBL teaching method exhibited better acquisition of basic knowledge and higher competence in case analysis compared with those learning ectopic pregnancy with the traditional teaching methods. These results suggested that the combined PBL-CBL teaching method might be a promising new mode for gynecologic education.


---
# CDK4/6 Inhibition Induces CD8+ T Cell Antitumor Immunity via MIF-Induced Functional Orchestration of Tumor-Associated Macrophages

## CDK4/6抑制通过MIF诱导肿瘤相关巨噬细胞的功能协调诱导CD8 T细胞抗肿瘤免疫

Link: https://www.researchsquare.com/article/rs-5235555/latest

Cyclin-dependent kinases 4 and 6 (CDK4/6) regulate cell cycle progression from the G1 to S phase. Recent findings have demonstrated that CDK4/6 inhibition (CDK4/6i) enhances antitumor immunity, as evidenced by increased tumor infiltration of CD8+ T cells, though the underlying mechanism remains unclear. Our current study reveals that CDK4/6i enhances intratumoral CD8+ T cell infiltration in breast tumors through the functional reprogramming of tumor-associated macrophages (TAMs), facilitating indirect interactions between tumor cells and CD8+ T cells. Mechanistically, CDK4/6i enhances the proliferation and activation of M1 macrophages and promote the polarization of M2 to M1 macrophages via the macrophage migration inhibitory factor (MIF)-CD44/CD74 axis between tumor cells and macrophages. CDK4/6i-trained M1 TAMs increase and activate CD8+ T cells through MHC-I antigen presentation machinery. Inhibition of MIF in tumor cells or loss of MIF reverses the immunostimulatory effects of CDK4/6i on macrophages and subsequent CD8+ T cell antitumor immunity. Therefore, CDK4/6i-trained M1 TAM supernatant therapy surmounts the immunosuppressive tumor microenvironment and invokes a tumor response to low-dose PD-1 immune checkpoint blockade therapy in breast cancers.


---
# DeepPlant: An Accurate Cross-Species 5mC Detection Tool for Oxford Nanopore Sequencing in Plants

## DeepPlant: 一种用于植物中牛津纳米孔测序的精确跨物种5mC检测工具

Link: https://www.researchsquare.com/article/rs-5187157/latest

Nanopore sequencing enables comprehensive detection of 5-methylcytosine (5mC), particularly in transposable elements and centromeric regions. However, CHH methylation detection in plants is limited by the scarcity of high-methylation positive samples, reducing generalization across species. Dorado, the only tool for plant 5mC detection on the R10.4 platform, lacks extensive species testing. To address this, we reanalyzed bisulfite sequencing (BS-seq) data to screen species with abundant high-methylation CHH sites, generating new datasets that cover diverse 9-mer motifs. We developed DeepPlant, a deep learning model incorporating both Bi-LSTM and Transformer architectures, which significantly improves CHH detection accuracy and performs well for CpG and CHG motifs. Evaluated across species, DeepPlant achieved high whole-genome methylation frequency correlations (0.705 to 0.881) with BS-seq data on CHH motifs, improved by 14.0% to 117.6% compared to Dorado. DeepPlant also demonstrated superior single-molecule accuracy, F1-score, and stability, offering strong generalization for plant epigenetics research.


---
# Predicting CTCF&rsquo;s cell type-specific binding sites in human genome

## 预测人类基因组中CTCF的细胞类型特异性结合位点

Link: https://www.researchsquare.com/article/rs-5042361/latest

The CCCTC-binding factor (CTCF) is pivotal in orchestrating diverse biological functions across the human genome, yet the mechanisms driving its cell type-specific DNA binding affinity remain underexplored. Here, we collected ChIP-seq data from 67 cell lines in ENCODE, constructed a unique dataset of cell type-specific CTCF binding sites (CBS), and trained convolutional neural networks (CNN) to dissect the patterns of CTCF binding specificity. Our analysis reveals that transcription factors RAD21/SMC3 and chromatin accessibility are more predictive compared to sequence motifs and histone modifications. Integrating them together achieved AUC values consistently above 0.868, highlighting their utility in deciphering CTCF transcription factor binding dynamics. This study provides a deeper understanding of the regulatory functions of CTCF via machine learning framework.

