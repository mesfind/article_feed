# Ab initio characterization of protein molecular dynamics with AI<sup>2</sup>BMD

## AI&lt;sup&gt;2&lt;/sup&gt;BMD对蛋白质分子动力学的从头算表征

Link: https://www.nature.com/articles/s41586-024-08127-z

<p>Nature, Published online: 06 November 2024; <a href="https://www.nature.com/articles/s41586-024-08127-z">doi:10.1038/s41586-024-08127-z</a></p>A study introduces AI2BMD, an artificial intelligence-based dynamics simulation program that uses protein fragmentation with a machine learning force field to accurately and efficiently model the folding and unfolding of large proteins.


---
# Learning-associated astrocyte ensembles regulate memory recall

## 学习相关的星形胶质细胞集合调节记忆回忆

Link: https://www.nature.com/articles/s41586-024-08170-w

<p>Nature, Published online: 06 November 2024; <a href="https://www.nature.com/articles/s41586-024-08170-w">doi:10.1038/s41586-024-08170-w</a></p>A study in mice shows that learning induces c-Fos expression in a subset of astrocytes in the hippocampus, and that ensembles of these learning-associated astrocytes are involved in the recall of memories.


---
# Deep generative design of RNA aptamers using structural predictions

## 使用结构预测的RNA适体的深度生成设计

Link: https://www.nature.com/articles/s43588-024-00720-6

<p>Nature Computational Science, Published online: 06 November 2024; <a href="https://www.nature.com/articles/s43588-024-00720-6">doi:10.1038/s43588-024-00720-6</a></p>A deep learning platform for structure-guided, generative design of RNA sequences is developed and used to discover fluorescent RNA aptamers.


---
# Initiation of pericentric heterochromatin: From non-conserved sequences to conserved machinery

## 周着地异染色质的起始: 从非保守序列到保守机制

Link: https://www.sciencedirect.com/science/article/pii/S2095927324006443?dgcid=rss_sd_all

<p>Publication date: 15 November 2024</p><p><b>Source:</b> Science Bulletin, Volume 69, Issue 21</p><p>Author(s): Jun Chen, Jiyu Chen, Haiyan Lin, Guohong Li</p>


---
# Geometric neural operators (gnps) for data-driven deep learning in non-euclidean settings

## 用于非欧几里得环境中数据驱动的深度学习的几何神经算子 (gnp)

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad8980

We introduce Geometric Neural Operators (GNPs) for data-driven deep learning of geometric features for tasks in non-euclidean settings. We present a formulation for accounting for geometric contributions along with practical neural network architectures and factorizations for training. We then demonstrate how GNPs can be used (i) to estimate geometric properties, such as the metric and curvatures of surfaces, (ii) to approximate solutions of geometric partial differential equations on manifolds, and (iii) to solve Bayesian inverse problems for identifying manifold shapes. These results show a few ways GNPs can be used for incorporating the roles of geometry in the data-driven learning of operators.


---
# Interpretable Fine‐Grained Phenotypes of Subcellular Dynamics via Unsupervised Deep Learning

## 通过无监督的深度学习解释亚细胞动力学的细粒度表型

Link: https://onlinelibrary.wiley.com/doi/10.1002/advs.202403547?af=R

Advanced Science, Volume 11, Issue 41, November 6, 2024.


---
# Machine‐Learning Analysis of Streptomyces coelicolor Transcriptomes Reveals a Transcription Regulatory Network Encompassing Biosynthetic Gene Clusters

## 链霉菌转录组的机器学习分析揭示了一个包含生物合成基因簇的转录调控网络

Link: https://onlinelibrary.wiley.com/doi/10.1002/advs.202403912?af=R

Advanced Science, Volume 11, Issue 41, November 6, 2024.


---
# TAG‐SPARK: Empowering High‐Speed Volumetric Imaging With Deep Learning and Spatial Redundancy

## Tag-spark: 通过深度学习和空间冗余增强高速体积成像

Link: https://onlinelibrary.wiley.com/doi/10.1002/advs.202405293?af=R

Advanced Science, Volume 11, Issue 41, November 6, 2024.


---
# EOSnet: Embedded Overlap Structures for Graph Neural Networks in Predicting Material Properties

## EOSnet: 用于预测材料特性的图神经网络的嵌入式重叠结构

Link: https://arxiv.org/abs/2411.02579

arXiv:2411.02579v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for predicting material properties, yet they often struggle to capture many-body interactions and require extensive manual feature engineering. Here, we present EOSnet (Embedded Overlap Structures for Graph Neural Networks), a novel approach that addresses these limitations by incorporating Gaussian Overlap Matrix (GOM) fingerprints as node features within the GNN architecture. Unlike models that rely on explicit angular terms or human-engineered features, EOSnet efficiently encodes many-body interactions through orbital overlap matrices, providing a rotationally invariant and transferable representation of atomic environments. The model demonstrates superior performance across various materials property prediction tasks, achieving particularly notable results in properties sensitive to many-body interactions. For band gap prediction, EOSnet achieves a mean absolute error of 0.163 eV, surpassing previous state-of-the-art models. The model also excels in predicting mechanical properties and classifying materials, with 97.7\% accuracy in metal/non-metal classification. These results demonstrate that embedding GOM fingerprints into node features enhances the ability of GNNs to capture complex atomic interactions, making EOSnet a powerful tool for materials discovery and property prediction.


---
# Straintronic magnetic tunnel junctions for analog computation: A perspective

## 用于模拟计算的应变电子磁隧道结: 观点

Link: https://arxiv.org/abs/2411.02636

arXiv:2411.02636v1 Announce Type: new 
Abstract: The straintronic magnetic tunnel junction (s-MTJ) is an MTJ whose resistance state can be changed continuously or gradually from high to low with a gate voltage that generates strain the magnetostrictive soft layer. This unusual feature, not usually available in MTJs that are switched abruptly with spin transfer torque, spin-orbit torque or voltage-controlled-magnetic-anisotropy, enables many analog applications where the typically low tunneling magneto-resistance ratio of MTJs (on/off ratio of the switch) and the relatively large switching error rate are not serious impediments unlike in digital logic or memory. More importantly, the transfer characteristic of a s-MTJ (conductance versus gate voltage) always sports a linear region that can be exploited to implement analog arithmetic, vector matrix multiplication and linear synapses in deep learning networks very effectively. In these applications, the s-MTJ is actually superior to the better known memristors and domain wall synapses which do not exhibit the linearity and/or the analog behavior.


---
# Utilizing a machine-learned potential to explore enhanced radiation tolerance in the MoNbTaVW high-entropy alloy

## 利用机器学习的潜力来探索MoNbTaVW高熵合金中增强的辐射耐受性

Link: https://arxiv.org/abs/2411.02834

arXiv:2411.02834v1 Announce Type: new 
Abstract: High-entropy alloys (HEAs) based on tungsten (W) have emerged as promising candidates for plasma-facing components in future fusion reactors, owing to their excellent irradiation resistance. In this study, we construct an efficient machine-learned interatomic potential for the MoNbTaVW quinary system. This potential achieves computational speeds comparable to the embedded-atom method (EAM) potential, allowing us to conduct a comprehensive investigation of the primary radiation damage through molecular dynamics simulations. Threshold displacement energies (TDEs) in the MoNbTaVW HEA are investigated and compared with pure metals. A series of displacement cascade simulations at primary knock-on atom energies ranging from 10 to 150 keV reveal significant differences in defect generation and clustering between MoNbTaVW HEA and pure W. In HEAs, we observe more surviving Frenkel pairs (FPs) but fewer and smaller interstitial clusters compared to W, indicating superior radiation tolerance. We propose extended damage models to quantify the radiation dose in the MoNbTaVW HEA, and suggest that one reason for their enhanced resistance is subcascade splitting, which reduces the formation of interstitial clusters. Our findings provide critical insights into the fundamental irradiation resistance mechanisms in refractory body-centered cubic alloys, offering guidance for the design of future radiation-tolerant materials.


---
# Chemifriction and Superlubricity: Friends or Foes?

## 化学和超润滑性: 朋友还是敌人？

Link: https://arxiv.org/abs/2411.03078

arXiv:2411.03078v1 Announce Type: new 
Abstract: The mechanisms underlying chemifriction, i.e. the contribution of interfacial bonding to friction in defected twisted graphene interfaces are revealed using fully atomistic machine-learning molecular dynamics simulations. This involves stochastic events of consecutive bond formation and rupture, that are spatially separated but not necessarily independent. A unique shear-induced interlayer atomic transfer healing mechanism is discovered that can be harnessed to design a run-in procedure to restore superlubric sliding. This mechanism should be manifested as negative differential friction coefficients that are expected to emerge under moderate normal loads. A physically motivated phenomenological model is developed to predict the effects of chemifriction in experimentally relevant sliding velocity regimes. This allows us to identify a distinct transition between logarithmic increase and logarithmic decrease of frictional stress with increasing sliding velocity. While demonstrated for homogeneous graphene interfaces, a similar mechanism is expected to occur in other homogeneous or heterogeneous defected two-dimensional material interfaces.


---
# Computing critical exponents in 3D Ising model via pattern recognition/deep learning approach

## 通过模式识别/深度学习方法在3D Ising模型中计算关键指数

Link: https://arxiv.org/abs/2411.02604

arXiv:2411.02604v1 Announce Type: cross 
Abstract: In this study, we computed three critical exponents ($\alpha, \beta, \gamma$) for the 3D Ising model with Metropolis Algorithm using Finite-Size Scaling Analysis on six cube length scales (L=20,30,40,60,80,90), and performed a supervised Deep Learning (DL) approach (3D Convolutional Neural Network or CNN) to train a neural network on specific conformations of spin states. We find one can effectively reduce the information in thermodynamic ensemble-averaged quantities vs. reduced temperature t (magnetization per spin $<m>(t)$, specific heat per spin $(t)$, magnetic susceptibility per spin $<\chi>(t)$) to \textit{six} latent classes. We also demonstrate our CNN on a subset of L=20 conformations and achieve a train/test accuracy of 0.92 and 0.6875, respectively. However, more work remains to be done to quantify the feasibility of computing critical exponents from the output class labels (binned $m, c, \chi$) from this approach and interpreting the results from DL models trained on systems in Condensed Matter Physics in general.


---
# An information-matching approach to optimal experimental design and active learning

## 优化实验设计和主动学习的信息匹配方法

Link: https://arxiv.org/abs/2411.02740

arXiv:2411.02740v1 Announce Type: cross 
Abstract: The efficacy of mathematical models heavily depends on the quality of the training data, yet collecting sufficient data is often expensive and challenging. Many modeling applications require inferring parameters only as a means to predict other quantities of interest (QoI). Because models often contain many unidentifiable (sloppy) parameters, QoIs often depend on a relatively small number of parameter combinations. Therefore, we introduce an information-matching criterion based on the Fisher Information Matrix to select the most informative training data from a candidate pool. This method ensures that the selected data contain sufficient information to learn only those parameters that are needed to constrain downstream QoIs. It is formulated as a convex optimization problem, making it scalable to large models and datasets. We demonstrate the effectiveness of this approach across various modeling problems in diverse scientific fields, including power systems and underwater acoustics. Finally, we use information-matching as a query function within an Active Learning loop for material science applications. In all these applications, we find that a relatively small set of optimal training data can provide the necessary information for achieving precise predictions. These results are encouraging for diverse future applications, particularly active learning in large machine learning models.


---
# A Robust and Efficient Multi-physics Numerical System for Intensive Blast Wave Propagation in Complex Environments

## 复杂环境中密集爆炸波传播的鲁棒高效多物理场数值系统

Link: https://arxiv.org/abs/2411.02407

arXiv:2411.02407v1 Announce Type: new 
Abstract: We establish a high-resolution, high-performance, and high-confidence compressible multiphysics system in a Cartesian grid with irregular boundary topologies to simulate intensive blast waves propagating in large-scale and extremely complex environments. The multiphysics system is modeled by a multi-component model solved using a generalized Godunov method and a classical material point method in a combination of Lagrangian particles and a rigid material model. An artificial neural network equation of state (EOS) is proposed based on experimental data to simulate the intensive explosion products and real gas under extreme pressure and temperature. To improve computational accuracy and efficiency, a deepMTBVD reconstruction scheme of our previous work is extended to the multiphysics system. With the aid of high-performance parallel computation, several large-scale blast wave applications, such as blast wave propagating in a local and entire urban city, are simulated in a reasonable time period, which can validate numerical schemes and lead to more practical engineering applications.


---
# SK-PINN: Accelerated physics-informed deep learning by smoothing kernel gradients

## Sk-pinn: 通过平滑核梯度加速物理通知深度学习

Link: https://arxiv.org/abs/2411.02411

arXiv:2411.02411v1 Announce Type: new 
Abstract: The automatic differentiation (AD) in the vanilla physics-informed neural networks (PINNs) is the computational bottleneck for the high-efficiency analysis. The concept of derivative discretization in smoothed particle hydrodynamics (SPH) can provide an accelerated training method for PINNs. In this paper, smoothing kernel physics-informed neural networks (SK-PINNs) are established, which solve differential equations using smoothing kernel discretization. It is a robust framework capable of solving problems in the computational mechanics of complex domains. When the number of collocation points gradually increases, the training speed of SK-PINNs significantly surpasses that of vanilla PINNs. In cases involving large collocation point sets or higher-order problems, SK-PINN training can be up to tens of times faster than vanilla PINN. Additionally, analysis using neural tangent kernel (NTK) theory shows that the convergence rates of SK-PINNs are consistent with those of vanilla PINNs. The superior performance of SK-PINNs is demonstrated through various examples, including regular and complex domains, as well as forward and inverse problems in fluid dynamics and solid mechanics.


---
# An Efficient Monte Carlo Simulation for Radiation Transport Based on Global Optimal Reference Field

## 基于全局最优参考场的高效蒙特卡罗辐射输运模拟

Link: https://arxiv.org/abs/2411.02415

arXiv:2411.02415v1 Announce Type: new 
Abstract: The reference field method, known as the difference formulation, is a key variance reduction technique for Monte Carlo simulations of thermal radiation transport problems. When the material temperature is relatively high and the spatial temperature gradient is moderate, this method demonstrates significant advantages in reducing variance compared to classical Monte Carlo methods. However, in problems with larger temperature gradients, this method has not only been found ineffective at reducing statistical noise, but in some cases, it even increases noise compared to classical Monte Carlo methods. The global optimal reference field method, a recently proposed variance reduction technique, effectively reduces the average energy weight of Monte Carlo particles, thereby decreasing variance. Its effectiveness has been validated both theoretically and numerically, demonstrating a significant reduction in statistical errors for problems with large temperature gradients. In our previous work, instead of computing the exact global optimal reference field, we developed an approximate, physically motivated method to find a relatively better reference field using a selection scheme. In this work, we reformulate the problem of determining the global optimal reference field as a linear programming problem and solve it exactly. To further enhance computational efficiency, we use the MindOpt solver, which leverages graph neural network methods. Numerical experiments demonstrate that the MindOpt solver not only solves linear programming problems accurately but also significantly outperforms the Simplex and interior-point methods in terms of computational efficiency. The global optimal reference field method combined with the MindOpt solver not only improves computational efficiency but also substantially reduces statistical errors.


---
# An Efficient Hierarchical Preconditioner-Learner Architecture for Reconstructing Multi-scale Basis Functions of High-dimensional Subsurface Fluid Flow

## 一种有效的分层预处理器-学习器体系结构，用于重建高维地下流体流的多尺度基函数

Link: https://arxiv.org/abs/2411.02431

arXiv:2411.02431v1 Announce Type: new 
Abstract: Modeling subsurface fluid flow in porous media is crucial for applications such as oil and gas exploration. However, the inherent heterogeneity and multi-scale characteristics of these systems pose significant challenges in accurately reconstructing fluid flow behaviors. To address this issue, we proposed Fourier Preconditioner-based Hierarchical Multiscale Net (FP-HMsNet), an efficient hierarchical preconditioner-learner architecture that combines Fourier Neural Operators (FNO) with multi-scale neural networks to reconstruct multi-scale basis functions of high-dimensional subsurface fluid flow. Using a dataset comprising 102,757 training samples, 34,252 validation samples, and 34,254 test samples, we ensured the reliability and generalization capability of the model. Experimental results showed that FP-HMsNet achieved an MSE of 0.0036, an MAE of 0.0375, and an R2 of 0.9716 on the testing set, significantly outperforming existing models and demonstrating exceptional accuracy and generalization ability. Additionally, robustness tests revealed that the model maintained stability under various levels of noise interference. Ablation studies confirmed the critical contribution of the preconditioner and multi-scale pathways to the model's performance. Compared to current models, FP-HMsNet not only achieved lower errors and higher accuracy but also demonstrated faster convergence and improved computational efficiency, establishing itself as the state-of-the-art (SOTA) approach. This model offers a novel method for efficient and accurate subsurface fluid flow modeling, with promising potential for more complex real-world applications.


---
# First observations of the seiche that shook the world

## 震撼世界的seiche的第一次观察

Link: https://arxiv.org/abs/2411.02469

arXiv:2411.02469v1 Announce Type: new 
Abstract: On September 16th, 2023, an anomalous 10.88 mHz seismic signal was observed globally, persisting for 9 days. One month later an identical signal appeared, lasting for another week. Several studies have theorized that these signals were produced by seiches which formed after two landslide generated mega-tsunamis in an East-Greenland fjord. This theory is supported by seismic inversions, and analytical and numerical modeling, but no direct observations have been made -- until now. Using data from the new Surface Water Ocean Topography mission, we present the first observations of this phenomenon. By ruling out other oceanographic processes, we validate the seiche theory of previous authors and independently estimate its initial amplitude at 7.9 m using Bayesian machine learning and seismic data. This study demonstrates the value of satellite altimetry for studying extreme events, while also highlighting the need for specialized methods to address the altimetric data's limitations, namely temporal sparsity. These data and approaches will help in understanding future unseen extremes driven by climate change.


---
# Computing critical exponents in 3D Ising model via pattern recognition/deep learning approach

## 通过模式识别/深度学习方法在3D Ising模型中计算关键指数

Link: https://arxiv.org/abs/2411.02604

arXiv:2411.02604v1 Announce Type: new 
Abstract: In this study, we computed three critical exponents ($\alpha, \beta, \gamma$) for the 3D Ising model with Metropolis Algorithm using Finite-Size Scaling Analysis on six cube length scales (L=20,30,40,60,80,90), and performed a supervised Deep Learning (DL) approach (3D Convolutional Neural Network or CNN) to train a neural network on specific conformations of spin states. We find one can effectively reduce the information in thermodynamic ensemble-averaged quantities vs. reduced temperature t (magnetization per spin $<m>(t)$, specific heat per spin $(t)$, magnetic susceptibility per spin $<\chi>(t)$) to \textit{six} latent classes. We also demonstrate our CNN on a subset of L=20 conformations and achieve a train/test accuracy of 0.92 and 0.6875, respectively. However, more work remains to be done to quantify the feasibility of computing critical exponents from the output class labels (binned $m, c, \chi$) from this approach and interpreting the results from DL models trained on systems in Condensed Matter Physics in general.


---
# Towards more efficient agricultural practices via transformer-based crop type classification

## 通过基于变压器的作物类型分类实现更有效的农业实践

Link: https://arxiv.org/abs/2411.02627

arXiv:2411.02627v1 Announce Type: new 
Abstract: Machine learning has great potential to increase crop production and resilience to climate change. Accurate maps of where crops are grown are a key input to a number of downstream policy and research applications. In this proposal, we present preliminary work showing that it is possible to accurately classify crops from time series derived from Sentinel 1 and 2 satellite imagery in Mexico using a pixel-based binary crop/non-crop time series transformer model. We also find preliminary evidence that meta-learning approaches supplemented with data from similar agro-ecological zones may improve model performance. Due to these promising results, we propose further development of this method with the goal of accurate multi-class crop classification in Jalisco, Mexico via meta-learning with a dataset comprising similar agro-ecological zones.


---
# Generalization vs. Hallucination

## 泛化与幻觉

Link: https://arxiv.org/abs/2411.02893

arXiv:2411.02893v1 Announce Type: new 
Abstract: With fast developments in computational power and algorithms, deep learning has made breakthroughs and been applied in many fields. However, generalization remains to be a critical challenge, and the limited generalization capability severely constrains its practical applications. Hallucination issue is another unresolved conundrum haunting deep learning and large models. By leveraging a physical model of imaging through scattering media, we studied the lack of generalization to system response functions in deep learning, identified its cause, and proposed a universal solution. The research also elucidates the creation process of a hallucination in image prediction and reveals its cause, and the common relationship between generalization and hallucination is discovered and clarified. Generally speaking, it enhances the interpretability of deep learning from a physics-based perspective, and builds a universal physical framework for deep learning in various fields. It may pave a way for direct interaction between deep learning and the real world, facilitating the transition of deep learning from a demo model to a practical tool in diverse applications.


---
# Adaptive-precision potentials for large-scale atomistic simulations

## 大规模原子模拟的自适应精度潜力

Link: https://arxiv.org/abs/2411.03002

arXiv:2411.03002v1 Announce Type: new 
Abstract: Large-scale atomistic simulations rely on interatomic potentials providing an efficient representation of atomic energies and forces. Modern machine-learning (ML) potentials provide the most precise representation compared to electronic structure calculations while traditional potentials provide a less precise, but computationally much faster representation and thus allow simulations of larger systems. We present a method to combine a traditional and a ML potential to a multi-resolution description, leading to an adaptive-precision potential with an optimum of performance and precision in large complex atomistic systems. The required precision is determined per atom by a local structure analysis and updated automatically during simulation. We use copper as demonstrator material with an embedded atom model as classical force field and an atomic cluster expansion (ACE) as ML potential, but in principle a broader class of potential combinations can be coupled by this method. The approach is developed for the molecular-dynamics simulator LAMMPS and includes a load-balancer to prevent problems due to the atom dependent force-calculation times, which makes it suitable for large-scale atomistic simulations. The developed adaptive-precision copper potential represents the ACE-forces and -energies with a precision of 10 meV/{\AA} and 0 meV for the precisely calculated atoms in a nanoindentation of 4 million atoms calculated for 100 ps and shows a speedup of 11.3 compared with a full ACE simulation.


---
# MA^2: A Self-Supervised and Motion Augmenting Autoencoder for Gait-Based Automatic Disease Detection

## MA ^ 2: 用于基于步态的自动疾病检测的自监督和运动增强自动编码器

Link: https://arxiv.org/abs/2411.03129

arXiv:2411.03129v1 Announce Type: new 
Abstract: Ground reaction force (GRF) is the force exerted by the ground on a body in contact with it. GRF-based automatic disease detection (ADD) has become an emerging medical diagnosis method, which aims to learn and identify disease patterns corresponding to different gait pressures based on deep learning methods. Although existing ADD methods can save doctors time in making diagnoses, training deep models still struggles with the cost caused by the labeling engineering for a large number of gait diagnostic data for subjects. On the other hand, the accuracy of the deep model under the unified benchmark GRF dataset and the generalization ability on scalable gait datasets need to be further improved. To address these issues, we propose MA2, a GRF-based self-supervised and motion augmenting auto-encoder, which models the ADD task as an encoder-decoder paradigm. In the encoder, we introduce an embedding block including the 3-layer 1D convolution for extracting the token and a mask generator to randomly mask out the sequence of tokens to maximize the model's potential to capture high-level, discriminative, intrinsic representations. whereafter, the decoder utilizes this information to reconstruct the pixel sequence of the origin input and calculate the reconstruction loss to optimize the network. Moreover, the backbone of an auto-encoder is multi-head self-attention that can consider the global information of the token from the input, not just the local neighborhood. This allows the model to capture generalized contextual information. Extensive experiments demonstrate MA2 has SOTA performance of 90.91% accuracy on 1% limited pathological GRF samples with labels, and good generalization ability of 78.57% accuracy on scalable Parkinson disease dataset.


---
# A data-driven study on Implicit LES using a spectral difference method

## 基于数据驱动的谱差法隐式LES研究

Link: https://arxiv.org/abs/2411.03211

arXiv:2411.03211v1 Announce Type: new 
Abstract: In this paper, we introduce a data-driven filter to analyze the relationship between Implicit Large-Eddy Simulations (ILES) and Direct Numerical Simulations (DNS) in the context of the Spectral Difference method. The proposed filter is constructed from a linear combination of sharp-modal filters where the weights are given by a convolutional neural network trained to replicate ILES results from filtered DNS data. In order to preserve the compactness of the discretization, the filter is local in time and acts at the elementary cell level. The neural network is trained on the data generated from the Taylor-Green Vortex test-case at Re=1600. In order to mitigate the temporal effects and highlight the influence of the spatial discretization, the ILES are periodically restarted from DNS data for different time windows. Smaller time windows result in higher cross-correlations between ILES and the filtered DNS snapshots using the data-driven filters. The modal decay of the filter for the smallest time window considered aligns with classical eigenanalysis, showing better energy conservation for higher orders of approximation. Similarly, an analysis of the filter's kernel in the Fourier space confirms that higher polynomial orders are less dissipative compared to lower orders. As large time windows are considered, the trained filter encounters difficulties in representing the data due to significant non linear effects. Additionally, the impact of the data-driven filter on the resolved kinetic energy has been assessed through the evaluation of the sub-grid production term which results in both direct and inverse cascades with the former being more likely on average. The presence of backscatter suggests that ILES based on Discontinuous Spectral Element Methods might be equipped with an intrinsic mechanisms to transfer energy in both directions with a predominance of direct kinetic energy cascade.


---
# Automatic solid form classification in pharmaceutical drug development

## 药物开发中的自动固体形式分类

Link: https://arxiv.org/abs/2411.03308

arXiv:2411.03308v1 Announce Type: new 
Abstract: In materials and pharmaceutical development, rapidly and accurately determining the similarity between X-ray powder diffraction (XRPD) measurements is crucial for efficient solid form screening and analysis. We present SMolNet, a classifier based on a Siamese network architecture, designed to automate the comparison of XRPD patterns. Our results show that training SMolNet on loss functions from the self-supervised learning domain yields a substantial boost in performance with respect to class separability and precision, specifically when classifying phases of previously unseen compounds. The application of SMolNet demonstrates significant improvements in screening efficiency across multiple active pharmaceutical ingredients, providing a powerful tool for scientists to discover and categorize measurements with reliable accuracy.


---
# The Fundamental Limit of Jet Tagging

## 射流标记的基本极限

Link: https://arxiv.org/abs/2411.02628

arXiv:2411.02628v1 Announce Type: cross 
Abstract: Identifying the origin of high-energy hadronic jets ('jet tagging') has been a critical benchmark problem for machine learning in particle physics. Jets are ubiquitous at colliders and are complex objects that serve as prototypical examples of collections of particles to be categorized. Over the last decade, machine learning-based classifiers have replaced classical observables as the state of the art in jet tagging. Increasingly complex machine learning models are leading to increasingly more effective tagger performance. Our goal is to address the question of convergence -- are we getting close to the fundamental limit on jet tagging or is there still potential for computational, statistical, and physical insights for further improvements? We address this question using state-of-the-art generative models to create a realistic, synthetic dataset with a known jet tagging optimum. Various state-of-the-art taggers are deployed on this dataset, showing that there is a significant gap between their performance and the optimum. Our dataset and software are made public to provide a benchmark task for future developments in jet tagging and other areas of particle physics.


---
# Transferable polychromatic optical encoder for neural networks

## 用于神经网络的可转移多色光学编码器

Link: https://arxiv.org/abs/2411.02697

arXiv:2411.02697v1 Announce Type: cross 
Abstract: Artificial neural networks (ANNs) have fundamentally transformed the field of computer vision, providing unprecedented performance. However, these ANNs for image processing demand substantial computational resources, often hindering real-time operation. In this paper, we demonstrate an optical encoder that can perform convolution simultaneously in three color channels during the image capture, effectively implementing several initial convolutional layers of a ANN. Such an optical encoding results in ~24,000 times reduction in computational operations, with a state-of-the art classification accuracy (~73.2%) in free-space optical system. In addition, our analog optical encoder, trained for CIFAR-10 data, can be transferred to the ImageNet subset, High-10, without any modifications, and still exhibits moderate accuracy. Our results evidence the potential of hybrid optical/digital computer vision system in which the optical frontend can pre-process an ambient scene to reduce the energy and latency of the whole computer vision system.


---
# An information-matching approach to optimal experimental design and active learning

## 优化实验设计和主动学习的信息匹配方法

Link: https://arxiv.org/abs/2411.02740

arXiv:2411.02740v1 Announce Type: cross 
Abstract: The efficacy of mathematical models heavily depends on the quality of the training data, yet collecting sufficient data is often expensive and challenging. Many modeling applications require inferring parameters only as a means to predict other quantities of interest (QoI). Because models often contain many unidentifiable (sloppy) parameters, QoIs often depend on a relatively small number of parameter combinations. Therefore, we introduce an information-matching criterion based on the Fisher Information Matrix to select the most informative training data from a candidate pool. This method ensures that the selected data contain sufficient information to learn only those parameters that are needed to constrain downstream QoIs. It is formulated as a convex optimization problem, making it scalable to large models and datasets. We demonstrate the effectiveness of this approach across various modeling problems in diverse scientific fields, including power systems and underwater acoustics. Finally, we use information-matching as a query function within an Active Learning loop for material science applications. In all these applications, we find that a relatively small set of optimal training data can provide the necessary information for achieving precise predictions. These results are encouraging for diverse future applications, particularly active learning in large machine learning models.


---
# Utilizing a machine-learned potential to explore enhanced radiation tolerance in the MoNbTaVW high-entropy alloy

## 利用机器学习的潜力来探索MoNbTaVW高熵合金中增强的辐射耐受性

Link: https://arxiv.org/abs/2411.02834

arXiv:2411.02834v1 Announce Type: cross 
Abstract: High-entropy alloys (HEAs) based on tungsten (W) have emerged as promising candidates for plasma-facing components in future fusion reactors, owing to their excellent irradiation resistance. In this study, we construct an efficient machine-learned interatomic potential for the MoNbTaVW quinary system. This potential achieves computational speeds comparable to the embedded-atom method (EAM) potential, allowing us to conduct a comprehensive investigation of the primary radiation damage through molecular dynamics simulations. Threshold displacement energies (TDEs) in the MoNbTaVW HEA are investigated and compared with pure metals. A series of displacement cascade simulations at primary knock-on atom energies ranging from 10 to 150 keV reveal significant differences in defect generation and clustering between MoNbTaVW HEA and pure W. In HEAs, we observe more surviving Frenkel pairs (FPs) but fewer and smaller interstitial clusters compared to W, indicating superior radiation tolerance. We propose extended damage models to quantify the radiation dose in the MoNbTaVW HEA, and suggest that one reason for their enhanced resistance is subcascade splitting, which reduces the formation of interstitial clusters. Our findings provide critical insights into the fundamental irradiation resistance mechanisms in refractory body-centered cubic alloys, offering guidance for the design of future radiation-tolerant materials.


---
# Quantum machine learning for multiclass classification beyond kernel methods

## 超越核方法的多分类量子机器学习

Link: https://arxiv.org/abs/2411.02913

arXiv:2411.02913v1 Announce Type: cross 
Abstract: Quantum machine learning is considered one of the current research fields with immense potential. In recent years, Havl\'i\v{c}ek et al. [Nature 567, 209-212 (2019)] have proposed a quantum machine learning algorithm with quantum-enhanced feature spaces, which effectively addressed a binary classification problem on a superconducting processor and offered a potential pathway to achieving quantum advantage. However, a straightforward binary classification algorithm falls short in solving multiclass classification problems. In this paper, we propose a quantum algorithm that rigorously demonstrates that quantum kernel methods enhance the efficiency of multiclass classification in real-world applications, providing a clear quantum advantage. To demonstrate quantum advantage, we design six distinct quantum kernels within the quantum algorithm to map input data into quantum state spaces and estimate the corresponding quantum kernel matrices. The results from quantum simulations reveal that the quantum algorithm outperforms its classical counterpart in handling six real-world multiclass classification problems. Furthermore, we leverage a family of performance metrics to comprehensively evaluate the classification performance of the quantum algorithm. The results indicate that the quantum algorithm achieves satisfactory classification accuracy and excels in terms of precision, recall, and F1 score for macroaverage, microaverage, and weighted average methods.


---
# A scalable generative model for dynamical system reconstruction from neuroimaging data

## 用于从神经影像数据重建动态系统的可扩展生成模型

Link: https://arxiv.org/abs/2411.02949

arXiv:2411.02949v1 Announce Type: cross 
Abstract: Data-driven inference of the generative dynamics underlying a set of observed time series is of growing interest in machine learning and the natural sciences. In neuroscience, such methods promise to alleviate the need to handcraft models based on biophysical principles and allow to automatize the inference of inter-individual differences in brain dynamics. Recent breakthroughs in training techniques for state space models (SSMs) specifically geared toward dynamical systems (DS) reconstruction (DSR) enable to recover the underlying system including its geometrical (attractor) and long-term statistical invariants from even short time series. These techniques are based on control-theoretic ideas, like modern variants of teacher forcing (TF), to ensure stable loss gradient propagation while training. However, as it currently stands, these techniques are not directly applicable to data modalities where current observations depend on an entire history of previous states due to a signal's filtering properties, as common in neuroscience (and physiology more generally). Prominent examples are the blood oxygenation level dependent (BOLD) signal in functional magnetic resonance imaging (fMRI) or Ca$^{2+}$ imaging data. Such types of signals render the SSM's decoder model non-invertible, a requirement for previous TF-based methods. Here, exploiting the recent success of control techniques for training SSMs, we propose a novel algorithm that solves this problem and scales exceptionally well with model dimensionality and filter length. We demonstrate its efficiency in reconstructing dynamical systems, including their state space geometry and long-term temporal properties, from just short BOLD time series.


---
# Reweighting simulated events using machine-learning techniques in the CMS experiment

## 在CMS实验中使用机器学习技术对模拟事件进行重新加权

Link: https://arxiv.org/abs/2411.03023

arXiv:2411.03023v1 Announce Type: cross 
Abstract: Data analyses in particle physics rely on an accurate simulation of particle collisions and a detailed simulation of detector effects to extract physics knowledge from the recorded data. Event generators together with a GEANT-based simulation of the detectors are used to produce large samples of simulated events for analysis by the LHC experiments. These simulations come at a high computational cost, where the detector simulation and reconstruction algorithms have the largest CPU demands. This article describes how machine-learning (ML) techniques are used to reweight simulated samples obtained with a given set of model parameters to samples with different parameters or samples obtained from entirely different models. The ML reweighting method avoids the need for simulating the detector response multiple times by incorporating the relevant information in a single sample through event weights. Results are presented for reweighting to model variations and higher-order calculations in simulated top quark pair production at the LHC. This ML-based reweighting is an important element of the future computing model of the CMS experiment and will facilitate precision measurements at the High-Luminosity LHC.


---
# Chemifriction and Superlubricity: Friends or Foes?

## 化学和超润滑性: 朋友还是敌人？

Link: https://arxiv.org/abs/2411.03078

arXiv:2411.03078v1 Announce Type: cross 
Abstract: The mechanisms underlying chemifriction, i.e. the contribution of interfacial bonding to friction in defected twisted graphene interfaces are revealed using fully atomistic machine-learning molecular dynamics simulations. This involves stochastic events of consecutive bond formation and rupture, that are spatially separated but not necessarily independent. A unique shear-induced interlayer atomic transfer healing mechanism is discovered that can be harnessed to design a run-in procedure to restore superlubric sliding. This mechanism should be manifested as negative differential friction coefficients that are expected to emerge under moderate normal loads. A physically motivated phenomenological model is developed to predict the effects of chemifriction in experimentally relevant sliding velocity regimes. This allows us to identify a distinct transition between logarithmic increase and logarithmic decrease of frictional stress with increasing sliding velocity. While demonstrated for homogeneous graphene interfaces, a similar mechanism is expected to occur in other homogeneous or heterogeneous defected two-dimensional material interfaces.


---
# Extreme events at the onset of epileptic-like chimeras in small-world networks of FitzHugh-Nagumo neurons

## Fitzhugh-nagumo神经元的小世界网络中癫痫样嵌合体发作时的极端事件

Link: https://arxiv.org/abs/2411.03311

arXiv:2411.03311v1 Announce Type: cross 
Abstract: In this work, we investigate the dynamics of complex networks of FitzHugh-Nagumo excitable oscillators, focusing on the impact of coupling strength, network size, and randomness on their collective dynamics. Considering Watts-Strogatz small-world network connectivities, the system exhibits three distinct dynamical phases: chaotic, intermittent, and synchronized, with the intermittent phase displaying transient, epileptic-like chimera states. We analyse the transition to synchronisation by means of the master stability function, and show that peaks in the proportion of extreme events of synchronisation, which correlate with the behaviour of the largest Lyapunov exponent of the system, precede the transitions between the distinct dynamical regimes and mark the onset of epileptic-like chimera states. Our findings contribute to a broader understanding of synchronisation in excitable systems real neural networks and offer insights into the conditions that may lead to pathological epileptic-like states. Furthermore, we discus the potential use of extreme events to study real neural data.


---
# DeFault: Deep-learning-based Fault Delineation Using the IBDP Passive Seismic Data at the Decatur CO2 Storage Site

## 默认: 在Decatur CO2存储站点使用IBDP被动地震数据进行基于深度学习的断层描绘

Link: https://arxiv.org/abs/2311.04361

arXiv:2311.04361v3 Announce Type: replace 
Abstract: The carbon capture, utilization, and storage (CCUS) framework is an essential component in reducing greenhouse gas emissions, with its success hinging on the comprehensive knowledge of subsurface geology and geomechanics. Passive seismic event relocation and fault detection serve as indispensable tools, offering vital insights into subsurface structures and fluid migration pathways. Accurate identification and localization of seismic events, however, face significant challenges, including the necessity for high-quality seismic data and advanced computational methods. To address these challenges, we introduce a novel deep learning method, DeFault, specifically designed for passive seismic source relocation and fault delineating for passive seismic monitoring projects. By leveraging data domain-adaptation, DeFault allows us to train a neural network with labeled synthetic data and apply it directly to field data. Using DeFault, the passive seismic sources are automatically clustered based on their recording time and spatial locations, and subsequently, faults and fractures are delineated accordingly. We demonstrate the efficacy of DeFault on a field case study involving CO2 injection related microseismic data from the Decatur, Illinois area. Our approach accurately and efficiently relocated passive seismic events, identified faults and aided in the prevention of potential geological hazards. Our results highlight the potential of DeFault as a valuable tool for passive seismic monitoring, emphasizing its role in ensuring CCUS project safety. This research bolsters the understanding of subsurface characterization in CCUS, illustrating machine learning's capacity to refine these methods. Ultimately, our work bear significant implications for CCUS technology deployment, an essential strategy in combating climate change.


---
# Polarimetric compressed sensing with hollow, self-assembled diffractive films

## 具有中空自组装衍射膜的极化压缩传感

Link: https://arxiv.org/abs/2407.14722

arXiv:2407.14722v2 Announce Type: replace 
Abstract: Sensing light's polarization and wavefront direction enables surface curvature assessment, material identification, shadow differentiation, and improved image quality in turbid environments. Traditional polarization cameras utilize multiple sensor measurements per pixel and polarization-filtering optics, which result in reduced image resolution. We propose a nanophotonic pipeline that enables compressive sensing and reduces the sampling requirements with a low-refractive-index, self-assembled optical encoder. These nanostructures scatter light into lattice modes, which encode the wavefront direction and the polarization ellipticity in the linearly-polarized components of the diffracted, interference patterns. Combining optical encoders with a neural network, the system predicts pointing and polarization when the interference patterns are adequately sampled. A comparison of ``ordered'' and ``random'' optical encoders shows that the latter both blurs the interference patterns and achieves higher resolution. Our work centers on the unexpected modulation and spatial multiplexing of incident light polarization by self-assembled hollow nanocavity arrays as a class of materials distinct from traditional metasurfaces that will not only enable encoding for polarization and optical computing but also for compressed sensing and imaging.


---
# Waveguide-multiplexed photonic matrix-vector multiplication processor using multiport photodetectors

## 使用多端口光电探测器的波导复用光子矩阵矢量乘法处理器

Link: https://arxiv.org/abs/2410.05956

arXiv:2410.05956v3 Announce Type: replace 
Abstract: The slowing down of Moore's law has driven the development of application-specific processors for deep learning. Analog photonic processors offer a promising solution for accelerating matrix-vector multiplications (MVMs) in deep learning by leveraging parallel computations in the optical domain. Intensity-based photonic MVM processors, which do not utilize the phase information of light, are appealing due to their simplified operations. However, existing intensity-based schemes for such processors often employ wavelength multiplexing or mode multiplexing, both of which have limited scalability due to high insertion loss or wavelength crosstalk. In this work, we present a scalable intensity-based photonic MVM processor based on the concept of waveguide multiplexing. This scheme employs multiport photodetectors (PDs) to sum the intensities of multiple optical signals, eliminating the need for multiple wavelengths or modes. A 16-port Ge PD with a 3 dB bandwidth of 11.8 GHz at a bias voltage of -3 V is demonstrated, and it can be further scaled up to handle 250 ports while maintaining a 6.1 GHz operation bandwidth. A 4 $\times$ 4 circuit fabricated on a Si-on-insulator (SOI) platform is used to perform MVMs in a 3-layer neural network designed for classifying Iris flowers, achieving a classification accuracy of 93.3%. Furthermore, the performance of large-scale circuits in a convolutional neural network (CNN) for Fashion-MNIST is simulated, resulting in a classification accuracy of 90.53%. This work provides a simplified and scalable approach to photonic MVM, laying a foundation for large-scale and multi-dimensional photonic matrix-matrix multiplication in optical neural networks.


---
# Extreme Value Statistics of Community Detection in Complex Networks with Reduced Network Extremal Ensemble Learning (RenEEL)

## 具有简化网络极值集成学习 (RenEEL) 的复杂网络社区检测的极值统计

Link: https://arxiv.org/abs/2411.00977

arXiv:2411.00977v2 Announce Type: replace 
Abstract: Arguably, the most fundamental problem in Network Science is finding structure within a complex network. One approach is to partition the nodes into communities that are more densely connected than one expects in a random network. "The" community structure then corresponds to the partition that maximizes Modularity, an objective function that quantifies this idea. Finding the maximizing partition, however, is a computationally difficult, NP-Complete problem. We explore using a recently introduced machine-learning algorithmic scheme to find the structure of benchmark networks. The scheme, known as RenEEL, creates an ensemble of $K$ partitions and updates the ensemble by replacing its worst member with the best of $L$ partitions found by analyzing a simplified network. The updating continues until consensus is achieved within the ensemble. We perform an empirical study of three real-world networks to explore how the Modularity of the consensus partition depends on the values of $K$ and $L$ and relate the results to the extreme value statistics of record-breaking. We find that increasing $K$ is generally more effective than increasing $L$ for finding the best partition.


---
# A versatile framework for attitude tuning of beamlines at advanced light sources

## 一种用于高级光源的光束线姿态调整的通用框架

Link: https://arxiv.org/abs/2411.01278

arXiv:2411.01278v2 Announce Type: replace 
Abstract: Aside from regular beamline experiments at light sources, the preparation steps before these experiments are also worth systematic consideration in terms of automation; a representative category in these steps is attitude tuning, which typically appears in names like beam focusing, sample alignment etc. With the goal of saving time and manpower in both writing and using in mind, a Mamba-based attitude-tuning framework is created. It supports flexible input/output ports, easy integration of diverse evaluation functions, and free selection of optimisation algorithms; with the help from Mamba's infrastructure, machine learning (ML) and artificial intelligence (AI) technologies can also be readily integrated. The tuning of a polycapillary lens and of an X-ray emission spectrometer are given as examples for the general use of this framework, featuring powerful command-line interfaces (CLIs) and friendly graphical user interfaces (GUIs) that allow comfortable human-in-the-loop control. The tuning of a Raman spectrometer demonstrates more specialised use of the framework with customised optimisation algorithms. With similar applications in mind, our framework is estimated to be capable of fulfilling a majority of attitude-tuning needs. Also reported is a virtual-beamline mechanism based on easily customisable simulated detectors and motors, which facilitates both testing for developers and training for users.


---
# Predicting the Temperature-Dependent CMC of Surfactant Mixtures with Graph Neural Networks

## 用图神经网络预测表面活性剂混合物的温度相关CMC

Link: https://arxiv.org/abs/2411.02224

arXiv:2411.02224v2 Announce Type: replace 
Abstract: Surfactants are key ingredients in foaming and cleansing products across various industries such as personal and home care, industrial cleaning, and more, with the critical micelle concentration (CMC) being of major interest. Predictive models for CMC of pure surfactants have been developed based on recent ML methods, however, in practice surfactant mixtures are typically used due to to performance, environmental, and cost reasons. This requires accounting for synergistic/antagonistic interactions between surfactants; however, predictive ML models for a wide spectrum of mixtures are missing so far. Herein, we develop a graph neural network (GNN) framework for surfactant mixtures to predict the temperature-dependent CMC. We collect data for 108 surfactant binary mixtures, to which we add data for pure species from our previous work [Brozos et al. (2024), J. Chem. Theory Comput.]. We then develop and train GNNs and evaluate their accuracy across different prediction test scenarios for binary mixtures relevant to practical applications. The final GNN models demonstrate very high predictive performance when interpolating between different mixture compositions and for new binary mixtures with known species. Extrapolation to binary surfactant mixtures where either one or both surfactant species are not seen before, yields accurate results for the majority of surfactant systems. We further find superior accuracy of the GNN over a semi-empirical model based on activity coefficients, which has been widely used to date. We then explore if GNN models trained solely on binary mixture and pure species data can also accurately predict the CMCs of ternary mixtures. Finally, we experimentally measure the CMC of 4 commercial surfactants that contain up to four species and industrial relevant mixtures and find a very good agreement between measured and predicted CMC values.


---
# Strategic Data Re-Uploads: A Pathway to Improved Quantum Classification Data Re-Uploading Strategies for Improved Quantum Classifier Performance

## 用于提高量子分类器性能的数据重新上传策略

Link: https://arxiv.org/abs/2405.09377

arXiv:2405.09377v2 Announce Type: replace-cross 
Abstract: Quantum machine learning (QML) is a promising field that explores the applications of quantum computing to machine learning tasks. A significant hurdle in the advancement of quantum machine learning lies in the development of efficient and resilient quantum classifiers capable of accurately mapping input data to specific, discrete target outputs. In this paper, we propose a novel approach to improve quantum classifier performance by using a data re-uploading strategy. Re-uploading classical information into quantum states multiple times can enhance the accuracy of quantum classifiers. We investigate the effects of different cost functions, such as fidelity and trace distance, on the optimization process and the classification results. We demonstrate our approach to two classification patterns: a linear classification pattern (LCP) and a non-linear classification pattern (NLCP). We evaluate the efficacy of our approach by benchmarking it against four distinct optimization techniques: L-BFGS-B, COBYLA, Nelder-Mead, and SLSQP. Additionally, we study the different impacts of fixed datasets and random datasets. Our results show that our approach can achieve high classification accuracy and robustness and outperform the existing quantum classifier models.


---
# Exploration of crystal chemical space using text-guided generative artificial intelligence

## 基于文本引导的生成式人工智能的晶体化学空间探索

Link: https://dx.doi.org/10.26434/chemrxiv-2024-rw8p5?rft_dat=source%3Ddrss

The vastness of chemical space presents a long-standing challenge for the exploration of new compounds with pre-determined properties. In materials science, crystal structure prediction has become a mature tool for mapping from composition to structure based on global optimisation techniques. Generative artificial intelligence (AI) now offers the means to efficiently navigate larger regions of crystal chemical space informed by structure-property datasets of materials. We introduce a model, named Chemeleon, designed to generate chemical compositions and crystal structures by learning from both textual descriptions and three-dimensional structural data. The model employs denoising diffusion techniques for compound generation using textual inputs aligned with structural data via cross-modal contrastive learning. The potential of this approach is demonstrated for multi-component compound generation, including the prediction of stable phases in the Li-P-S-Cl quaternary space of relevance to solid-state batteries. Our work highlights the potential of bridging geometric and linguistic data to unlock approaches to materials design.


---
# Spectro: A multi-modal approach for molecule elucidation using IR and NMR data

## Spectro: 使用IR和NMR数据进行分子阐明的多模态方法

Link: https://dx.doi.org/10.26434/chemrxiv-2024-37v2j?rft_dat=source%3Ddrss

Molecular structure elucidation is a crucial but fundamentally challenging step in the characterization of materials given the large number of possible structures. Here, we introduce Spectro, an innovative multi-modal approach for molecular elucidation that combines $\CNMR$ and $\HNMR$ NMR data with IR. Spectro translates the embedded representations of the spectra into molecular structures using the SELFIES notation. We employed a vision model for the embedded representation of the IR data, which was pretrained to detect relevant functional group peaks in the IR spectra achieving an F1 score of 91\%. For NMR data, we utilized LLM2Vec, treating the NMR spectra as text.  This integration of multiple spectroscopic techniques allows Spectro to achieve an overall test accuracy of 93\% when trained jointly with the vision model for the IR spectra, and 82\% when trained with fixed embeddings. Our approach demonstrates the potential of multi-modal learning in tackling complex molecular characterization tasks.


---
# MIND-HOPE: Multilingual Identification of Nuanced Dimensions of HOPE

## 心灵希望: 希望细微差别的多语言识别

Link: https://www.researchsquare.com/article/rs-5338649/latest

Hope plays a crucial role in human psychology, yet research on its expression and detection across languages is limited. This study addresses this gap by developing the first multiclass hope speech detection datasets for Spanish and German. The research includes a comprehensive review of existing datasets and techniques and employs various learning approaches&mdash;traditional machine learning, deep learning, and transformer-based models&mdash;to evaluate their effectiveness. The new datasets significantly advance hope speech detection by incorporating diverse linguistic contexts. Comparative analyses reveal that transformer models, such as xlm-roberta-base for Spanish and uklfr/gottbert-base for German, achieve superior performance with F1 scores of 0.6801 and 0.6977, respectively, in multiclass detection tasks compared to the rest of the models. Multilingual transformers are also promising in cross-lingual applications but require further refinement. This study sets the groundwork for future advancements by enhancing dataset diversity and model performance, with future research focusing on refining multilingual models and expanding to various languages.


---
# AdditiveGDL: Generative deep learning for predicting local thermal distributions in metal 3D-printed layers

## AdditiveGDL: 用于预测金属3d打印层中局部热分布的生成式深度学习

Link: https://www.researchsquare.com/article/rs-5257658/latest

In metal additive manufacturing, comprehending the intricate thermal dynamics during the printing process is paramount. These dynamics have far-reaching effects on various critical aspects including microstructure and mechanical properties, fatigue life, residual stresses, dimensional accuracy, shape integrity, and surface quality. &amp;nbsp;Additionally, the scan strategy &amp;nbsp;significantly impacts heat accumulation, especially at geometric features with sharp corners, overhangs, and thin walls. &amp;nbsp;Thus, predicting heat distribution given the scan strategy becomes crucial. While numerical simulations using finite element methods are common, they can be computationally prohibitive for complex parts. &amp;nbsp;In this paper, we propose a &amp;nbsp;method that leverages constrained generative neural networks to predict the local thermal distribution given the laser toolpath. By identifying critical regions of heat accumulation, we can optimize geometry, and scan paths, ultimately enhancing the quality and reliability of 3D-printed metal components. &amp;nbsp;Results &amp;nbsp;show that &amp;nbsp;generative deep learning offers &amp;nbsp;an alternative approach to predicting the thermal field of printed layers efficiently.


---
# Improvement of Generalization Performance of Diagnostic System for Drill Bit Abnormality in Rotary Percussion Drilling with Grad-CAM

## Grad-cam旋转冲击钻井钻头异常诊断系统泛化性能的提高

Link: https://www.researchsquare.com/article/rs-5162718/latest

Rotary percussion drills, specifically top hammer types, are essential in resource extraction and exploration. These drills frequently suffer damage at the drill button, necessitating effective decision-making to address issues. Traditionally, on-site operators relied on intuition, but recent advancements promote automated systems to enhance safety and failure detection in challenging mining environments. This study employs Convolutional Neural Networks (CNN) to develop an automated system for detecting drill bit abnormalities. In a prior investigation, a CNN model was established to discern normal functioning and four distinct abnormalities. To enhance generalization performance, researchers endeavored to create a filter using Gradient-weighted Class Activation Mapping (Grad-CAM), an inverse analysis technique. However, challenges arose as the frequency bands contributing significantly to judgments varied among the five identified states. In response, this study adopts a refined approach, constructing a model that categorizes drill performance into two states: normal and abnormal. Leveraging Grad-CAM, the research identifies the frequency band with a high contribution rate to judgment and applies a filter tailored to this specific band. Notably, by training the CNN model to recognize differences in rock types, the resulting model exhibits adaptability to changes in drill bit types, achieving an accuracy rate of 83.3%.


---
# A Covert, Secure and Energy-Efficient Communication Protocol Based on Statistical Machine Learning in Multi-Domain Communication Applications

## 多域通信应用中基于统计机器学习的隐蔽、安全、节能的通信协议

Link: https://www.researchsquare.com/article/rs-5342581/latest

In recent decades, multi-domain communications (air-water) have garnered significant attention from both scientific and civil communities due to their diverse impacts and applications. However, in addition to security challenges, these types of communications face limitations regarding direct cross-medium communication, transmission capacity, transmission range, and energy consumption due to water properties and reflections occurring at the interface between the two mediums. While various solutions have been proposed to address these challenges, the majority of them are either not energy-efficient or fail to guarantee communication security in specific applications. Therefore, in this research, we propose a secure covert communication protocol with energy efficiency for multi-domain communication applications to address the aforementioned challenges. In this protocol, to enhance security and reduce bandwidth consumption, data is sampled based on its entropy and then simultaneously compressed and encrypted according to its sparsity level. Next, the resulting output is modulated onto amplified spontaneous emission (ASE) noise, hidden, and spread out over time using a chirped fiber Bragg grating (CFBG). The signal is then transmitted through a wide-field optical system. Here, we utilize an array of ultrasonic sensors and a prediction algorithm to calculate the optimal water surface impact point. We also use OOK pulse-based modulation combined with laser diode switching to reduce energy consumption and increase data transmission capacity. Simulation results demonstrate that the proposed model, compared to previous methods, not only enhances security but also reduces energy consumption and increases transmission capacity.


---
# A Public health wound: health and work among children engaged in worst forms of child labour in the informal sector in Dhaka, Bangladesh: a retrospective analysis of M&eacute;decins Sans Fronti&egrave;res Occupational health data from 2014 to 2023.

## 公共卫生创伤: 孟加拉国达卡非正规部门从事最恶劣形式童工的儿童的健康和工作: 对2014年2023年的无国界医生职业健康数据的回顾性分析。

Link: https://www.researchsquare.com/article/rs-5313328/latest

Background: Bangladesh has the second highest burden of child labour in South Asia. The informal sector employs most of the children however, evidence and data on health including injuries and place of work for children are limited. &amp;nbsp;As the deadline for the Sustainable Development Goals to end child labour by 2025 is approaching, it is paramount to document the impact of child labour on health. This study aims to contribute to this knowledge gap by presenting medical data from occupational health clinics set up by M&eacute;decins Sans Fronti&egrave;res (MSF) in an urban area of Dhaka, Bangladesh.
Methods: We did a retrospective analysis of health care records of children attending MSF occupational health clinics between February 2014 and December 2023 in Dhaka. We stratified the analysis by gender and age (&amp;lt;14 years and &ge;14-&amp;lt;18 years). We looked at morbidities according to type of factory, whether children reported working with machinery, and examined nutritional and mental health (2018-2023) status.
Results: Over the study period, there were 10,200 occupational health consultations among children &amp;lt;18 years, of which 4945 were new/first time consultations. The average age of children attending their first consultation was 14.7 years, of which 61% were male. Fifteen percent reported living inside the factory. Musculoskeletal (26%) and dermatological (20%) were the most identified conditions, and 7.5% of consultations were for work-related injuries. Almost all children reported operating machinery. A higher proportion of male children had injuries (11% vs 2.5% in girls). &amp;nbsp;Children working in metal factories accounted for most injuries (65%). &amp;nbsp;Mood-related disorders accounted for 86% of the 51 mental health consultations. Half of all children were malnourished with higher levels in boys and those &amp;lt;14 years. Specific gender and age vulnerabilities were documented.
Conclusions
Findings suggest that children face hazardous realities, engaged in the worst form of labour, bearing important morbidity and injury burden. Weak enforcement of labour regulations in the informal sector ultimately enables child exploitation and suffering. &amp;nbsp;Further research is essential to explore the intersectional dimensions of child labour, such as gender, age, and disability, to inform interventions aimed at eliminating child labour and its severe consequences in this and similar contexts.


---
# Technical assessment of 3D-printed spur gears produced from recycled PLA

## 回收PLA生产的3d打印正齿轮的技术评估

Link: https://www.researchsquare.com/article/rs-5284212/latest

Plastic gears are primarily utilised in manufacturing and automotive industries due to their quiet operation, resistance to corrosion, and lightweight characteristics. Traditionally, injection moulding (IM) has been the preferred method for producing gears. However, the high cost associated with IM has made additive manufacturing (otherwise known as &amp;ldquo;3D printing&amp;rdquo;) an increasingly attractive alternative. This study investigated the potential benefits of 3D-printed spur gears made from three distinct types of polylactic acid (PLA) materials: recycled PLA (rPLA), blended PLA, and virgin PLA (vPLA). Gears with varying tooth counts were designed based on commercially available models and printed using optimised printing parameters, including layer height, infill density and nozzle temperature. The performance of polymer gears depends on several engineering characteristics, including wear resistance, running load, speed, and operating temperature. To assess these factors, sound, temperature, wear loss, wear rate, and service life were measured using a custom-built testing machine at rotational speeds of 500, 1000, and 1500 rpm under a torque of 1.5 Nm. The results were compared with those of injection-moulded PLA and nylon gears under the same testing conditions. The experimental findings revealed that the rPLA gears exhibited the poorest performance across all measured metrics. In contrast, the blended PLA gears demonstrated wear characteristics similar to those of the vPLA gears, although they still fell short of the performance of the injection-moulded gears.


---
# Sequestration of carbon dioxide from a gas sweetening plant in an oilfield via integrated microalgal cultivation with wastewater treatment; A technical appraisal and economic feasibility evaluation.

## 通过将微藻培养与废水处理相结合，从油田的气体脱硫厂中封存二氧化碳; 技术评估和经济可行性评估。

Link: https://www.researchsquare.com/article/rs-5380165/latest

Carbon capture and storage (CCS) is promoted a promising decarbonization strategy. It is argued to be a potential solution for Egypt&rsquo;s greenhouse gas emissions which have substantially grown over the past three decades. A widely recognized method of CCS is biological storage via microalgal cultivation. However, most CCS applications in the oil sector are geologic storage and there is no single biological or geologic storage project in Egypt. Additionally, there is a severe lack of research on microalgal applications for CO2&amp;nbsp;storage in Egypt. That is why this research aims to build a case study for a pure source of CO2&amp;nbsp;emitted from a gas sweetening plant in Bapetco oil company in the western desert in Egypt. It is a preliminary design for an integrated microalgal cultivation project with wastewater treatment capability for the sake of carbon sequestration and biomass production. To do so, this paper performed a laboratory experiment to examine the tolerability of two microalgal species for being exposed to a CO2&amp;nbsp;source. Based on the results of this experiment, a technical model was proposed to select the required machinery and infrastructure. Finally, it proposed a financial model of the capital and operating costs, loan repayment, and net present value with sensitivity analysis. The findings showed that selling biomass as a final product was uneconomic enough as it generated negative IRR and NPV. It also showed two strikingly interesting results: species with high CO2tolerability are not recommended, and carbon pricing is of little help in funding microalgal projects compared to biomass productivity. The originality of this research comes from its adoption of biological storage in the oil industry, equipped with technical and financial models.&amp;nbsp;&amp;nbsp;


---
# Analysis of the Dynamic Behavior of Onboard Rotors in Non-Linear Regimes Under the Influence of Parametric Uncertainties

## 参数不确定性影响下非线性状态下机载转子的动态行为分析

Link: https://www.researchsquare.com/article/rs-5313495/latest

In recent decades, a significant advance in the understanding of the dynamic behavior of rotors has been observed, including the capacity to model and forecast the physical behavior of these systems. The emergence of novel applications seeks to optimize performance and cost-effectiveness maintaining safe operating conditions and pushing rotating systems to their limits. Therefore, this contribution presents a combined numerical and experimental investigation of the nonlinear behavior exhibited by rotating systems subjected to base excitations. A comprehensive model incorporates nonlinear behavior resulting from large displacements as derived from the Lagrange's equations and the finite element (FE) method. The deterministic model is extended to encompass bearings with stochastic stiffness. A rotating machine with a flexible shaft, a rigid disk, and supported by two bearings is evaluated. A dedicated test bench was used to compare the vibration responses obtained by using the implemented mathematical model with the experimental measurements. The obtained results demonstrate the representativeness of the considered FE model.


---
# SELF-QMM: An Self-directed Model Based-on Extended Q-Learning and Markov Model to Estimate MTTF in Multiprocessor Platform of Embedded Systems

## Self-qmm: 基于扩展Q学习和Markov模型的自导向模型，用于估计嵌入式系统多处理器平台中的MTTF

Link: https://www.researchsquare.com/article/rs-5327542/latest

Computers, multiprocessor platforms on a chip (MPSoC) and embedded systems have many applications in the military, security, medical, and space industries. Improving reliability and trust in these systems is very important. By improving reliability in multiprocessor and embedded systems, their efficiency and performance will increase. Multi-processor platforms in embedded systems (EMMPSoC) can perform sensitive and critical tasks by communicating with each other; But in the execution process, they may encounter errors and problems in the processing. The existence of errors and problems in the execution process, temperature and heat generation, high energy consumption, unfavorable execution time, etc. in these systems leads to a decrease in reliability and the occurrence of irreparable events. One of the most important challenges in MPSoC is improving reliability. The reliability of these systems can be increased by estimating the Mean Time to Failure (MTTF). In this research, a Self-directed Model based-on Clipping Double Q-Learning (CDQL) and extended Markov model (EMM) and meta-heuristic MUO algorithm (Self -QMM) to estimate the average failure time in EMMPSoC systems. has been raised The CDQL has been used to predict the critical time in MPSoC systems and the developed Markov model has been used to select the appropriate processor. By simulating the proposed Self-QMM model, it has been improved that the energy consumption in the Self-QMM model is 50, 27 and 14 kJ, respectively, compared with the latest proposed methods such as FIS, FNN-NSGA-II and MUO method, the temperature production rate and temperatures have improved by 45.4, 22.9 and 9.9 degrees Celsius and the execution time by 0.16 minutes (9.6 s), 0.09 minutes (5.4 s) and 0.08 minutes (4.8 s).


---
# Synthetic CT generation from CBCT and MRI using the StarGAN in Pelvic Region

## 在骨盆区域使用StarGAN从CBCT和MRI生成合成CT

Link: https://www.researchsquare.com/article/rs-5079041/latest

Background This study evaluates StarGAN, a deep learning model designed to generate synthetic CT (sCT) images from MRI and CBCT data via a single model. The goal is to provide accurate Hounsfield Unit (HU) data for dose calculation and compare StarGAN's performance to CycleGAN.Methods StarGAN and CycleGAN were trained on a pelvic cancer dataset consisting of 23 training, 5 validation, and 5 testing cases. The evaluation involved qualitative and quantitative analyses, with a focus on synthetic image quality and dose distribution calculations.Results For sCT generated from CBCT, the StarGAN demonstrated superior anatomical preservation in qualitative evaluations. Quantitatively, CycleGAN exhibited lower mean absolute error (MAE) values for body (42.77&amp;thinsp;&amp;plusmn;&amp;thinsp;4.28 HU), soft tissue (36.97&amp;thinsp;&amp;plusmn;&amp;thinsp;3.87 HU), and bone (138.17&amp;thinsp;&amp;plusmn;&amp;thinsp;20.29), whereas StarGAN presented higher MAE values (50.81&amp;thinsp;&amp;plusmn;&amp;thinsp;5.16 HU, 44.57&amp;thinsp;&amp;plusmn;&amp;thinsp;5.14 HU, 153.36&amp;thinsp;&amp;plusmn;&amp;thinsp;27.67 HU, respectively). Dosimetric evaluations revealed a mean dose difference (DD) within 2% for planning the target volume (PTV) and body, with a gamma passing rate (GPR)&amp;thinsp;&amp;gt;&amp;thinsp;90% under 2%/2 mm criteria. For sCT generated from MRI, qualitative evaluation also favored StarGAN's anatomical preservation. The CycleGAN resulted in lower MAEs (79.77&amp;thinsp;&amp;plusmn;&amp;thinsp;13.96 HU, 70.14&amp;thinsp;&amp;plusmn;&amp;thinsp;16.26 HU, and 253.62&amp;thinsp;&amp;plusmn;&amp;thinsp;30.85 HU), whereas the StarGAN resulted in higher MAEs (94.65&amp;thinsp;&amp;plusmn;&amp;thinsp;7.41 HU, 80.75&amp;thinsp;&amp;plusmn;&amp;thinsp;9.60 HU, and 353.58&amp;thinsp;&amp;plusmn;&amp;thinsp;34.85 HU). Both models achieved a mean DD within 2% in the PTV and body, and GPR&amp;thinsp;&amp;gt;&amp;thinsp;90%.Conclusion While CycleGAN exhibited superior quantitative metrics, StarGAN was better in terms of anatomical preservation, highlighting its potential for sCT generation in radiotherapy.


---
# A Hybrid Ontology-Based Feature SelectionFramework for Enhancing Predictive Accuracy inRegression Models

## 基于混合本体的特征选择框架，可提高回归模型的预测精度

Link: https://www.researchsquare.com/article/rs-5325338/latest

Predicting firefighter interventions presents a complex challenge due to the high dimensionality and intricacy of the data. While machine learning (ML) technologies offer promising solutions, ineffective feature selection can significantly hinder model performance and reduce predictive accuracy. This study proposes a hybrid feature selection approach that combines ontology-based reasoning with traditional ML techniques to enhance the predictive accuracy of regression models for firefighter interventions. We utilized three machine learning algorithms&amp;mdash;XGBoost, LightGBM, and Long Short-Term Memory (LSTM) networks&amp;mdash;across two feature selection strategies: one solely based on ML algorithms, and another using a hybrid approach that integrates ontology-based centrality metrics, such as degree, closeness, and betweenness, with ML techniques. A domain-specific ontology was developed to capture key environmental, temporal, and intervention-related factors, improving the feature selection process for more interpretable and contextually relevant features. The results clearly show that the hybrid feature selection approach consistently outperforms the ML-only method. For the XGBoost model, the hybrid approach resulted in an R2 of 0.976, compared to 0.97 for the ML-only method. The LSTM model also saw improvements, with the hybrid approach achieving an R2 of 0.964, compared to 0.96 for ML-only. Similarly, for the LightGBM model, the hybrid approach produced an R2 of 0.975, compared to 0.97 for ML-only. This research underscores the significant advantages of combining ontology-based feature selection with ML, leading to improved predictive accuracy and better model interpretability, particularly in high-dimensional data environments.


---
# Hitchlearning: A general free-lunch paradigm for single-image enhancement by unifying inference and training

## Hitchlearning: 通过统一推理和训练来增强单个图像的通用免费午餐范例

Link: https://www.researchsquare.com/article/rs-5346989/latest

Deep learning (DL) has ushered in a suite of promising tools for image processing, including denoising (DN), deblurring (DB), and super-resolution (SR). However, traditional DL methods assume independent and identically distributed (i.i.d.) data for model training and inference, which does not hold in practice due to factors such as sample variation, variability in imaging conditions, and temporal effects in living cells. This discrepancy prevents models, even when trained on extensive datasets, from reaching their full performance potential during inference. This practical issue, unfortunately, is still unexplored. To address this issue, drawing inspiration from the way biological intelligence adapts through past experiences to shape future learning, we introduce HitchLearning&mdash;a revolutionary paradigm that breaks away from the conventional separation of training and inference. In HitchLearning, we leverage a single inference image to unsupervisedly optimize the model by aligning the training images with it. Subsequently, we employ this optimized model for processing individual inference images. This approach allows the model to adapt to the specific characteristics of each inference image, leading to improved results in a manner reminiscent of a "free lunch." We conducted a thorough evaluation of our method across three distinct tasks within both supervised and unsupervised frameworks, utilizing four diverse datasets. Compared to conventional training methods, HitchLearning demonstrated average performance increases of 4.34 dB, 4.08 dB, and 0.54 dB for the DN, DN, and SR tasks, respectively. The experimental results unequivocally demonstrate that our algorithm offers a universally applicable and cost-free optimization solution for processing image and can be used in other fields as well.


---
# Inter-Patch Spatio-Temporal Relation Prediction for Video Anomaly Detection

## 用于视频异常检测的片间时空关系预测

Link: https://www.researchsquare.com/article/rs-5329540/latest

Video Anomaly Detection (VAD), aiming to identify abnormalities within a specific context and timeframe, is crucial for intelligent Video Surveillance Systems. While recent deep learning-based VAD models have shown promising results by generating high-resolution frames, they often lack competence in preserving detailed spatial and temporal coherence in video frames. To tackle this issue, we propose a self-supervised learning approach for VAD through an inter-patch relationship prediction task. Specifically, we introduce a two-branch vision transformer network designed to capture deep visual features of video frames, which can address spatial and temporal dimensions responsible for modeling appearance and motion patterns, respectively. The inter-patch relationship in each dimension is decoupled into inter-patch similarity and the order information of each patch. To mitigate memory consumption, we convert the order information prediction task into a multi-label learning problem, and the inter-patch similarity prediction task into a inter-patch distance matrix regression problem. Comprehensive experiments demonstrate the effectiveness of our method, surpassing pixel-generation-based methods by a significant margin across three public benchmarks. Additionally, our approach outperforms other self-supervised learning-based methods.


---
# Sustainability in Professional Development: Manifestations and Reliefs of Technology Anxiety among Mandarin Chinese Teachers in the Era of Digital Intelligence

## 专业发展的可持续性: 数字智能时代汉语教师技术焦虑的表现与缓解

Link: https://www.researchsquare.com/article/rs-5344781/latest

With the rapid development and practical application of digital intelligence technology in many fields of human society, the integration trend of digital intelligence technology with Mandarin Chinese education is inevitable. Digital intelligence technology seems to have also placed a psychological and physical burden on teachers when providing them with convenience. Focusing on the technology anxiety of Mandarin Chinese teachers, this research discussed the manifestations and generation of their technology anxiety in the era of digital intelligence through in-depth interviews with 25 Mandarin Chinese teachers and classroom observations. The results indicated that the technology anxiety of Mandarin Chinese teachers manifested as cognitive dilemma anxiety caused by the distorted cognition of technology and technology iteration, technology-induced obstacle anxiety caused by invisible technology obstacles and the reform of teaching empowered by technology, career development anxiety caused by the weak renewal of teachers&amp;rsquo; technology knowledge and skills and deviation of intelligent education expectations, and ethical security anxiety caused by anomie of artificial intelligence and technology risk prevention and management. This irrational psychological state was the result of interactions between Mandarin Chinese teachers and technology influenced by a series of cognitive, emotional, and social factors. On the basis of this, the following suggestions for relieving such anxiety include exploring and adopting diverse measures to help teachers hold positive technology cognition and value-evaluation viewpoints, taking the cultivation of intelligent education knowledge and practical ability as the core to improve teachers' intelligent education literacy, exploring a new model of human‒machine collaborative education and bringing teachers' professional advantages to full play in the era of digital intelligence, and providing guidance for intelligent education technology to instruct teachers to correctly understand and address ethical security problems derived from technology.


---
# Discovering hidden physics using ML-based multimodal super-resolution measurement and its application to fusion plasmas

## 基于ML的多模态超分辨率测量发现隐藏物理及其在融合等离子体中的应用

Link: https://www.researchsquare.com/article/rs-4646544/latest

A non-linear complex system governed by multi-spatial and multi-temporal physics scales cannot be fully understood with a single diagnostic, as each provides only a partial view and much information is lost during data extraction. Combining multiple diagnostics also results in imperfect projections of the system's physics. By identifying hidden inter-correlations between diagnostics, we can leverage mutual support to fill in these gaps, but uncovering these inter-correlations analytically is too complex.
We introduce a groundbreaking machine learning methodology to address this issue. Our multimodal approach generates super-resolution data encompassing multiple physics phenomena, capturing detailed structural evolution and responses to perturbations previously unobservable. This methodology addresses a critical problem in fusion plasmas: the Edge Localized Mode (ELM), a plasma instability that can severely damage reactor walls. One method to stabilize ELM is using resonant magnetic perturbation to trigger magnetic islands. However, low spatial and temporal resolution of measurements limits the analysis of these magnetic islands due to their small size, rapid dynamics, and complex interactions within the plasma.
With super-resolution diagnostics, we can experimentally verify theoretical models of magnetic islands for the first time, providing unprecedented insights into their role in ELM stabilization. This advancement aids in developing effective ELM suppression strategies for future fusion reactors like ITER and has broader applications, potentially revolutionizing diagnostics in fields such as astronomy, astrophysics, and medical imaging.


---
# Considerations for adapting digital competencies and training approaches to the public health workforce: An interpretive description of practitioners&rsquo; perspectives in Canada

## 适应数字能力和培训方法对公共卫生人力的考虑: 对加拿大从业者观点的解释性描述

Link: https://www.researchsquare.com/article/rs-5320781/latest

Background Widespread digital transformation necessitates developing digital competencies for public health practice. We explored public health practitioners' experiences and perspectives on adapting digital competencies and training recommendations for Canada.Methods Between November and December 2023, we conducted an interpretive description using four focus groups with 19 public health practitioners in regional and federal health authorities across Canada, with at least 3 years&amp;rsquo; experience in current roles and experience using digital technologies in practice. We explored practitioners&amp;rsquo; experiences using digital technologies and sought their opinions on how digital competency recommendations previously identified could be adapted to Canada&amp;rsquo;s context. We analyzed verbatim transcripts using reflexive thematic analysis.Results We identified three main themes: a) public health systems must evolve to support new digital competencies; b) strengthen the basics before extending towards digital competencies; and c) focus on building general digital competencies with options for specialization where necessary. Findings emphasized matching workforce digital competencies to public health system capabilities and meaningfully integrating digital competencies within existing curricula. Such integration can consider how digital technologies change current public health practice to ensure practitioners are better able to address contemporary public health problems. Findings demonstrated roles for specialized programs as resources for learning within health systems and emphasized hands-on real-world training approaches.Conclusion We need integrated, systems-focused approaches to digital competencies cutting across the current public health curriculum, while creating space for specialized digital public health competencies and roles. Further research is needed to understand requirements for enacting these recommendations in practice.


---
# Quantitative Analysis of Medical Image Data for Improved Diagnostic Accuracy

## 医学图像数据的定量分析以提高诊断准确性

Link: https://www.researchsquare.com/article/rs-5341739/latest

Background Quantitative analysis of medical image data has become essential for improving diagnostic accuracy by reducing subjectivity and enhancing clinical decision-making. With advancements in imaging technologies such as MRI, CT, and X-rays, large volumes of medical images are now available. However, traditional qualitative assessments are prone to errors and inconsistencies due to subjective interpretation. This study investigates how quantitative metrics like precision, recall, F1 score, and area under the curve (AUC) can enhance diagnostic performance by automating and standardizing medical image analysis.
Main text This research employed a diverse dataset of 1,000 medical images, including scans from MRI, CT, and X-ray modalities. These images were stratified to cover conditions such as tumors, fractures, and internal bleeding. Advanced image processing and machine learning techniques were used to extract quantitative features, allowing us to develop robust diagnostic models. Compared to traditional methods, the quantitative analysis demonstrated improved accuracy and consistency across all modalities. MRI scans, in particular, showed the highest accuracy at 85%, indicating their superiority in precise diagnostics.
Conclusion The findings highlight the potential of quantitative analysis in medical imaging to outperform existing diagnostic methods. With statistically significant improvements across all metrics&mdash;including precision, recall, and AUC&mdash;this method offers a reliable solution to reduce diagnostic errors. Adopting quantitative analysis tools in clinical practice could lead to better patient outcomes, especially in detecting complex medical conditions.


---
# Conformational trajectory of the HIV-1 fusion peptide during CD4-induced envelope opening

## CD4-induced包膜打开过程中HIV-1融合肽的构象轨迹

Link: https://www.researchsquare.com/article/rs-5090208/latest

The hydrophobic fusion peptide (FP), a critical component of the HIV-1 entry machinery, is located at the N terminal stretch of the envelope (Env) gp41 subunit1-3. The receptor-binding gp120 subunit of Env forms a heterodimer with gp41 and assembles into a trimer, in which FP is accessible for antibody binding3. Env conformational changes or &ldquo;opening&rdquo; that follow receptor binding result in FP relocating to a newly formed interprotomer pocket at the gp41-gp120 interface where it is sterically inaccessible to antibody4. The mechanistic steps connecting the entry-related transition of antibody accessible-to-inaccessible FP configurations remain unresolved. Here, using SOSIP-stabilized Env ectodomains5, we visualized atomic-level details of a functional entry intermediate, where partially open Env was bound to receptor CD4, co-receptor mimetic antibody 17b, and FP-targeting antibody VRC34.01, demonstrating that FP remains antibody accessible despite substantial receptor-induced Env opening. We determined a series of structures delineating stepwise opening of Env from its closed state to a newly resolved intermediate and defining downstream re-organizations of the gp120-gp41 interface that ultimately resulted in FP burial in an antibody-inaccessible configuration. Our studies improve our understanding of HIV-1 entry and provide information on entry-related conformation reorganization of a key site of HIV vulnerability to neutralizing antibody.


---
# Generative AI Enables Medical Image Segmentation in Ultra Low-Data Regimes

## 生成式AI可在超低数据条件下实现医学图像分割

Link: https://www.researchsquare.com/article/rs-4982456/latest

Semantic segmentation of medical images is pivotal in applications like disease diagnosis and treatment planning. While deep learning has excelled in automating this task, a major hurdle is the need for numerous annotated segmentation masks, which are resource-intensive to produce due to the required expertise and time. This scenario often leads to ultra low-data regimes, where annotated images are extremely limited, posing significant challenges for the generalization of conventional deep learning methods on test images. To address this, we introduce a generative deep learning framework, which uniquely generates high-quality paired segmentation masks and medical images, serving as auxiliary data for training robust models in data-scarce environments. Unlike traditional generative models that treat data generation and segmentation model training as separate processes, our method employs multi-level optimization for end-to-end data generation. This approach allows segmentation performance to directly influence the data generation process, ensuring that the generated data is specifically tailored to enhance the performance of the segmentation model. Our method demonstrated strong generalization performance across 9 diverse medical image segmentation tasks and on 16 datasets, in ultra-low data regimes, spanning various diseases, organs, and imaging modalities. When applied to various segmentation models, it achieved performance improvements of 10-20% (absolute), in both same-domain and out-of-domain scenarios. Notably, it requires 8 to 20 times less training data than existing methods to achieve comparable results. This advancement significantly improves the feasibility and cost-effectiveness of applying deep learning in medical imaging, particularly in scenarios with limited data availability.


---
# Autonomous Design of Ordered Gas Diffusion Layers for High-performing Fuel Cells via Bayesian Machine Learning

## 通过贝叶斯机器学习自主设计高性能燃料电池的有序气体扩散层

Link: https://www.researchsquare.com/article/rs-5235975/latest

Rational design of gas diffusion layers (GDL) is an example of a long-standing pursuit to increase the power density and reduce the cost of proton exchange membrane fuel cells (PEMFC). However, current state-of-the-art GDLs are designed by trial and error, which is a time-consuming endeavor. Here, we propose an autonomous Bayesian machine learning approach to optimize the design of GDL structures. With the artificial neural network accelerating the calculation of anisotropic transport properties of reconstructed 7621 fibrous GDLs, Bayesian optimization algorithm identifies optimal structures in only 40 steps, maximizing the PEMFC&rsquo;s limiting current density. Results suggest that the optimal GDL structure consists of highly orientated fibers with moderate diameters (~10 &micro;m), which is successfully fabricated with a controlled electrospinning technique. Impressively, the PEMFC demonstrates a record high power density of 2.17 W cm-2 and a limiting current density of ~7200 mA cm-2, far exceeding that with commercial GDL which only achieves 1.33 W cm-2 and ~2700 mA cm-2. The approach reported here represents how the advanced algorithms can aid the innovative material design to address the critical water flooding issues in PEMFCs, leading to significant performance improvements, which paves the way for further application across various scientific fields.


---
# Forecasting field rice grain moisture content using Sentinel-2 and weather data

## 使用Sentinel-2和天气数据预测田间水稻籽粒水分含量

Link: https://www.researchsquare.com/article/rs-5390827/latest

Optimizing the timing of rice paddy drainage and harvest is crucial for maximizing yield and quality. These decisions are guided by rice grain moisture content (GMC), which is typically determined by destructive sampling fields at point locations. Providing spatial forecasts of grain moisture to rice farmers will reduce the time required to gather, thresh and measure sample moistures, and will reduce errors due to samples being taken from unrepresentative areas and allow advanced planning of end-of-season drain and harvest timing. This work demonstrates consistent relationships between rice GMC and indices derived from Sentinel-2 satellite imagery, particularly those involving selected shortwave infrared and red edge bands (r=0.84, 1620 field samples, 3 years). A methodology was developed to allow forecasts of grain moisture past the latest image date to be provided, by fusing remote sensing and accumulated weather data as inputs to machine learning models. The moisture content predictions had root mean squared error between 1.6 and 2.6 % and R2 of 0.7 with forecast horizons from 0 to 28 days. Time-series grain moisture dry-down predictions were summarised per field to find the optimal harvest date (22% grain moisture), with an average RMSE around 6.5 days. The developed methodology was operationalized to provide rice growers with current and forecast grain moisture, enabling data-driven decisions, ultimately enhancing operational efficiency and crop outcomes.


---
# Vision Transformer-based Meta Loss Landscape Exploration with Actor-Critic Method

## 基于视觉变换器的演员-批评家方法的元损失景观探索

Link: https://www.researchsquare.com/article/rs-5330274/latest

Detecting and mitigating overfitting in deep neural networks remains a critical challenge in modern machine learning. This paper investigates innovative approaches to address these challenges, particularly focusing on vision transformer-based models. By leveraging meta-learning techniques and reinforcement learning frameworks, we introduce Transformer-based Loss Landscape Exploration (TLLE), which utilizes the validation loss landscape to guide gradient descent optimization. Unlike conventional methods, TLLE employs the Actor-Critic algorithm to learn the mapping from model weights to future values, facilitating efficient sample collection and precise value predictions. Experimental results demonstrate the superior performance of TLLE-enhanced transformer models in image classification and segmentation tasks, showcasing the efficacy of our approach in optimizing deep learning models for image analysis.


---
# Selection of key components in ball screw-driven servomechanisms with toothed belt drive transmission for machine tools through combinational optimization

## 通过组合优化选择带有齿形带传动的机床滚珠丝杠伺服机构中的关键部件

Link: https://www.researchsquare.com/article/rs-5309199/latest

We have developed a program for the optimal combination of servomotors, ball screws, and tooth pulleys that are key components in the machine tool application of a ball screw-driven servomechanism with pulley transmission. This program helps to produce an optimal combination of motor output torque/ motor output power/mass of system, etc., satisfying a given design requirement from the components being discretized by a given catalog. The input to this program is catalogs of components and initial design data of the machine tool servo mechanism to be designed. The outputs are the component characteristics of the servomotor-ball screw-pulley pair combinations (possible combinations) that satisfy the constraints on the component characteristics and the constraints on the dynamic and control characteristics of the system, and the characteristics of the virtual servo mechanism determined by each possible combination (maximum load torque, ball-position dependent minimum stiffness, natural frequency, gear ratio, inertia moment ratio, etc.) and the corresponding diagrams. Depending on which search target is set for these output data, the optimal combination for different destination tables can be quickly searched. The advantage of this method is to determine the global and precise optimal component combinations from a vast amount of databases by means of simple numerical simulations, which is verified by applications to servomechanisms for machining center


---
# End-to-End Semantically Aware Tactile Generation

## 端到端语义感知触觉生成

Link: https://www.researchsquare.com/article/rs-5338871/latest

Tactile graphics are an essential tool for conveying visual information to visually impaired individuals. However, translating 2D plots, such as B&amp;acute;ezier curves, polygons, and bar charts, into an effective tactile format remains a challenge. This paper presents a novel, two-stage deep learning pipeline for automating this conversion process.Our method leverages a Pix2Pix architecture, employing a U-Net++ generatornetwork for robust image generation. To improve the perceptual quality of the tactilerepresentations, we incorporate an adversarial perceptual loss function alongside agradient penalty. The pipeline operates in a sequential manner: firstly, convertingthe source plot into a grayscale tactile representation, followed by a transformationinto a channel-wise equivalent.We evaluate the performance of our model on a comprehensive synthetic datasetconsisting of 20,000 source-target pairs encompassing various 2D plot types. Toquantify performance, we utilize fuzzy versions of established metrics like pixel accuracy, Dice coefficient, and Jaccard index. Additionally, a human study is conductedto assess the visual quality of the generated tactile graphics.The proposed approach demonstrates promising results, significantly streamliningthe conversion of 2D plots into tactile graphics. This paves the way for the development of fully automated systems, enhancing accessibility of visual information forvisually impaired individuals.


---
# Diffusion-Inspired Quantum Noise Mitigation in Parameterized Quantum Circuits

## 参数化量子电路中受扩散启发的量子噪声缓解

Link: https://www.researchsquare.com/article/rs-5335334/latest

Parameterized Quantum Circuits (PQCs) have been acknowledged as a leading strategy to utilize near-term quantum advantages in multiple problems, including machine learning and combinatorial optimization. When applied to specific tasks, the parameters in the quantum circuits are trained to minimize the target function. Although there have been comprehensive studies to improve the performance of the PQCs on practical tasks, the errors caused by the quantum noise downgrade the performance when running on real quantum computers. In particular, when the quantum state is transformed through multiple quantum circuit layers, the effect of the quantum noise happens cumulatively and becomes closer to the maximally mixed state or complete noise. This paper studies the relationship between the quantum noise and the diffusion model. Then, we propose a novel diffusion-inspired learning approach to mitigate the quantum noise in the PQCs and reduce the error for specific tasks. Through our experiments, we illustrate the efficiency of the learning strategy and achieve state-of-the-art performance on classification tasks in the quantum noise scenarios.

