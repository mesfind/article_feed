# Fault-tolerant neural networks from biological error correction codes

## 来自生物纠错码的容错神经网络

Link: http://link.aps.org/doi/10.1103/PhysRevE.110.054303

Author(s): Alexander Zlokapa, Andrew K. Tan, John M. Martyn, Ila R. Fiete, Max Tegmark, and Isaac L. Chuang<br /><p>The idea that individual components with high error rates can still achieve reliable computation is known as fault-tolerant computation and is investigated here in the context of artificial intelligence. The authors construct a fault-tolerant neural network and find a threshold below which the network achieves reliable computation. It is also shown that noisy biological neurons lie below this threshold.</p><img height="" src="http://cdn.journals.aps.org/journals/PRE/key_images/10.1103/PhysRevE.110.054303.png" width="200" /><br />[Phys. Rev. E 110, 054303] Published Tue Nov 05, 2024


---
# A single-transducer echomyography system for monitoring muscle activity

## 用于监测肌肉活动的单换能器心电图系统

Link: https://www.nature.com/articles/s41928-024-01273-2

<p>Nature Electronics, Published online: 05 November 2024; <a href="https://www.nature.com/articles/s41928-024-01273-2">doi:10.1038/s41928-024-01273-2</a></p>A wearable single-transducer echomyography system has been developed that can be used to track and identify different breathing patterns by detecting diaphragm activity with sub-millimetre resolution. Moreover, hand gestures can be recognized from the single-channel radiofrequency ultrasound signals detected from muscles in the forearm, using a customized deep learning algorithm.


---
# Predicting tremor improvement after MRgFUS thalamotomy in essential tremor from preoperative spontaneous brain activity: A machine learning approach

## 从术前自发性脑活动预测原发性震颤MRgFUS丘脑切开术后震颤改善: 一种机器学习方法

Link: https://www.sciencedirect.com/science/article/pii/S2095927324005887?dgcid=rss_sd_all

<p>Publication date: 15 October 2024</p><p><b>Source:</b> Science Bulletin, Volume 69, Issue 19</p><p>Author(s): Dong Zhang, Yongqin Xiong, Haoxuan Lu, Caohui Duan, Jiayu Huang, Yan Li, Xiangbing Bian, Dekang Zhang, Jiayou Zhou, Longsheng Pan, Xin Lou</p>


---
# An approach for full space inverse materials design by combining universal machine learning potential, universal property model, and optimization algorithm

## 结合通用机器学习潜力，通用属性模型和优化算法的全空间逆材料设计方法

Link: https://www.sciencedirect.com/science/article/pii/S2095927324004948?dgcid=rss_sd_all

<p>Publication date: 15 October 2024</p><p><b>Source:</b> Science Bulletin, Volume 69, Issue 19</p><p>Author(s): Guanjian Cheng, Xin-Gao Gong, Wan-Jian Yin</p>


---
# Covariant Jacobi-Legendre expansion for total energy calculations within the projector augmented wave formalism

## 用于投影仪内总能量计算的协变jacobi-legendre扩展增强波形式主义

Link: http://link.aps.org/doi/10.1103/PhysRevB.110.184106

Author(s): Bruno Focassio, Michelangelo Domina, Urvesh Patil, Adalberto Fazzio, and Stefano Sanvito<br /><p>Machine-learning models can be trained to predict the converged electron charge density of a density functional theory (DFT) calculation. In general, the value of the density at a given point in space is invariant under global translations and rotations having that point as a center. Hence, one can …</p><br />[Phys. Rev. B 110, 184106] Published Tue Nov 05, 2024


---
# Understanding solid nitrogen through molecular dynamics simulations with a machine-learning potential

## 通过具有机器学习潜力的分子动力学模拟了解固体氮

Link: http://link.aps.org/doi/10.1103/PhysRevB.110.184107

Author(s): Marcin Kirsz, Ciprian G. Pruteanu, Peter I. C. Cooke, and Graeme J. Ackland<br /><p>We construct a fast, transferable, general purpose, machine-learning interatomic potential suitable for large-scale simulations of ${\mathrm{N}}_{2}$. The potential is trained only on high quality quantum chemical molecule-molecule interactions; no condensed phase information is used. Although there…</p><br />[Phys. Rev. B 110, 184107] Published Tue Nov 05, 2024


---
# Deep Learning‐Assisted Label‐Free Parallel Cell Sorting with Digital Microfluidics

## 使用数字微流体技术进行深度学习辅助的无标签并行细胞分选

Link: https://onlinelibrary.wiley.com/doi/10.1002/advs.202408353?af=R

Advanced Science, EarlyView.


---
# Artificial Intelligence End-to-End Workflow for Transmission Electron Microscopy: From Data Analysis Automation to Materials Knowledge Unveiling

## 人工智能透射电子显微镜的端到端工作流程: 从数据分析自动化到材料知识揭秘

Link: https://arxiv.org/abs/2411.01024

arXiv:2411.01024v1 Announce Type: new 
Abstract: This article introduces a groundbreaking analytical workflow designed for the holistic characterisation, modelling and physical simulation of device heterostructures. Our innovative workflow autonomously, comprehensively and locally characterises the crystallographic information and 3D orientation of the crystal phases, the elemental composition, and the strain maps of devices from (scanning) transmission electron microscopy data. It converts a manual characterisation process that traditionally takes days into an automatic routine completed in minutes. This is achieved through a physics-guided artificial intelligence model that combines unsupervised and supervised machine learning in a modular way to provide a representative 3D description of the devices, materials structures, or samples under analysis. To culminate the process, we integrate the extracted knowledge to automate the generation of both 3D finite element and atomic models of millions of atoms acting as digital twins, enabling simulations that yield essential physical and chemical insights crucial for understanding the device's behaviour in practical applications. We prove this end-to-end workflow with a state-of-the-art materials platform based on SiGe planar heterostructures for hosting coherent and scalable spin qubits. Our workflow connects representative digital twins of the experimental devices with their theoretical properties to reveal the true impact that every atom in the structure has on their electronic properties, and eventually, into their functional quantum performance. Notably, the versatility of our workflow is demonstrated through its successful application to a wide array of materials systems, device configurations and sample morphologies.


---
# Combining graph deep learning and London dispersion interatomic potentials: A case study on pnictogen chalcohalides

## 结合图深度学习和伦敦色散原子间势: 以pnictogen硫属卤化物为例

Link: https://arxiv.org/abs/2411.01197

arXiv:2411.01197v1 Announce Type: new 
Abstract: Machine-learning interatomic potential models based on graph neural network architectures have the potential to make atomistic materials modeling widely accessible due to their computational efficiency, scalability, and broad applicability. The training datasets for many such models are derived from density-functional theory calculations, typically using a semilocal exchange-correlation functional. As a result, long-range interactions such as London dispersion are often missing in these models. We investigate whether this missing component can be addressed by combining a graph deep learning potential with semiempirical dispersion models. We assess this combination by deriving the equations of state for layered pnictogen chalcohalides BiTeBr and BiTeI and performing crystal structure optimizations for a broader set of V-VI-VII compounds with various stoichiometries, many of which possess van der Waals gaps. We characterize the optimized crystal structures by calculating their X-ray diffraction patterns and radial distribution function histograms, which are also used to compute Earth mover's distances to quantify the dissimilarity between the optimized and corresponding experimental structures. We find that dispersion-corrected graph deep learning potentials generally (though not universally) provide a more realistic description of these compounds due to the inclusion of van der Waals attractions. In particular, their use results in systematic improvements in predicting not only the van der Waals gap but also the layer thickness in layered V-VI-VII compounds. Our results demonstrate that the combined potentials studied here, derived from a straightforward approach that neither requires fine-tuning the training nor refitting the potential parameters, can significantly improve the description of layered polar crystals.


---
# Revisit Many-body Interaction Heat Current and Thermal Conductivity Calculation in Moment Tensor Potential/LAMMPS Interface

## 再访矩张量势/LAMMPS接口中的多体相互作用热流和热导率计算

Link: https://arxiv.org/abs/2411.01255

arXiv:2411.01255v1 Announce Type: new 
Abstract: The definition of heat current operator for systems for non-pairwise additive interactions and its impact on related lattice thermal conductivity ($\kappa_{L}$) via molecular dynamics simulation (MD) are ambiguous and controversial when migrating from conventional empirical potential models to machine learning potential (MLP) models. Empirical model descriptions are often limited to three- to four-body interaction while a sophisticated representation of the many-body physics could be resembled in MLPs. Herein, we study and compare the significance of many-body interaction to the heat current computation in one of the most popular MLP models, the Moment Tensor Potential (MTP). Non-equilibrium MD simulations and equilibrium MD simulations among four different materials, $PbTe$, amorphous $Sc_{0.2}Sb_{2}Te_{3}$, graphene, and $BAs$, were performed. We found inconsistency between the simulation thermostat and its implemented heat current operator in our non-equilibrium MD results which violate law of energy conservation and suggest a need for revision. We revisit the virial stress tensor expression within the calculator and identified the lack of a generalised many-body heat current description in it. We uncover the influence of the modified heat current formula that could alter the $\kappa_{L}$ results 29% to 64% using the equilibrium MD computational approach. Our work demonstrates the importance of a many-body description during thermal analysis in MD simulations when MLPs are in concern. This work sheds light on a better understanding of the relationship between interatomic interaction and its heat transport mechanism.


---
# Efficient moment tensor machine-learning interatomic potential for accurate description of defects in Ni-Al Alloys

## 有效的矩张量机器学习原子间势，用于准确描述ni-al合金中的缺陷

Link: https://arxiv.org/abs/2411.01282

arXiv:2411.01282v1 Announce Type: new 
Abstract: Combining the efficiency of semi-empirical potentials with the accuracy of quantum mechanical methods, machine-learning interatomic potentials (MLIPs) have significantly advanced atomistic modeling in computational materials science and chemistry. This necessitates the continual development of MLIP models with improved accuracy and efficiency, which enable long-time scale molecular dynamics simulations to unveil the intricate underlying mechanisms that would otherwise remain elusive. Among various existing MLIP models, the moment tensor potential (MTP) model employs a highly descriptive rotationally-covariant moment tensor to describe the local atomic environment, enabling the use of even linear regression for model fitting. Although the current MTP model has achieved state-of-the-art efficiency for similar accuracy, there is still room for optimizing the contraction process of moment tensors. In this work, we propose an effective genetic algorithm based optimization scheme that can significantly reduce the number of independent moment tensor components and intermediate tensor components. This leads to a speedup of nearly one order of magnitude in efficiency and also improved accuracy compared to the traditional MTP model for intricate basis sets. We have applied our improved MTP model to predicting the energetic and dynamical properties of various point and planar defects in Ni-Al alloys, showing overall good performances and in general outperforming the semi-empirical potentials. This work paves the way for fast and accurate atomistic modeling of complex systems and provides a useful tool for modeling defects in Ni-Al alloys.


---
# Integrating Graph Neural Networks and Many-Body Expansion Theory for Potential Energy Surfaces

## 势能面的图神经网络和多体扩张理论的集成

Link: https://arxiv.org/abs/2411.01578

arXiv:2411.01578v1 Announce Type: new 
Abstract: Rational design of next-generation functional materials relied on quantitative predictions of their electronic structures beyond single building blocks. First-principles quantum mechanical (QM) modeling became infeasible as the size of a material grew beyond hundreds of atoms. In this study, we developed a new computational tool integrating fragment-based graph neural networks (FBGNN) into the fragment-based many-body expansion (MBE) theory, referred to as FBGNN-MBE, and demonstrated its capacity to reproduce full-dimensional potential energy surfaces (FD-PES) for hierarchic chemical systems with manageable accuracy, complexity, and interpretability. In particular, we divided the entire system into basic building blocks (fragments), evaluated their single-fragment energies using a first-principles QM model and attacked many-fragment interactions using the structure-property relationships trained by FBGNNs. Our development of FBGNN-MBE demonstrated the potential of a new framework integrating deep learning models into fragment-based QM methods, and marked a significant step towards computationally aided design of large functional materials.


---
# Atomic-scale 3D structural dynamics and functional degradation of Pt alloy nanocatalysts

## Pt合金纳米催化剂的原子尺度三维结构动力学和功能降解

Link: https://arxiv.org/abs/2411.01727

arXiv:2411.01727v1 Announce Type: new 
Abstract: Pt-based electrocatalysts are the primary choice for fuel cells due to their superior oxygen reduction reaction (ORR) activity. To enhance ORR performance and durability, extensive studies have investigated transition metal alloying, doping, and shape control to optimize the three key governing factors for ORR: geometry, local chemistry, and strain of their surface and subsurface. However, systematic optimization remains incomplete, as it requires an atomic-scale understanding of these factors and their dynamics over potential cycling, as well as their relationship to ORR activity. Here, we implement neural network-assisted atomic electron tomography to measure the 3D atomic structural dynamics and their effects on the functional degradation of PtNi alloy catalysts. Our results reveal that PtNi catalysts undergo shape changes, surface alloying, and strain relaxation during cycling, which can be effectively mitigated by Ga doping. By combining geometry, local chemistry, and strain analysis, we calculated the changes in ORR activity over thousands of cycles and observed that Ga doping leads to higher initial activity and greater stability. These findings offer a pathway to understanding 3D atomic structural dynamics and their relation to ORR activity during cycling, paving the way for the systematic design of durable, high-efficiency nanocatalysts.


---
# On the phase diagram of extensive-rank symmetric matrix denoising beyond rotational invariance

## 关于超越旋转不变性的广秩对称矩阵去噪的相图

Link: https://arxiv.org/abs/2411.01974

arXiv:2411.01974v1 Announce Type: new 
Abstract: Matrix denoising is central to signal processing and machine learning. Its analysis when the matrix to infer has a factorised structure with a rank growing proportionally to its dimension remains a challenge, except when it is rotationally invariant. In this case the information theoretic limits and a Bayes-optimal denoising algorithm, called rotational invariant estimator [1,2], are known. Beyond this setting few results can be found. The reason is that the model is not a usual spin system because of the growing rank dimension, nor a matrix model due to the lack of rotation symmetry, but rather a hybrid between the two. In this paper we make progress towards the understanding of Bayesian matrix denoising when the hidden signal is a factored matrix $XX^\intercal$ that is not rotationally invariant. Monte Carlo simulations suggest the existence of a denoising-factorisation transition separating a phase where denoising using the rotational invariant estimator remains Bayes-optimal due to universality properties of the same nature as in random matrix theory, from one where universality breaks down and better denoising is possible by exploiting the signal's prior and factorised structure, though algorithmically hard. We also argue that it is only beyond the transition that factorisation, i.e., estimating $X$ itself, becomes possible up to sign and permutation ambiguities. On the theoretical side, we combine mean-field techniques in an interpretable multiscale fashion in order to access the minimum mean-square error and mutual information. Interestingly, our alternative method yields equations which can be reproduced using the replica approach of [3]. Using numerical insights, we then delimit the portion of the phase diagram where this mean-field theory is reliable, and correct it using universality when it is not. Our ansatz matches well the numerics when accounting for finite size effects.


---
# Learning optimal erasure of a Static Random Access Memory

## 学习静态随机存取存储器的最佳擦除

Link: https://arxiv.org/abs/2411.02044

arXiv:2411.02044v1 Announce Type: new 
Abstract: In this paper, we study the thermodynamic cost associated with erasing a static random access memory. By combining the stochastic thermodynamics framework of electronic circuits with machine learning-based optimization techniques, we show that it is possible to erase an electronic random access memory at arbitrarily fast speed and finite heat dissipation. This disproves a widely held belief that heat dissipation scales linearly with erasure speed. Furthermore, we find driving protocols that minimize the heat dissipation, leading to explicit design principles for future computer memories. This bridges an important gap between the theoretical framework of stochastic thermodynamics and applications in electronic engineering.


---
# Solute diffusion calculation in Fe-Si and Fe-Cr-Si multicomponent alloys

## Fe-si和fe-cr-si多元合金中的溶质扩散计算

Link: https://arxiv.org/abs/2411.02053

arXiv:2411.02053v1 Announce Type: new 
Abstract: Diffusion plays a key role in microstructure evolution at multicomponent alloys: diffusion controls the kinetics of phase transformations and alloy homogenization. This study aims at developing computationally efficient approaches to estimate the solute diffusion coefficients in two-component systems. We consider silicon as the solute example because it is highly used in industrial steels. We demonstrate that the silicon jump frequency may be calculated with the bond potential instead of the more computationally expensive machine learning potential in Fe-Si and Fe-Cr-Si alloys. We show that the silicon jump frequency can be estimated from thermodynamic simulations for the bond potential without kinetic simulations. The silicon correlation factor slightly depends on silicon concentration and can be approximately estimated by the analytical nine-frequency model.


---
# Convolutional neural networks applied to differential dynamic microscopy reduces noise when quantifying heterogeneous dynamics

## 应用于差分动态显微镜的卷积神经网络可在量化异质动力学时降低噪声

Link: https://arxiv.org/abs/2411.02314

arXiv:2411.02314v1 Announce Type: new 
Abstract: Differential dynamic microscopy (DDM) typically relies on movies containing hundreds or thousands of frames to accurately quantify motion in soft matter systems. Using movies much shorter in duration produces noisier and less accurate results. This limits the applicability of DDM to situations where the dynamics are stationary over extended times. Here, we investigate a method to denoise the DDM process, particularly suited to when a limited number of imaging frames are available or when dynamics are quickly evolving in time. We use a convolutional neural network encoder-decoder (CNN-ED) model to reduce the noise in the intermediate scattering function that is computed via DDM. We demonstrate this approach of combining machine learning and DDM on samples containing diffusing micron-sized colloidal particles. We quantify how the particles' diffusivities change over time as the fluid they are suspended in gels. We also quantify how the diffusivity of particles varies with position in a sample containing a viscosity gradient. These test cases demonstrate how studies of non-equilibrium dynamics and high-throughput screens could benefit from a method to denoise the outputs of DDM.


---
# Graph Neural Networks Based Deep Learning for Predicting Structural and Electronic Properties

## 基于图神经网络的深度学习预测结构和电子特性

Link: https://arxiv.org/abs/2411.02331

arXiv:2411.02331v1 Announce Type: new 
Abstract: This study presents a deep learning approach to predicting structural and electronic properties of materials using Graph Neural Networks (GNNs). Leveraging data from the Materials Project database, we construct graph representations of crystal structures and employ GNNs to predict multiple properties simultaneously. All crystal structures are from the Materials Project database, with a total of 158,874 structures used. Our model achieves high predictive accuracy across various properties, as indicated by \( R^2 \) values: 0.96 for density, 0.97 for formation energy, 0.54 for energy above hull, 0.47 for structural stability (is\_S), 0.76 for band gap, 0.86 for valence band maximum, 0.78 for conduction band minimum, and 0.82 for Fermi energy. These results demonstrate the potential of GNNs in materials science, offering a powerful tool for rapid screening and discovery of materials with desired properties.


---
# Dynamical simulations of many-body quantum chaos on a quantum computer

## 量子计算机上多体量子混沌的动力学模拟

Link: https://arxiv.org/abs/2411.00765

arXiv:2411.00765v1 Announce Type: cross 
Abstract: Quantum circuits with local unitaries have emerged as a rich playground for the exploration of many-body quantum dynamics of discrete-time systems. While the intrinsic locality makes them particularly suited to run on current quantum processors, the task of verification at non-trivial scales is complicated for non-integrable systems. Here, we study a special class of maximally chaotic circuits known as dual unitary circuits -- exhibiting unitarity in both space and time -- that are known to have exact analytical solutions for certain correlation functions. With advances in noise learning and the implementation of novel error mitigation methods, we show that a superconducting quantum processor with 91 qubits is able to accurately simulate these correlators. We then probe dynamics beyond exact verification, by perturbing the circuits away from the dual unitary point, and compare our results to classical approximations with tensor networks. These results cement error-mitigated digital quantum simulation on pre-fault-tolerant quantum processors as a trustworthy platform for the exploration and discovery of novel emergent quantum many-body phases.


---
# Intrinsic Dimensionality of Fermi-Pasta-Ulam-Tsingou High-Dimensional Trajectories Through Manifold Learning

## 基于流形学习的费米-意大利面-乌兰-青豆高维轨迹的内在维数

Link: https://arxiv.org/abs/2411.02058

arXiv:2411.02058v1 Announce Type: cross 
Abstract: A data-driven approach based on unsupervised machine learning is proposed to infer the intrinsic dimensions $m^{\ast}$ of the high-dimensional trajectories of the Fermi-Pasta-Ulam-Tsingou (FPUT) model. Principal component analysis (PCA) is applied to trajectory data consisting of $n_s = 4,000,000$ datapoints, of the FPUT $\beta$ model with $N = 32$ coupled oscillators, revealing a critical relationship between $m^{\ast}$ and the model's nonlinear strength. For weak nonlinearities, $m^{\ast} \ll n$, where $n = 2N$. In contrast, for strong nonlinearities, $m^{\ast} \rightarrow n - 1$, consistently with the ergodic hypothesis. Furthermore, one of the potential limitations of PCA is addressed through an analysis with t-distributed stochastic neighbor embedding ($t$-SNE). Accordingly, we found strong evidence suggesting that the datapoints lie near or on a curved low-dimensional manifold for weak nonlinearities.


---
# Speak so a physicist can understand you! TetrisCNN for detecting phase transitions and order parameters

## 说出来，这样物理学家就能理解你了!用于检测相变和阶数参数的TetrisCNN

Link: https://arxiv.org/abs/2411.02237

arXiv:2411.02237v1 Announce Type: cross 
Abstract: Recently, neural networks (NNs) have become a powerful tool for detecting quantum phases of matter. Unfortunately, NNs are black boxes and only identify phases without elucidating their properties. Novel physics benefits most from insights about phases, traditionally extracted in spin systems using spin correlators. Here, we combine two approaches and design TetrisCNN, a convolutional NN with parallel branches using different kernels that detects the phases of spin systems and expresses their essential descriptors, called order parameters, in a symbolic form based on spin correlators. We demonstrate this on the example of snapshots of the one-dimensional transverse-field Ising model taken in various bases. We show also that TetrisCNN can detect more complex order parameters using the example of two-dimensional Ising gauge theory. This work can lead to the integration of NNs with quantum simulators to study new exotic phases of matter.


---
# Machine-learned nodal structures of Fermion systems

## 费米子系统的机器学习节点结构

Link: https://arxiv.org/abs/2411.02257

arXiv:2411.02257v1 Announce Type: cross 
Abstract: A major challenge in quantum physics is the accurate simulation of fermionic systems, particularly those involving strong correlations. While effective for bosonic systems, traditional quantum Monte Carlo methods encounter the notorious sign problem when applied to Fermions, often resulting in biased outcomes through the fixed-node approximation. This work demonstrates the potential of machine learning techniques to address these limitations by allowing nodal structures to be learned through gradient descent optimization iterations and the variational algorithm. Using a neural network to represent the wave function, we focus on quantum dots containing up to 30 electrons. The results show a significant reduction in the variational bias, achieving greater accuracy and a lower ground state energy than diffusion Monte Carlo with the fixed-node approximation. Our approach paves the way for precise and accurate property predictions in fermionic strongly correlated systems, advancing fundamental understanding and applications in quantum technologies.


---
# Polyvalent Machine-Learned Potential for Cobalt: from Bulk to Nanoparticles

## 钴的多价机器学习潜力: 从块体到纳米颗粒

Link: https://arxiv.org/abs/2404.02626

arXiv:2404.02626v2 Announce Type: replace 
Abstract: We present the development and applications of a quadratic Spectral Neighbor Analysis Potential (q-SNAP) for ferromagnetic cobalt. Trained on Density Functional Theory calculations using the Perdew-Burke-Ernzerhof (DFT-PBE) functional, this machine-learned potential enables simulations of large systems over extended time scales across a wide range of temperatures and pressures at near DFT accuracy. It is validated by closely reproducing the phonon dispersions of hexagonal close-packed (hcp) and face-centered cubic (fcc) Co, surface energies, and the relative stability of nanoparticles of various shapes. An important feature of this novel potential is its numerical stability in long molecular dynamics simulations. This robustness is exploited to compute the heat capacity of nanoparticles containing up to 9201 atoms, showing convergence to less than 2 J.K-1.mol-1 after 100 ns. Computations of the melting temperature of nanoparticles as a function of their size revealed a convergence to the bulk limit in excellent agreement with the experimental value. Thus, the new, highly accurate machine-learned potential for Co opens exciting opportunities for further applications such as the dynamics of nanoparticles in catalytic reactions.


---
# Stress Predictions in Polycrystal Plasticity using Graph Neural Networks with Subgraph Training

## 使用具有子图训练的图神经网络进行多晶塑性应力预测

Link: https://arxiv.org/abs/2409.05169

arXiv:2409.05169v2 Announce Type: replace 
Abstract: Polycrystal plasticity in metals is characterized by nonlinear behavior and strain hardening, making numerical models computationally intensive. We employ Graph Neural Networks (GNN) to surrogate polycrystal plasticity with complex geometries from Finite Element Method (FEM) simulations. We present a novel message-passing GNN that encodes nodal strain and edge distances between FEM mesh cells, aggregates them to obtain embeddings, and combines the decoded embeddings with the nodal strains to predict stress tensors on graph nodes. We demonstrate training GNN based on subgraphs generated from FEM mesh-graphs, in which the mesh cells are converted to nodes and edges are created between adjacent cells. The GNN is trained on 80\% of the graphs and tested on the rest (90 graphs in total). We apply the trained GNN to periodic polycrystals and learn the stress-strain maps based on crystal plasticity theory. The GNN is accurately trained based on FEM graphs, in which the $R^2$ for both training and testing sets are 0.993. The proposed GNN plasticity constitutive model speeds up more than 150 times compared with the benchmark FEM method on randomly selected test polycrystals. We also apply the trained GNN to 30 unseen FEM simulations and the GNN generalizes well with an overall $R^2$ of 0.992. Analysis of the von Mises stress distributions in polycrystals shows that the GNN model accurately learns the stress distribution with low error. By comparing the error distribution across training, testing, and unseen datasets, one deduces that the proposed model does not overfit and generalizes well beyond the training data. This work outlooks surrogating computationally intensive crystal plasticity simulations using graph data.


---
# Latent heat estimation with machine learning

## 基于机器学习的潜热估计

Link: https://arxiv.org/abs/2411.00733

arXiv:2411.00733v2 Announce Type: replace 
Abstract: We set out to explore the possibility of investigating the critical behavior of systems with first-order phase transition using deep machine learning. We propose a machine learning protocol with ternary classification of instantaneous spin configurations using known values of disordered phase energy and ordered phase energy. The trained neural network is used to predict whether a given sample belong to one or the other phase of matter. This allows us to estimate the probability that configurations with a certain energy belong to the ordered phase, mixed phase and, disordered phase. From these probabilities, we obtained estimates of the values of the critical energies and the latent heat for the Potts model with 10 and 20 components, which undergoes a strong discontinuous transition. We also find that the probabilities can reflect geometric transitions in the mixed phase.


---
# Scaling Whole-Chip QAOA for Higher-Order Ising Spin Glass Models on Heavy-Hex Graphs

## 在重十六进制图上缩放高阶Ising自旋玻璃模型的全芯片QAOA

Link: https://arxiv.org/abs/2312.00997

arXiv:2312.00997v2 Announce Type: replace-cross 
Abstract: We show through numerical simulation that the Quantum Approximate Optimization Algorithm (QAOA) for higher-order, random-coefficient, heavy-hex compatible spin glass Ising models has strong parameter concentration across problem sizes from $16$ up to $127$ qubits for $p=1$ up to $p=5$, which allows for straight-forward transfer learning of QAOA angles on instance sizes where exhaustive grid-search is prohibitive even for $p>1$. We use Matrix Product State (MPS) simulation at different bond dimensions to obtain confidence in these results, and we obtain the optimal solutions to these combinatorial optimization problems using CPLEX. In order to assess the ability of current noisy quantum hardware to exploit such parameter concentration, we execute short-depth QAOA circuits (with a CNOT depth of 6 per $p$, resulting in circuits which contain $1420$ two qubit gates for $127$ qubit $p=5$ QAOA) on $100$ higher-order (cubic term) Ising models on IBM quantum superconducting processors with $16, 27, 127$ qubits using QAOA angles learned from a single $16$-qubit instance. We show that (i) the best quantum processors generally find lower energy solutions up to $p=3$ for 27 qubit systems and up to $p=2$ for 127 qubit systems and are overcome by noise at higher values of $p$, (ii) the best quantum processors find mean energies that are about a factor of two off from the noise-free numerical simulation results. Additional insights from our experiments are that large performance differences exist among different quantum processors even of the same generation and that dynamical decoupling significantly improve performance for some, but decrease performance for other quantum processors. Lastly we show $p=1$ QAOA angle mean energy landscapes computed using up to a $414$ qubit quantum computer, showing that the mean QAOA energy landscapes remain very similar as the problem size changes.


---
# Uncertainty-biased molecular dynamics for learning uniformly accurate interatomic potentials

## 用于学习均匀精确的原子间势的不确定性偏置分子动力学

Link: https://arxiv.org/abs/2312.01416

arXiv:2312.01416v2 Announce Type: replace-cross 
Abstract: Efficiently creating a concise but comprehensive data set for training machine-learned interatomic potentials (MLIPs) is an under-explored problem. Active learning, which uses biased or unbiased molecular dynamics (MD) to generate candidate pools, aims to address this objective. Existing biased and unbiased MD-simulation methods, however, are prone to miss either rare events or extrapolative regions -- areas of the configurational space where unreliable predictions are made. This work demonstrates that MD, when biased by the MLIP's energy uncertainty, simultaneously captures extrapolative regions and rare events, which is crucial for developing uniformly accurate MLIPs. Furthermore, exploiting automatic differentiation, we enhance bias-forces-driven MD with the concept of bias stress. We employ calibrated gradient-based uncertainties to yield MLIPs with similar or, sometimes, better accuracy than ensemble-based methods at a lower computational cost. Finally, we apply uncertainty-biased MD to alanine dipeptide and MIL-53(Al), generating MLIPs that represent both configurational spaces more accurately than models trained with conventional MD.


---
# Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks

## 学习grok: 模块化算术任务中上下文学习和技能组合的出现

Link: https://arxiv.org/abs/2406.02550

arXiv:2406.02550v2 Announce Type: replace-cross 
Abstract: Large language models can solve tasks that were not present in the training set. This capability is believed to be due to in-context learning and skill composition. In this work, we study the emergence of in-context learning and skill composition in a collection of modular arithmetic tasks. Specifically, we consider a finite collection of linear modular functions $z = a \, x + b \, y \;\mathrm{mod}\; p$ labeled by the vector $(a, b) \in \mathbb{Z}_p^2$. We use some of these tasks for pre-training and the rest for out-of-distribution testing. We empirically show that a GPT-style transformer exhibits a transition from in-distribution to out-of-distribution generalization as the number of pre-training tasks increases. We find that the smallest model capable of out-of-distribution generalization requires two transformer blocks, while for deeper models, the out-of-distribution generalization phase is \emph{transient}, necessitating early stopping. Finally, we perform an interpretability study of the pre-trained models, revealing highly structured representations in both attention heads and MLPs; and discuss the learned algorithms. Notably, we find an algorithmic shift in deeper models, as we go from few to many in-context examples.


---
# Why Warmup the Learning Rate? Underlying Mechanisms and Improvements

## 为什么要预热学习率？基本机制和改进

Link: https://arxiv.org/abs/2406.09405

arXiv:2406.09405v2 Announce Type: replace-cross 
Abstract: It is common in deep learning to warm up the learning rate $\eta$, often by a linear schedule between $\eta_{\text{init}} = 0$ and a predetermined target $\eta_{\text{trgt}}$. In this paper, we show through systematic experiments using SGD and Adam that the overwhelming benefit of warmup arises from allowing the network to tolerate larger $\eta_{\text{trgt}}$ {by forcing the network to more well-conditioned areas of the loss landscape}. The ability to handle larger $\eta_{\text{trgt}}$ makes hyperparameter tuning more robust while improving the final performance. We uncover different regimes of operation during the warmup period, depending on whether training starts off in a progressive sharpening or sharpness reduction phase, which in turn depends on the initialization and parameterization. Using these insights, we show how $\eta_{\text{init}}$ can be properly chosen by utilizing the loss catapult mechanism, which saves on the number of warmup steps, in some cases completely eliminating the need for warmup. We also suggest an initialization for the variance in Adam which provides benefits similar to warmup.


---
# Learning State Preparation Circuits for Quantum Phases of Matter

## 用于物质量子相的学习状态准备电路

Link: https://arxiv.org/abs/2410.23544

arXiv:2410.23544v2 Announce Type: replace-cross 
Abstract: Many-body ground state preparation is an important subroutine used in the simulation of physical systems. In this paper, we introduce a flexible and efficient framework for obtaining a state preparation circuit for a large class of many-body ground states. We introduce polynomial-time classical algorithms that take reduced density matrices over $\mathcal{O}(1)$-sized balls as inputs, and output a circuit that prepares the global state. We introduce algorithms applicable to (i) short-range entangled states (e.g., states prepared by shallow quantum circuits in any number of dimensions, and more generally, invertible states) and (ii) long-range entangled ground states (e.g., the toric code on a disk). Both algorithms can provably find a circuit whose depth is asymptotically optimal. Our approach uses a variant of the quantum Markov chain condition that remains robust against constant-depth circuits. The robustness of this condition makes our method applicable to a large class of states, whilst ensuring a classically tractable optimization landscape.


---
# AI Support Meets AR Visualization for Alice and Bob: Personalized Learning Based on Individual ChatGPT Feedback in an AR Quantum Cryptography Experiment for Physics Lab Courses

## AI支持满足Alice和Bob的AR可视化: 基于物理实验室课程的AR量子密码实验中的个人ChatGPT反馈的个性化学习

Link: https://arxiv.org/abs/2411.00849

arXiv:2411.00849v1 Announce Type: new 
Abstract: Quantum cryptography is a central topic in the quantum technology field that is particularly important for secure communication. The training of qualified experts in this field is necessary for continuous development. However, the abstract and complex nature of quantum physics makes the topic difficult to understand. Augmented reality (AR) allows otherwise invisible abstract concepts to be visualized and enables interactive learning, offering significant potential for improving quantum physics education in university lab courses. In addition, personalized feedback on challenging concepts can facilitate learning, and large language models (LLMs) like ChatGPT can effectively deliver such feedback. This study combines these two aspects and explores the impact of an AR-based quantum cryptography experiment with integrated ChatGPT-based feedback on university students' learning outcomes and cognitive processes. The study involved 38 students in a physics laboratory course at a German university and used four open-ended questions to measure learning outcomes and gaze data as a learning process assessment. Statistical analysis was used to compare scores between feedback and non-feedback questions, and the effect of ChatGPT feedback on eye-tracking data was examined. The results show that ChatGPT feedback significantly improved learning outcomes and affected gaze data. While the feedback on conceptual questions tended to direct attention to the visualizations of the underlying model, the feedback on questions about experimental procedures increased visual attention to the real experimental materials. Overall, the results show that AI-based feedback draws visual attention towards task-relevant factors and increases learning performance in general.


---
# Realtime Particulate Matter and Bacteria Analysis of Peritoneal Dialysis Fluid using Digital Inline Holography

## 使用数字在线全息技术实时分析腹膜透析液中的颗粒物和细菌

Link: https://arxiv.org/abs/2411.00901

arXiv:2411.00901v1 Announce Type: new 
Abstract: We developed a digital inline holography (DIH) system integrated with deep learning algorithms for real-time detection of particulate matter (PM) and bacterial contamination in peritoneal dialysis (PD) fluids. The system comprises a microfluidic sample delivery module and a DIH imaging module that captures holograms using a pulsed laser and a digital camera with a 40x objective. Our data processing pipeline enhances holograms, reconstructs images, and employs a YOLOv8n-based deep learning model for particle identification and classification, trained on labeled holograms of generic PD particles, Escherichia coli (E. coli), and Pseudomonas aeruginosa (P. aeruginosa). The system effectively detected and classified generic particles in sterile PD fluids, revealing diverse morphologies predominantly sized 1-5 um with an average concentration of 61 particles per microliter. In PD fluid samples spiked with high concentrations of E. coli and P. aeruginosa, our system achieved high sensitivity in detecting and classifying these bacteria at clinically relevant low false positive rates. Further validation against standard colony-forming unit (CFU) methods using PD fluid spiked with bacterial concentrations from approximately 100 to 10,000 bacteria per milliliter demonstrated a clear one-to-one correspondence between our measurements and CFU counts. Our DIH system provides a rapid, accurate alternative to traditional culture-based methods for assessing bacterial contamination in PD fluids. By enabling real-time sterility monitoring, it can significantly improve patient outcomes in PD treatment, facilitate point-of-care fluid production, reduce logistical challenges, and be extended to quality control in pharmaceutical production.


---
# Extreme Value Statistics of Community Detection in Complex Networks with Reduced Network Extremal Ensemble Learning (RenEEL)

## 具有简化网络极值集成学习 (RenEEL) 的复杂网络社区检测的极值统计

Link: https://arxiv.org/abs/2411.00977

arXiv:2411.00977v1 Announce Type: new 
Abstract: Arguably, the most fundamental problem in Network Science is finding structure within a complex network. One approach is to partition the nodes into communities that are more densely connected than one expects in a random network. "The" community structure then corresponds to the partition that maximizes Modularity, an objective function that quantifies this idea. Finding the maximizing partition, however, is a computationally difficult, NP-Complete problem. We explore using a recently introduced machine-learning algorithmic scheme to find the structure of benchmark networks. The scheme, known as RenEEL, creates an ensemble of $K$ partitions and updates the ensemble by replacing its worst member with the best of $L$ partitions found by analyzing a simplified network. The updating continues until consensus is achieved within the ensemble. We perform an empirical study of three real-world networks to explore how the Modularity of the consensus partition depends on the values of $K$ and $L$ and relate the results to the extreme value statistics of record-breaking. We find that increasing $K$ is generally more effective than increasing $L$ for finding the best partition.


---
# Addressing out-of-sample issues in multi-layer convolutional neural-network parameterization of mesoscale eddies applied near coastlines

## 解决在海岸线附近应用的中尺度涡旋的多层卷积神经网络参数化中的样本外问题

Link: https://arxiv.org/abs/2411.01138

arXiv:2411.01138v1 Announce Type: new 
Abstract: This study addresses the boundary artifacts in machine-learned (ML) parameterizations for ocean subgrid mesoscale momentum forcing, as identified in the online ML implementation from a previous study (Zhang et al., 2023). We focus on the boundary condition (BC) treatment within the existing convolutional neural network (CNN) models and aim to mitigate the "out-of-sample" errors observed near complex coastal regions without developing new, complex network architectures. Our approach leverages two established strategies for placing BCs in CNN models, namely zero and replicate padding. Offline evaluations revealed that these padding strategies significantly reduce root mean squared error (RMSE) in coastal regions by limiting the dependence on random initialization of weights and restricting the range of out-of-sample predictions. Further online evaluations suggest that replicate padding consistently reduces boundary artifacts across various retrained CNN models. In contrast, zero padding sometimes intensifies artifacts in certain retrained models despite both strategies performing similarly in offline evaluations. This study underscores the need for BC treatments in CNN models trained on open water data when predicting near-coastal subgrid forces in ML parameterizations. The application of replicate padding, in particular, offers a robust strategy to minimize the propagation of extreme values that can contaminate computational models or cause simulations to fail. Our findings provide insights for enhancing the accuracy and stability of ML parameterizations in the online implementation of ocean circulation models with coastlines.


---
# A versatile framework for attitude tuning of beamlines at advanced light sources

## 一种用于高级光源的光束线姿态调整的通用框架

Link: https://arxiv.org/abs/2411.01278

arXiv:2411.01278v1 Announce Type: new 
Abstract: Aside from regular beamline experiments at light sources, the preparation steps before these experiments are also worth systematic consideration in terms of automation; a representative category in these steps is attitude tuning, which typically appears in names like beam focusing, sample alignment etc. With the goal of saving time and manpower in both writing and using in mind, a Mamba-based attitude-tuning framework is created. It supports flexible input/output ports, easy integration of diverse evaluation functions, and free selection of optimisation algorithms; with the help from Mamba's infrastructure, machine learning (ML) and artificial intelligence (AI) technologies can also be readily integrated. The tuning of a polycapillary lens and of an X-ray emission spectrometer are given as examples for the general use of this framework, featuring powerful command-line interfaces (CLIs) and friendly graphical user interfaces (GUIs) that allow comfortable human-in-the-loop control. The tuning of a Raman spectrometer demonstrates more specialised use of the framework with customised optimisation algorithms. With similar applications in mind, our framework is estimated to be capable of fulfilling a majority of attitude-tuning needs. Also reported is a virtual-beamline mechanism based on easily customisable simulated detectors and motors, which facilitates both testing for developers and training for users.


---
# Symmetry Adapted Residual Neural Network Diabatization: Conical Intersections in Aniline Photodissociation

## 对称适应的残差神经网络双化: 苯胺光解离中的圆锥形交点

Link: https://arxiv.org/abs/2411.01702

arXiv:2411.01702v1 Announce Type: new 
Abstract: We present a symmetry adapted residual neural network (SAResNet) diabatization method to construct quasi-diabatic Hamiltonians that accurately represent ab initio adiabatic energies, energy gradients, and nonadiabatic couplings for moderate sized systems. Our symmetry adapted neural network inherits from the pioneering symmetry adapted polynomial and fundamental invariant neural network diabatization methods to exploit the power of neural network along with the transparent symmetry adaptation of polynomial for both symmetric and asymmetric irreducible representations. In addition, our symmetry adaptation provides a unified framework for symmetry adapted polynomial and symmetry adapted neural network, enabling the adoption of the residual neural network architecture, which is a powerful descendant of the pioneering feedforward neural network. Our SAResNet is applied to construct the full 36-dimensional coupled diabatic potential energy surfaces for aniline N-H bond photodissociation, with 2,269 data points and 32,640 trainable parameters and 190 cm-1 root mean square deviation in energy. In addition to the experimentally observed {\pi}{\pi}* and {\pi}Rydberg/{\pi}{\sigma}* states, a higher state (HOMO - 1 {\pi} to Rydberg/{\sigma}* excitation) is found to introduce an induced geometric phase effect thus indirectly participate in the photodissociation process.


---
# Experimental demonstration of dark current mitigation by an over-inserted plug in a normal conducting VHF gun

## 通过在正常导电的VHF枪中插入过度的插头来减轻暗电流的实验演示

Link: https://arxiv.org/abs/2411.01754

arXiv:2411.01754v1 Announce Type: new 
Abstract: The room temperature continuous wave (CW) very-high-frequency (VHF) gun is one of the candidates for the electron gun of the high-repetition-rate free-electron lasers (FELs). The VHF gun operates with a cathode gradient of ~ 20 MV/m and an accelerating voltage of ~ 750 kV. The gun dark current emission leads to beam loss along the FEL machine, therefore is a critical parameter for the performance of the CW gun. In this paper, we presents a systematic study of the dark current reduction of the VHF gun, including cathode region optimizations, dark current tracking simulations and measurements. Over-inserted cathode plugs were tested in two VHF guns of different acceleration gap sizes, and both demonstrated significant dark current reduction ratios of more than two orders of magnitude.


---
# Physics-Constrained Graph Neural Networks for Spatio-Temporal Prediction of Drop Impact on OLED Display Panels

## 用于OLED显示面板跌落影响的时空预测的物理约束图神经网络

Link: https://arxiv.org/abs/2411.01848

arXiv:2411.01848v1 Announce Type: new 
Abstract: This study aims to predict the spatio-temporal evolution of physical quantities observed in multi-layered display panels subjected to the drop impact of a ball. To model these complex interactions, graph neural networks have emerged as promising tools, effectively representing objects and their relationships as graph structures. In particular, MeshGraphNets (MGNs) excel in capturing dynamics in dynamic physics simulations using irregular mesh data. However, conventional MGNs often suffer from non-physical artifacts, such as the penetration of overlapping objects. To resolve this, we propose a physics-constrained MGN that mitigates these penetration issues while maintaining high level of accuracy in temporal predictions. Furthermore, to enhance the model's robustness, we explore noise injection strategies with varying magnitudes and different combinations of targeted components, such as the ball, the plate, or both. In addition, our analysis on model stability in spatio-temporal predictions reveals that during the inference, deriving next time-step node positions by predicting relative changes (e.g., displacement or velocity) between the current and future states yields superior accuracy compared to direct absolute position predictions. This approach consistently shows greater stability and reliability in determining subsequent node positions across various scenarios. Building on this validated model, we evaluate its generalization performance by examining its ability to extrapolate with respect to design variables. Furthermore, the physics-constrained MGN serves as a near real-time emulator for the design optimization of multi-layered OLED display panels, where thickness variables are optimized to minimize stress in the light-emitting materials. It outperforms conventional MGN in optimization tasks, demonstrating its effectiveness for practical design applications.


---
# Prediction of three-dimensional chemically reacting compressible turbulence based on implicit U-Net enhanced Fourier neural operator

## 基于隐式u-net增强Fourier神经算子的三维化学反应可压缩湍流预测

Link: https://arxiv.org/abs/2411.01885

arXiv:2411.01885v1 Announce Type: new 
Abstract: The accurate and fast prediction of long-term dynamics of turbulence presents a significant challenge for both traditional numerical simulations and machine learning methods. In recent years, the emergence of neural operators has provided a promising approach to address this issue. The implicit U-Net enhanced Fourier neural operator (IU-FNO) has successfully demonstrated long-term stable predictions for three-dimensional incompressible turbulence. In this study, we extend this method to the three-dimensional chemically reacting compressible turbulence. Numerical results show that the IU-FNO model predicts flow dynamics significantly faster than the traditional dynamic Smagorinsky model (DSM) used in large eddy simulation (LES). In terms of prediction accuracy, the IU-FNO framework outperforms the traditional DSM in predicting the energy spectra of velocity, temperature, and density, the probability density functions (PDFs) of vorticity and velocity increments, and instantaneous spatial structures of temperature. Therefore, the IU-FNO represents a highly promising approach for predicting chemically reacting compressible turbulence.


---
# Building robust surrogate models of laser-plasma interactions using large scale PIC simulation

## 使用大规模PIC模拟构建激光-等离子体相互作用的鲁棒代理模型

Link: https://arxiv.org/abs/2411.02079

arXiv:2411.02079v1 Announce Type: new 
Abstract: As the repetition rates of ultra-high intensity lasers increase, simulations used for the prediction of experimental results may need to be augmented with machine learning to keep up. In this paper, the usage of gaussian process regression in producing surrogate models of laser-plasma interactions from particle-in-cell simulations is investigated. Such a model retains the characteristic behaviour of the simulations but allows for faster on-demand results and estimation of statistical noise. A demonstrative model of Bremsstrahlung emission by hot electrons from a femtosecond timescale laser pulse in the $10^{20} - 10^{23}\;\mathrm{Wcm}^{-2}$ intensity range is produced using 800 simulations of such a laser-solid interaction from 1D hybrid-PIC. While the simulations required 84,000 CPU-hours to generate, subsequent training occurs on the order of a minute on a single core and prediction takes only a fraction of a second. The model trained on this data is then compared against analytical expectations. The efficiency of training the model and its subsequent ability to distinguish types of noise within the data are analysed, and as a result error bounds on the model are defined.


---
# Predicting the Temperature-Dependent CMC of Surfactant Mixtures with Graph Neural Networks

## 用图神经网络预测表面活性剂混合物的温度相关CMC

Link: https://arxiv.org/abs/2411.02224

arXiv:2411.02224v1 Announce Type: new 
Abstract: Surfactants are key ingredients in foaming and cleansing products across various industries such as personal and home care, industrial cleaning, and more, with the critical micelle concentration (CMC) being of major interest. Predictive models for CMC of pure surfactants have been developed based on recent ML methods, however, in practice surfactant mixtures are typically used due to to performance, environmental, and cost reasons. This requires accounting for synergistic/antagonistic interactions between surfactants; however, predictive ML models for a wide spectrum of mixtures are missing so far. Herein, we develop a graph neural network (GNN) framework for surfactant mixtures to predict the temperature-dependent CMC. We collect data for 108 surfactant binary mixtures, to which we add data for pure species from our previous work [Brozos et al. (2024), J. Chem. Theory Comput.]. We then develop and train GNNs and evaluate their accuracy across different prediction test scenarios for binary mixtures relevant to practical applications. The final GNN models demonstrate very high predictive performance when interpolating between different mixture compositions and for new binary mixtures with known species. Extrapolation to binary surfactant mixtures where either one or both surfactant species are not seen before, yields accurate results for the majority of surfactant systems. We further find superior accuracy of the GNN over a semi-empirical model based on activity coefficients, which has been widely used to date. We then explore if GNN models trained solely on binary mixture and pure species data can also accurately predict the CMCs of ternary mixtures. Finally, we experimentally measure the CMC of 4 commercial surfactants that contain up to four species and industrial relevant mixtures and find a very good agreement between measured and predicted CMC values.


---
# Braided interferometer mesh for robust photonic matrix-vector multiplications with non-ideal components

## 用于具有非理想分量的鲁棒光子矩阵矢量乘法的编织干涉仪网格

Link: https://arxiv.org/abs/2411.02243

arXiv:2411.02243v1 Announce Type: new 
Abstract: Matrix-vector multiplications (MVMs) are essential for a wide range of applications, particularly in modern machine learning and quantum computing. In photonics, there is growing interest in developing architectures capable of performing linear operations with high speed, low latency, and minimal loss. Traditional interferometric photonic architectures, such as the Clements design, have been extensively used for MVM operations. However, as these architectures scale, improving stability and robustness becomes critical. In this paper, we introduce a novel photonic braid interferometer architecture that outperforms both the Clements and Fldzhyan designs in these aspects. Using numerical simulations, we evaluate the performance of these architectures under ideal conditions and systematically introduce non-idealities such as insertion losses, beam splitter imbalances, and crosstalk. The results demonstrate that the braid architecture offers superior robustness due to its symmetrical design and reduced layer count. Further analysis shows that the braid architecture is particularly advantageous in large-scale implementations, delivering better performance as the size of the interferometer increases. We also assess the footprint and total insertion losses of each architecture. Although waveguide crossings in the braid architecture slightly increase the footprint and insertion loss, recent advances in crossing technology significantly minimize these effects. Our study suggests that the braid architecture is a robust solution for photonic neuromorphic computing, maintaining high fidelity in realistic conditions where imperfections are inevitable.


---
# Machine-learned nodal structures of Fermion systems

## 费米子系统的机器学习节点结构

Link: https://arxiv.org/abs/2411.02257

arXiv:2411.02257v1 Announce Type: new 
Abstract: A major challenge in quantum physics is the accurate simulation of fermionic systems, particularly those involving strong correlations. While effective for bosonic systems, traditional quantum Monte Carlo methods encounter the notorious sign problem when applied to Fermions, often resulting in biased outcomes through the fixed-node approximation. This work demonstrates the potential of machine learning techniques to address these limitations by allowing nodal structures to be learned through gradient descent optimization iterations and the variational algorithm. Using a neural network to represent the wave function, we focus on quantum dots containing up to 30 electrons. The results show a significant reduction in the variational bias, achieving greater accuracy and a lower ground state energy than diffusion Monte Carlo with the fixed-node approximation. Our approach paves the way for precise and accurate property predictions in fermionic strongly correlated systems, advancing fundamental understanding and applications in quantum technologies.


---
# Designing a Dataset for Convolutional Neural Networks to Predict Space Groups Consistent with Extinction Laws

## 为卷积神经网络设计数据集以预测符合灭绝定律的空间群

Link: https://arxiv.org/abs/2411.00803

arXiv:2411.00803v1 Announce Type: cross 
Abstract: In this paper, we utilize a dataset composed of one-dimensional powder diffraction patterns to train Convolutional Neural Networks for predicting space groups. We used a new strategy to design the dataset, the diffraction pattern was calculated based the lattice parameters and the Extinction Laws, instead of the traditional strategy that generating it from the crystallographic database. This paper demonstrated that the new strategy is more reasonable than the traditional one. As a result, the model trained on the cubic and tetragonal training set from the newly designed dataset achieves prediction accuracy that matches the theoretical maximums calculated based on Extinction Laws. This result demonstrates that the machine learning based prediction can be physically reasonable and reliable. Additionally, the model trained on our new designed dataset shows better generalization capability than the one trained on a traditionally designed dataset.


---
# Automatic feature selection and weighting using Differentiable Information Imbalance

## 使用可微信息不平衡的自动特征选择和加权

Link: https://arxiv.org/abs/2411.00851

arXiv:2411.00851v1 Announce Type: cross 
Abstract: Feature selection is a common process in many applications, but it is accompanied by uncertainties such as: What is the optimal dimensionality of an interpretable, reduced feature space to retain a maximum amount of information? How to account for different units of measure in features? How to weight different features according to their importance? To address these challenges, we introduce the Differentiable Information Imbalance (DII), an automatic data analysis method to rank information content between sets of features. Based on the nearest neighbors according to distances in the ground truth feature space, the method finds a low-dimensional subset of the input features, within which the pairwise distance relations are most similar to the ground truth. By employing the Differentiable Information Imbalance as a loss function, the relative feature weights of the inputs are optimized, simultaneously performing unit alignment and relative importance scaling, while preserving interpretability. Furthermore, this method can generate sparse solutions and determine the optimal size of the reduced feature space. We illustrate the usefulness of this approach on two prototypical benchmark problems: (1) Identifying a small set of collective variables capable of describing the conformational space of a biomolecule, and (2) selecting a subset of features for training a machine-learning force field. The results highlight the potential of the Differentiable Information Imbalance in addressing feature selection challenges and optimizing dimensionality in various applications. The method is implemented in the Python library DADApy.


---
# Zero-Shot Self-Consistency Learning for Seismic Irregular Spatial Sampling Reconstruction

## 用于地震不规则空间采样重建的零拍自洽学习

Link: https://arxiv.org/abs/2411.00911

arXiv:2411.00911v1 Announce Type: cross 
Abstract: Seismic exploration is currently the most important method for understanding subsurface structures. However, due to surface conditions, seismic receivers may not be uniformly distributed along the measurement line, making the entire exploration work difficult to carry out. Previous deep learning methods for reconstructing seismic data often relied on additional datasets for training. While some existing methods do not require extra data, they lack constraints on the reconstruction data, leading to unstable reconstruction performance. In this paper, we proposed a zero-shot self-consistency learning strategy and employed an extremely lightweight network for seismic data reconstruction. Our method does not require additional datasets and utilizes the correlations among different parts of the data to design a self-consistency learning loss function, driving a network with only 90,609 learnable parameters. We applied this method to experiments on the USGS National Petroleum Reserve-Alaska public dataset and the results indicate that our proposed approach achieved good reconstruction results. Additionally, our method also demonstrates a certain degree of noise suppression, which is highly beneficial for large and complex seismic exploration tasks.


---
# Autoencoders for At-Source Data Reduction and Anomaly Detection in High Energy Particle Detectors

## 用于高能粒子检测器中的源数据缩减和异常检测的自动编码器

Link: https://arxiv.org/abs/2411.01118

arXiv:2411.01118v1 Announce Type: cross 
Abstract: Detectors in next-generation high-energy physics experiments face several daunting requirements: high data rates, damaging radiation exposure, and stringent constraints on power, space, and latency. To address these challenges, machine learning in readout electronics can be leveraged for smart detector designs, enabling intelligent inference and data reduction at-source. Autoencoders offer a variety of benefits for front-end readout; an on-sensor encoder can perform efficient lossy data compression while simultaneously providing a latent space representation that can be used for anomaly detection. Results are presented from low-latency and resource-efficient autoencoders for front-end data processing in a futuristic silicon pixel detector. Encoder-based data compression is found to preserve good performance of off-detector analysis while significantly reducing the off-detector data rate as compared to a similarly sized data filtering approach. Furthermore, the latent space information is found to be a useful discriminator in the context of real-time sensor defect monitoring. Together, these results highlight the multifaceted utility of autoencoder-based front-end readout schemes and motivate their consideration in future detector designs.


---
# Combining graph deep learning and London dispersion interatomic potentials: A case study on pnictogen chalcohalides

## 结合图深度学习和伦敦色散原子间势: 以pnictogen硫属卤化物为例

Link: https://arxiv.org/abs/2411.01197

arXiv:2411.01197v1 Announce Type: cross 
Abstract: Machine-learning interatomic potential models based on graph neural network architectures have the potential to make atomistic materials modeling widely accessible due to their computational efficiency, scalability, and broad applicability. The training datasets for many such models are derived from density-functional theory calculations, typically using a semilocal exchange-correlation functional. As a result, long-range interactions such as London dispersion are often missing in these models. We investigate whether this missing component can be addressed by combining a graph deep learning potential with semiempirical dispersion models. We assess this combination by deriving the equations of state for layered pnictogen chalcohalides BiTeBr and BiTeI and performing crystal structure optimizations for a broader set of V-VI-VII compounds with various stoichiometries, many of which possess van der Waals gaps. We characterize the optimized crystal structures by calculating their X-ray diffraction patterns and radial distribution function histograms, which are also used to compute Earth mover's distances to quantify the dissimilarity between the optimized and corresponding experimental structures. We find that dispersion-corrected graph deep learning potentials generally (though not universally) provide a more realistic description of these compounds due to the inclusion of van der Waals attractions. In particular, their use results in systematic improvements in predicting not only the van der Waals gap but also the layer thickness in layered V-VI-VII compounds. Our results demonstrate that the combined potentials studied here, derived from a straightforward approach that neither requires fine-tuning the training nor refitting the potential parameters, can significantly improve the description of layered polar crystals.


---
# Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary Refinement Network

## 基于辅助细化网络的vSHARP心脏MRI深度多对比重建

Link: https://arxiv.org/abs/2411.01291

arXiv:2411.01291v1 Announce Type: cross 
Abstract: Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth insights into cardiac structure and function. Multi-contrast CMRI (MCCMRI), which acquires sequences with varying contrast weightings, significantly enhances diagnostic capabilities by capturing a wide range of cardiac tissue characteristics. However, MCCMRI is often constrained by lengthy acquisition times and susceptibility to motion artifacts. To mitigate these challenges, accelerated imaging techniques that use k-space undersampling via different sampling schemes at acceleration factors have been developed to shorten scan durations. In this context, we propose a deep learning-based reconstruction method for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI. Our approach integrates the state-of-the-art vSHARP model, which utilizes half-quadratic variable splitting and ADMM optimization, with a Variational Network serving as an Auxiliary Refinement Network (ARN) to better adapt to the diverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed into the ARN, which produces an initial prediction for the denoising step used by vSHARP. This, along with the subsampled k-space, is then used by vSHARP to generate high-quality 2D sequence predictions. Our method outperforms traditional reconstruction techniques and other vSHARP-based models.


---
# Pre-trained Molecular Language Models with Random Functional Group Masking

## 具有随机官能团掩蔽的预训练分子语言模型

Link: https://arxiv.org/abs/2411.01401

arXiv:2411.01401v1 Announce Type: cross 
Abstract: Recent advancements in computational chemistry have leveraged the power of trans-former-based language models, such as MoLFormer, pre-trained using a vast amount of simplified molecular-input line-entry system (SMILES) sequences, to understand and predict molecular properties and activities, a critical step in fields like drug discovery and materials science. To further improve performance, researchers have introduced graph neural networks with graph-based molecular representations, such as GEM, incorporating the topology, geometry, 2D or even 3D structures of molecules into pre-training. While most of molecular graphs in existing studies were automatically converted from SMILES sequences, it is to assume that transformer-based language models might be able to implicitly learn structure-aware representations from SMILES sequences. In this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular \underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES subsequences corresponding to specific molecular \underline{\em F}unctional \underline{\em G}roups to incorporate structure information of atoms during the pre-training phase. This technique aims to compel the model to better infer molecular structures and properties, thus enhancing its predictive capabilities. Extensive experimental evaluations across 11 benchmark classification and regression tasks in the chemical domain demonstrate the robustness and superiority of \ours{}. Our findings reveal that \ours{} outperforms existing pre-training models, either based on SMILES or graphs, in 9 out of the 11 downstream tasks, ranking as a close second in the remaining ones.


---
# Are EEG functional networks really describing the brain? A comparison with other information-processing complex systems

## 脑电图功能网络真的描述了大脑吗？与其他信息处理复杂系统的比较

Link: https://arxiv.org/abs/2411.01522

arXiv:2411.01522v1 Announce Type: cross 
Abstract: Functional networks representing human brain dynamics have become a standard tool in neuroscience, providing an accessible way of depicting the computation performed by the brain in healthy and pathological conditions. Yet, these networks share multiple characteristics with those representing other natural and man-made complex systems, leading to the question of whether they are actually capturing the uniqueness of the human brain. By resorting to a large set of data representing multiple financial, technological, social, and natural complex systems, and by relying on Deep Learning classification models, we show how they are highly similar. We specifically reach the conclusion that, under some general reconstruction methodological choices, it is as difficult to understand whether a network represents a human brain or a financial market, as to diagnose a major pathology. This suggests that functional networks are describing information processing mechanisms that are common across complex systems; but that are not currently defining the uniqueness of the human mind. We discuss the consequence of these findings for neuroscience and complexity science in general, and suggest future avenues for exploring this interesting topic.


---
# Integrating Graph Neural Networks and Many-Body Expansion Theory for Potential Energy Surfaces

## 势能面的图神经网络和多体扩张理论的集成

Link: https://arxiv.org/abs/2411.01578

arXiv:2411.01578v1 Announce Type: cross 
Abstract: Rational design of next-generation functional materials relied on quantitative predictions of their electronic structures beyond single building blocks. First-principles quantum mechanical (QM) modeling became infeasible as the size of a material grew beyond hundreds of atoms. In this study, we developed a new computational tool integrating fragment-based graph neural networks (FBGNN) into the fragment-based many-body expansion (MBE) theory, referred to as FBGNN-MBE, and demonstrated its capacity to reproduce full-dimensional potential energy surfaces (FD-PES) for hierarchic chemical systems with manageable accuracy, complexity, and interpretability. In particular, we divided the entire system into basic building blocks (fragments), evaluated their single-fragment energies using a first-principles QM model and attacked many-fragment interactions using the structure-property relationships trained by FBGNNs. Our development of FBGNN-MBE demonstrated the potential of a new framework integrating deep learning models into fragment-based QM methods, and marked a significant step towards computationally aided design of large functional materials.


---
# Lorentz-Equivariant Quantum Graph Neural Network for High-Energy Physics

## 用于高能物理的洛伦兹等变量子图神经网络

Link: https://arxiv.org/abs/2411.01641

arXiv:2411.01641v1 Announce Type: cross 
Abstract: The rapid data surge from the high-luminosity Large Hadron Collider introduces critical computational challenges requiring novel approaches for efficient data processing in particle physics. Quantum machine learning, with its capability to leverage the extensive Hilbert space of quantum hardware, offers a promising solution. However, current quantum graph neural networks (GNNs) lack robustness to noise and are often constrained by fixed symmetry groups, limiting adaptability in complex particle interaction modeling. This paper demonstrates that replacing the Lorentz Group Equivariant Block modules in LorentzNet with a dressed quantum circuit significantly enhances performance despite using nearly 5.5 times fewer parameters. Our Lorentz-Equivariant Quantum Graph Neural Network (Lorentz-EQGNN) achieved 74.00% test accuracy and an AUC of 87.38% on the Quark-Gluon jet tagging dataset, outperforming the classical and quantum GNNs with a reduced architecture using only 4 qubits. On the Electron-Photon dataset, Lorentz-EQGNN reached 67.00% test accuracy and an AUC of 68.20%, demonstrating competitive results with just 800 training samples. Evaluation of our model on generic MNIST and FashionMNIST datasets confirmed Lorentz-EQGNN's efficiency, achieving 88.10% and 74.80% test accuracy, respectively. Ablation studies validated the impact of quantum components on performance, with notable improvements in background rejection rates over classical counterparts. These results highlight Lorentz-EQGNN's potential for immediate applications in noise-resilient jet tagging, event classification, and broader data-scarce HEP tasks.


---
# GraphXForm: Graph transformer for computer-aided molecular design with application to extraction

## GraphXForm: 用于计算机辅助分子设计的图形转换器，可用于提取

Link: https://arxiv.org/abs/2411.01667

arXiv:2411.01667v1 Announce Type: cross 
Abstract: Generative deep learning has become pivotal in molecular design for drug discovery and materials science. A widely used paradigm is to pretrain neural networks on string representations of molecules and fine-tune them using reinforcement learning on specific objectives. However, string-based models face challenges in ensuring chemical validity and enforcing structural constraints like the presence of specific substructures. We propose to instead combine graph-based molecular representations, which can naturally ensure chemical validity, with transformer architectures, which are highly expressive and capable of modeling long-range dependencies between atoms. Our approach iteratively modifies a molecular graph by adding atoms and bonds, which ensures chemical validity and facilitates the incorporation of structural constraints. We present GraphXForm, a decoder-only graph transformer architecture, which is pretrained on existing compounds and then fine-tuned using a new training algorithm that combines elements of the deep cross-entropy method with self-improvement learning from language modeling, allowing stable fine-tuning of deep transformers with many layers. We evaluate GraphXForm on two solvent design tasks for liquid-liquid extraction, showing that it outperforms four state-of-the-art molecular design techniques, while it can flexibly enforce structural constraints or initiate the design from existing molecular structures.


---
# Atomic-scale 3D structural dynamics and functional degradation of Pt alloy nanocatalysts

## Pt合金纳米催化剂的原子尺度三维结构动力学和功能降解

Link: https://arxiv.org/abs/2411.01727

arXiv:2411.01727v1 Announce Type: cross 
Abstract: Pt-based electrocatalysts are the primary choice for fuel cells due to their superior oxygen reduction reaction (ORR) activity. To enhance ORR performance and durability, extensive studies have investigated transition metal alloying, doping, and shape control to optimize the three key governing factors for ORR: geometry, local chemistry, and strain of their surface and subsurface. However, systematic optimization remains incomplete, as it requires an atomic-scale understanding of these factors and their dynamics over potential cycling, as well as their relationship to ORR activity. Here, we implement neural network-assisted atomic electron tomography to measure the 3D atomic structural dynamics and their effects on the functional degradation of PtNi alloy catalysts. Our results reveal that PtNi catalysts undergo shape changes, surface alloying, and strain relaxation during cycling, which can be effectively mitigated by Ga doping. By combining geometry, local chemistry, and strain analysis, we calculated the changes in ORR activity over thousands of cycles and observed that Ga doping leads to higher initial activity and greater stability. These findings offer a pathway to understanding 3D atomic structural dynamics and their relation to ORR activity during cycling, paving the way for the systematic design of durable, high-efficiency nanocatalysts.


---
# Solute diffusion calculation in Fe-Si and Fe-Cr-Si multicomponent alloys

## Fe-si和fe-cr-si多元合金中的溶质扩散计算

Link: https://arxiv.org/abs/2411.02053

arXiv:2411.02053v1 Announce Type: cross 
Abstract: Diffusion plays a key role in microstructure evolution at multicomponent alloys: diffusion controls the kinetics of phase transformations and alloy homogenization. This study aims at developing computationally efficient approaches to estimate the solute diffusion coefficients in two-component systems. We consider silicon as the solute example because it is highly used in industrial steels. We demonstrate that the silicon jump frequency may be calculated with the bond potential instead of the more computationally expensive machine learning potential in Fe-Si and Fe-Cr-Si alloys. We show that the silicon jump frequency can be estimated from thermodynamic simulations for the bond potential without kinetic simulations. The silicon correlation factor slightly depends on silicon concentration and can be approximately estimated by the analytical nine-frequency model.


---
# Intrinsic Dimensionality of Fermi-Pasta-Ulam-Tsingou High-Dimensional Trajectories Through Manifold Learning

## 基于流形学习的费米-意大利面-乌兰-青豆高维轨迹的内在维数

Link: https://arxiv.org/abs/2411.02058

arXiv:2411.02058v1 Announce Type: cross 
Abstract: A data-driven approach based on unsupervised machine learning is proposed to infer the intrinsic dimensions $m^{\ast}$ of the high-dimensional trajectories of the Fermi-Pasta-Ulam-Tsingou (FPUT) model. Principal component analysis (PCA) is applied to trajectory data consisting of $n_s = 4,000,000$ datapoints, of the FPUT $\beta$ model with $N = 32$ coupled oscillators, revealing a critical relationship between $m^{\ast}$ and the model's nonlinear strength. For weak nonlinearities, $m^{\ast} \ll n$, where $n = 2N$. In contrast, for strong nonlinearities, $m^{\ast} \rightarrow n - 1$, consistently with the ergodic hypothesis. Furthermore, one of the potential limitations of PCA is addressed through an analysis with t-distributed stochastic neighbor embedding ($t$-SNE). Accordingly, we found strong evidence suggesting that the datapoints lie near or on a curved low-dimensional manifold for weak nonlinearities.


---
# Towards certification: A complete statistical validation pipeline for supervised learning in industry

## 走向认证: 用于工业监督学习的完整统计验证管道

Link: https://arxiv.org/abs/2411.02075

arXiv:2411.02075v1 Announce Type: cross 
Abstract: Methods of Machine and Deep Learning are gradually being integrated into industrial operations, albeit at different speeds for different types of industries. The aerospace and aeronautical industries have recently developed a roadmap for concepts of design assurance and integration of neural network-related technologies in the aeronautical sector. This paper aims to contribute to this paradigm of AI-based certification in the context of supervised learning, by outlining a complete validation pipeline that integrates deep learning, optimization and statistical methods. This pipeline is composed by a directed graphical model of ten steps. Each of these steps is addressed by a merging key concepts from different contributing disciplines (from machine learning or optimization to statistics) and adapting them to an industrial scenario, as well as by developing computationally efficient algorithmic solutions. We illustrate the application of this pipeline in a realistic supervised problem arising in aerostructural design: predicting the likelikood of different stress-related failure modes during different airflight maneuvers based on a (large) set of features characterising the aircraft internal loads and geometric parameters.


---
# Unsupervised detection of semantic correlations in big data

## 大数据中语义关联的无监督检测

Link: https://arxiv.org/abs/2411.02126

arXiv:2411.02126v1 Announce Type: cross 
Abstract: In real-world data, information is stored in extremely large feature vectors. These variables are typically correlated due to complex interactions involving many features simultaneously. Such correlations qualitatively correspond to semantic roles and are naturally recognized by both the human brain and artificial neural networks. This recognition enables, for instance, the prediction of missing parts of an image or text based on their context. We present a method to detect these correlations in high-dimensional data represented as binary numbers. We estimate the binary intrinsic dimension of a dataset, which quantifies the minimum number of independent coordinates needed to describe the data, and is therefore a proxy of semantic complexity. The proposed algorithm is largely insensitive to the so-called curse of dimensionality, and can therefore be used in big data analysis. We test this approach identifying phase transitions in model magnetic systems and we then apply it to the detection of semantic correlations of images and text inside deep neural networks.


---
# La Serena School for Data Science and the Spanish Virtual Observatory Schools: Initiatives Based on Hands on Experience

## La Serena数据科学学院和西班牙虚拟天文台学校: 基于实践经验的举措

Link: https://arxiv.org/abs/2411.02247

arXiv:2411.02247v1 Announce Type: cross 
Abstract: The worlds of Data Science (including big and/or federated data, machine learning, etc) and Astrophysics started merging almost two decades ago. For instance, around 2005, international initiatives such as the Virtual Observatory framework rose to standardize the way we publish and transfer data, enabling new tools such as VOSA (SED Virtual Observatory Analyzer) to come to existence and remain relevant today. More recently, new facilities like the Vera Rubin Observatory, serve as motivation to develop efficient and extremely fast (very often deep learning based) methodologies in order to fully exploit the informational content of the vast Legacy Survey of Space and Time (LSST) dataset. However, fundamental changes in the way we explore and analyze data cannot permeate in the "astrophysical sociology and idiosyncrasy" without adequate training. In this talk, I will focus on one specific initiative that has been extremely successful and is based on "learning by doing": the La Serena School for Data Science. I will also briefly touch on a different successful approach: a series of schools organized by the Spanish Virtual Observatory. The common denominator among the two kinds of schools is to present the students with real scientific problems that benefit from the concepts / methodologies taught. On the other hand, the demographics targeted by both initiatives vary significantly and can represent examples of two "flavours" to be followed by others.


---
# Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking

## 具有人工智能和强化学习的纳米机器人仿真，用于高级癌细胞检测和跟踪

Link: https://arxiv.org/abs/2411.02345

arXiv:2411.02345v1 Announce Type: cross 
Abstract: Nanorobots are a promising development in targeted drug delivery and the treatment of neurological disorders, with potential for crossing the blood-brain barrier (BBB). These small devices leverage advancements in nanotechnology and bioengineering for precise navigation and targeted payload delivery, particularly for conditions like brain tumors, Alzheimer's disease, and Parkinson's disease. Recent progress in artificial intelligence (AI) and machine learning (ML) has improved the navigation and effectiveness of nanorobots, allowing them to detect and interact with cancer cells through biomarker analysis. This study presents a new reinforcement learning (RL) framework for optimizing nanorobot navigation in complex biological environments, focusing on cancer cell detection by analyzing the concentration gradients of surrounding biomarkers. We utilize a computer simulation model to explore the behavior of nanorobots in a three-dimensional space with cancer cells and biological barriers. The proposed method uses Q-learning to refine movement strategies based on real-time biomarker concentration data, enabling nanorobots to autonomously navigate to cancerous tissues for targeted drug delivery. This research lays the groundwork for future laboratory experiments and clinical applications, with implications for personalized medicine and less invasive cancer treatments. The integration of intelligent nanorobots could revolutionize therapeutic strategies, reducing side effects and enhancing treatment effectiveness for cancer patients. Further research will investigate the practical deployment of these technologies in medical settings, aiming to unlock the full potential of nanorobotics in healthcare.


---
# Network community detection via neural embeddings

## 基于神经嵌入的网络社区检测

Link: https://arxiv.org/abs/2306.13400

arXiv:2306.13400v2 Announce Type: replace 
Abstract: Recent advances in machine learning research have produced powerful neural graph embedding methods, which learn useful, low-dimensional vector representations of network data. These neural methods for graph embedding excel in graph machine learning tasks and are now widely adopted. However, how and why these methods work -- particularly how network structure gets encoded in the embedding -- remain largely unexplained. Here, we show that node2vec -- shallow, linear neural network -- encodes communities into separable clusters better than random partitioning down to the information-theoretic detectability limit for the stochastic block models. We show that this is due to the equivalence between the embedding learned by node2vec and the spectral embedding via the eigenvectors of the symmetric normalized Laplacian matrix. Numerical simulations demonstrate that node2vec is capable of learning communities on sparse graphs generated by the stochastic blockmodel, as well as on sparse degree-heterogeneous networks. Our results highlight the features of graph neural networks that enable them to separate communities in embedding space.


---
# Uncertainty-biased molecular dynamics for learning uniformly accurate interatomic potentials

## 用于学习均匀精确的原子间势的不确定性偏置分子动力学

Link: https://arxiv.org/abs/2312.01416

arXiv:2312.01416v2 Announce Type: replace 
Abstract: Efficiently creating a concise but comprehensive data set for training machine-learned interatomic potentials (MLIPs) is an under-explored problem. Active learning, which uses biased or unbiased molecular dynamics (MD) to generate candidate pools, aims to address this objective. Existing biased and unbiased MD-simulation methods, however, are prone to miss either rare events or extrapolative regions -- areas of the configurational space where unreliable predictions are made. This work demonstrates that MD, when biased by the MLIP's energy uncertainty, simultaneously captures extrapolative regions and rare events, which is crucial for developing uniformly accurate MLIPs. Furthermore, exploiting automatic differentiation, we enhance bias-forces-driven MD with the concept of bias stress. We employ calibrated gradient-based uncertainties to yield MLIPs with similar or, sometimes, better accuracy than ensemble-based methods at a lower computational cost. Finally, we apply uncertainty-biased MD to alanine dipeptide and MIL-53(Al), generating MLIPs that represent both configurational spaces more accurately than models trained with conventional MD.


---
# Prediction of turbulent channel flow using Fourier neural operator-based machine-learning strategy

## 基于傅里叶神经算子的机器学习策略预测湍流通道流量

Link: https://arxiv.org/abs/2403.03051

arXiv:2403.03051v4 Announce Type: replace 
Abstract: Fast and accurate predictions of turbulent flows are of great importance in the science and engineering field. In this paper, we investigate the implicit U-Net enhanced Fourier neural operator (IUFNO) in the stable prediction of long-time dynamics of three-dimensional (3D) turbulent channel flows. The trained IUFNO models are tested in the large-eddy simulations (LES) at coarse grids for three friction Reynolds numbers: $Re_{\tau}\approx180$, $395$ and $590$. The adopted near-wall mesh grids are tangibly coarser than the general requirements for wall-resolved LES. Compared to the original Fourier neural operator (FNO), the implicit FNO (IFNO) and U-Net enhanced FNO (UFNO), the IUFNO model has a much better long-term predictive ability. The numerical experiments show that the IUFNO framework outperforms the traditional dynamic Smagorinsky model (DSM) and the wall-adapted local eddy-viscosity (WALE) model in the predictions of a variety of flow statistics and structures, including the mean and fluctuating velocities, the probability density functions (PDFs) and joint PDF of velocity fluctuations, the Reynolds stress profile, the kinetic energy spectrum, and the Q-criterion (vortex structures). Meanwhile, the trained IUFNO models are computationally much faster than the traditional LES models. Thus, the IUFNO model is a promising approach for the fast prediction of wall-bounded turbulent flow.


---
# Physics-informed Shadowgraph Network: An End-to-end Density Field Reconstruction Method

## 物理信息阴影图网络: 一种端到端的密度场重建方法

Link: https://arxiv.org/abs/2410.20203

arXiv:2410.20203v2 Announce Type: replace 
Abstract: This study presents a novel approach for quantificationally reconstructing density fields from shadowgraph images using physics-informed neural networks


---
# Classically studied coherent structures only paint a partial picture of wall-bounded turbulence

## 经典研究的相干结构仅描绘了壁界湍流的部分图片

Link: https://arxiv.org/abs/2410.23189

arXiv:2410.23189v2 Announce Type: replace 
Abstract: For the last 140 years, the mechanisms of transport and dissipation of energy in a turbulent flow have not been completely understood due to the complexity of this phenomenon. The dissipation of energy due to turbulence is significative, and understanding turbulence physics is crucial for fighting the present climate emergency. Previous research has focused on analyzing the so-called coherent structures of the flow (Q events, streaks, and vortices), which are regions of high turbulence transport, high/low streamwise fluctuation, and rotation, respectively. However, the connection between these classically studied structures and the flow development is still uncertain. To fill this gap, here we show a data-driven methodology for objectively identifying high-importance regions in a turbulent flow. A deep-learning model is trained to predict a future state of a turbulent channel flow and the gradient-SHAP explainability algorithm is used to calculate the importance of each grid point for such a prediction. Finally, high-importance regions are computed using the SHAP data, analyzing and comparing their characteristics with those of the other coherent structures. The SHAP analysis provides an objective way to identify the regions of highest importance in the turbulent flow, which exhibit different levels of agreement with the classically studied structures.


---
# Higher-Rank Irreducible Cartesian Tensors for Equivariant Message Passing

## 等变消息传递的高阶不可约笛卡尔张量

Link: https://arxiv.org/abs/2405.14253

arXiv:2405.14253v2 Announce Type: replace-cross 
Abstract: The ability to perform fast and accurate atomistic simulations is crucial for advancing the chemical sciences. By learning from high-quality data, machine-learned interatomic potentials achieve accuracy on par with ab initio and first-principles methods at a fraction of their computational cost. The success of machine-learned interatomic potentials arises from integrating inductive biases such as equivariance to group actions on an atomic system, e.g., equivariance to rotations and reflections. In particular, the field has notably advanced with the emergence of equivariant message passing. Most of these models represent an atomic system using spherical tensors, tensor products of which require complicated numerical coefficients and can be computationally demanding. Cartesian tensors offer a promising alternative, though state-of-the-art methods lack flexibility in message-passing mechanisms, restricting their architectures and expressive power. This work explores higher-rank irreducible Cartesian tensors to address these limitations. We integrate irreducible Cartesian tensor products into message-passing neural networks and prove the equivariance and traceless property of the resulting layers. Through empirical evaluations on various benchmark data sets, we consistently observe on-par or better performance than that of state-of-the-art spherical and Cartesian models.


---
# Predicting Ground State Properties: Constant Sample Complexity and Deep Learning Algorithms

## 预测基态属性: 恒定样本复杂度和深度学习算法

Link: https://arxiv.org/abs/2405.18489

arXiv:2405.18489v2 Announce Type: replace-cross 
Abstract: A fundamental problem in quantum many-body physics is that of finding ground states of local Hamiltonians. A number of recent works gave provably efficient machine learning (ML) algorithms for learning ground states. Specifically, [Huang et al. Science 2022], introduced an approach for learning properties of the ground state of an $n$-qubit gapped local Hamiltonian $H$ from only $n^{\mathcal{O}(1)}$ data points sampled from Hamiltonians in the same phase of matter. This was subsequently improved by [Lewis et al. Nature Communications 2024], to $\mathcal{O}(\log n)$ samples when the geometry of the $n$-qubit system is known. In this work, we introduce two approaches that achieve a constant sample complexity, independent of system size $n$, for learning ground state properties. Our first algorithm consists of a simple modification of the ML model used by Lewis et al. and applies to a property of interest known beforehand. Our second algorithm, which applies even if a description of the property is not known, is a deep neural network model. While empirical results showing the performance of neural networks have been demonstrated, to our knowledge, this is the first rigorous sample complexity bound on a neural network model for predicting ground state properties. We also perform numerical experiments that confirm the improved scaling of our approach compared to earlier results.


---
# Enhancing 3D Planetary Atmosphere Simulations with a Surrogate Radiative Transfer Model

## 使用替代辐射传输模型增强3D行星大气模拟

Link: https://arxiv.org/abs/2407.08556

arXiv:2407.08556v2 Announce Type: replace-cross 
Abstract: This work introduces an approach to enhancing the computational efficiency of 3D atmospheric simulations by integrating a machine-learned surrogate model into the OASIS global circulation model (GCM). Traditional GCMs, which are based on repeatedly numerically integrating physical equations governing atmospheric processes across a series of time-steps, are time-intensive, leading to compromises in spatial and temporal resolution of simulations. This research improves upon this limitation, enabling higher resolution simulations within practical timeframes. Speeding up 3D simulations holds significant implications in multiple domains. Firstly, it facilitates the integration of 3D models into exoplanet inference pipelines, allowing for robust characterisation of exoplanets from a previously unseen wealth of data anticipated from JWST and post-JWST instruments. Secondly, acceleration of 3D models will enable higher resolution atmospheric simulations of Earth and Solar System planets, enabling more detailed insights into their atmospheric physics and chemistry. Our method replaces the radiative transfer module in OASIS with a recurrent neural network-based model trained on simulation inputs and outputs. Radiative transfer is typically one of the slowest components of a GCM, thus providing the largest scope for overall model speed-up. The surrogate model was trained and tested on the specific test case of the Venusian atmosphere, to benchmark the utility of this approach in the case of non-terrestrial atmospheres. This approach yields promising results, with the surrogate-integrated GCM demonstrating above 99.0% accuracy and 147 factor GPU speed-up of the entire simulation compared to using the matched original GCM under Venus-like conditions.


---
# Forecasting High-Speed Solar Wind Streams from Solar Images

## 从太阳图像预测高速太阳风流

Link: https://arxiv.org/abs/2410.05068

arXiv:2410.05068v2 Announce Type: replace-cross 
Abstract: The solar wind, a stream of charged particles originating from the Sun and transcending interplanetary space, poses risks to technology and astronauts.In this work, we develop a prediction model to forecast the solar wind speed at the Earth. We focuse on high-speed streams (HSSs) and their solar source regions, coronal holes. As input, we use the coronal hole area, extracted from solar extreme ultraviolet (EUV) images and mapped on a fixed grid, as well as the solar wind speed 27 days before. We use a polynomial regression model and a distribution transformation to predict the solar wind speed with a lead time of four days. Our forecast achieves a root mean square error (RMSE) of 68.1 km/s for the solar wind speed prediction and an RMSE of 76.8 km/s for the HSS peak velocity prediction for 2010 to 2019. We also demonstrate the applicability of our model to the current solar cycle 25 in an operational setting, resulting in an RMSE of 80.3 km/s and an HSS peak velocity RMSE of 92.2 km/s. The study shows that a small number of physical features explains most of the solar wind variation, and that focusing on these features with simple machine learning algorithms even outperforms current approaches based on deep neural networks and MHD simulations. In addition, we explain why the typically used loss function, the mean squared error, systematically underestimates the HSS peak velocities, aggravates operational space weather forecasts, and how a distribution transformation can resolve this issue.


---
# MOSAEC-DB: A comprehensive database of experimental metal-organic frameworks with verified chemical accuracy suitable for molecular simulations

## Mosaec-db: 实验金属有机框架的综合数据库，具有适用于分子模拟的经过验证的化学准确性

Link: https://dx.doi.org/10.26434/chemrxiv-2024-zmq13?rft_dat=source%3Ddrss

Ongoing developments in computational databases seek to improve the accessibility and breadth of high-throughput screening and materials discovery efforts. Their reliance on experimental crystal structures necessitates significant processing prior to computation in order to resolve any crystallographic disorder or partial occupancies and remove any residual solvent molecules in the case of activated porous materials. Contemporary investigations revealed that deficiencies in the experimental characterization and computational preprocessing methods generated considerable occurrence of structural errors in metal-organic framework (MOF) databases. The MOSAEC MOF database (MOSAEC-DB) tackles these structural reliability concerns through utilization of innovative preprocessing and error analysis protocols applying the concepts of oxidation states and formal charge to exclude erroneous MOF crystal structures. Comprising more than 124k crystal structures, this work maintains the largest and most accurate dataset of experimental MOFs ready for immediate deployment in molecular simulations. The databases’ comparative diversity is demonstrated through its enhanced coverage of the periodic table, expansive quantity of structures, and balance of chemical properties relative to existing MOF databases. Chemical and geometric descriptors, as well as DFT electrostatic potential-fitted charges, are included to facilitate subsequent atomistic simulation and machine-learning (ML) studies. Curated subsets—sampled according to their chemical properties and structural uniqueness—are also provided to further enable ML studies in recognition of the strict demand for duplicate elimination and dataset diversity in such applications.


---
# Data-Driven Improvement of Local Hybrid Functionals: Neural-Network-Based Local Mixing Functions and Power-Series Correlation Functionals

## 局部混合泛函的数据驱动改进: 基于神经网络的局部混合函数和幂级数相关泛函

Link: https://dx.doi.org/10.26434/chemrxiv-2024-g3r93?rft_dat=source%3Ddrss

Local hybrid functionals (LHs) are a modern class of density functionals that use a real-space position-dependent admixture of exact exchange (EXX), governed by a local mixing function (LMF). While many model LMFs have been proposed and evaluated over the past 10-20 years, their systematic construction has been hampered by a lack of exact physical constraints on their valence behavior. Here we exploit a data-driven approach and train a new type of "n-LMF" as a relatively shallow neural network. The input features of this n-LMF are of meta-GGA character, while the W4-17 atomization-energy and BH76 reaction-barrier test sets have been used for training. Simply replacing the widely used "t-LMF" of the LH20t functional by the n-LMF provides the LH24n-B95 functional. Augmented by DFT-D4 dispersion corrections, LH24n-B95-D4 remarkably improves the WTMAD-2 value for the large GMTKN55 test suite of general main-group thermochemistry, kinetics and noncovalent interactions (NCIs) from 4.55 kcal/mol to 3.49 kcal/mol. As we found the limited flexibility of the B95c correlation functional to disfavor much further improvement on NCIs, we proceeded to replace it by an optimized B97c-type power-series expansion. This gives the LH24n functional. LH24n-D4 gives a WTMAD-2 value of 3.10 kcal/mol, the so far lowest value of a rung 4 functional in self-consistent calculations. The new functionals perform moderately well for organometallic transition-metal energetics while leaving room for further data-driven improvements in that area. Compared to complete neural-network functionals like DM21, the present more tailored approach to train just the LMF in a flexible but well-defined human-designed LH functional retains the possibility of graphical LMF analyses to gain deeper understanding. We find that both the present n-LMF and the recent x-LMF suppress the so-called gauge problem of local hybrids without adding a calibration function as required for other LMFs like the t-LMF. LMF plots show that this can be traced back to large LMF values in the small-density region between the interacting atoms in NCIs for n- and x-LMFs and low values for the t-LMF. We also find that the trained n-LMF has relatively large values in covalent bonds without deteriorating binding energies. The current approach enables fast and efficient routine self-consistent calculations using n-LMFs in Turbomole. Further routes toward improved functionals are delineated.


---
# In Silico Analysis of Cardiac Disease Protein Biomarkers by Using Aptamers

## 通过使用适体对心脏疾病蛋白质生物标志物进行计算机分析

Link: https://dx.doi.org/10.26434/chemrxiv-2024-5kgkp?rft_dat=source%3Ddrss

Acute myocardial infarction (AMI), also known as a heart attack, is a serious medical condition and a leading cause of death worldwide. The diagnosis of AMI relies on a combination of clinical symptoms, physical examination, electrocardiogram (ECG), and blood tests detecting elevated levels of cardiac disease protein biomarkers indicative of heart muscle injury. Nevertheless, these techniques usually necessitate skilled personnel and pose a significant economic strain. Among these biomarkers, Tumor Necrosis Factor α (TNF-α) has been identified as specific to AMI. Recently, DNA-based aptamers that specifically bind to TNF-α have been developed to detect cardiac diseases. We hypothesize that the high specificity of these aptamers towards the TNF-α protein is due to a specific binding site present on the surface of this soluble protein. Consequently, the TNF-α-aptamer interactions have been investigated by molecular docking simulations. First, the aptamer 3D structures were modeled and docked onto the TNF-α protein. By comparing the TNF-α binding site using machine learning and electrostatic surface potential analysis, the docking results were further verified. Based on these findings, novel aptamers were rationally designed by making chemical mutations and were subsequently docked onto the TNF-α protein. Among these mutate aptamers M4 binds strongly to the protein and can potentially aid in developing TNF-α biomarkers. The current investigation work will facilitate the development of rapid and highly sensitive diagnostic tools for the early detection and monitoring of cardiac diseases using aptamers.


---
# Galvanic Corrosion Underlies Coulombic Efficiency Differences in High-Performing Lithium Metal Battery Electrolytes

## 电化学腐蚀是高性能锂金属电池电解质库仑效率差异的基础

Link: https://dx.doi.org/10.26434/chemrxiv-2024-6g0h2?rft_dat=source%3Ddrss

Current guidelines for electrolyte engineering in lithium metal batteries are based on design metrics such as lithium morphology, electrolyte transport properties, solid electrolyte interphase (SEI) characteristics, and lithium-electrolyte reactivity. In our work, we show that those design metrics fail to account for performance differences in new high-performing electrolytes whereas galvanic corrosion does. This insight regarding the importance of galvanic corrosion is enabled by the combination of machine learning with rigorous experimental characterization. First, we partition our electrolyte data into low and high Coulombic efficiency (CE) segments to obtain an interpretable machine learning model which informs the design of high-performing (high CE) electrolytes. We design new model-guided, high-performing electrolytes and use spectroscopy and electroanalytical methods to demonstrate the weak correlation between common design metrics and performance in the high-performing electrolytes. Our work results in the design of a high-performing electrolyte with a Coulombic efficiency (CE) of 99.6%, a new understanding that common performance indicators are not sufficient for informing the development of high-performing electrolytes, and the identification of galvanic corrosion as an important performance driver in high-performing electrolytes.


---
# Machine learning predicted n-type semiconductor material for H2S gas sensing

## 用于H2S气体传感的机器学习预测n型半导体材料

Link: https://dx.doi.org/10.26434/chemrxiv-2024-jjm8b-v2?rft_dat=source%3Ddrss

Hydrogen sulfide (H2S) can be extremely flammable and hazardous. It is frequently found in industrial settings where individuals face serious dangers to human health and safety, such as in the production of oil and gas, wastewater treatment, and chemical manufacture. H2S can create serious health risks, even at low quantities, such as respiratory failure and fatalities, which makes gas detection imperative. In this study, ML models have been employed to predict how n-type materials doped with various metals—such as Ag, Pd, and Au—will react when they are exposed to hydrogen sulfide (H2S) gas. The tree-based machine learning models used in the study include Gradient Boosting Regression (GBR), Random Forest (RF), and Decision Tree (DT) coupled with several optimization strategies (such as Bayesian optimization, Random Search, and Grid Search). Additionally, the examination involves the utilization of Partial Dependence Plots (PDPs) and Shapley Additive exPlanations (SHAP) to gain insights into the intrinsic mechanisms of the ML model and to elucidate the opaque nature of the ML model, these post-model interpretations elucidate the significance of features in gas sensing.


---
# A New Optimization-Based Framework for Enhanced Feature Selection with the Narwal Optimizer

## 使用Narwal优化器增强特征选择的新的基于优化的框架

Link: https://www.researchsquare.com/article/rs-5304943/latest

The selection of relevant features is a critical step in many machine learning and data analysis tasks, as it can significantly impact the performance and inter-pretability of the resulting models. In this work, we introduce a novel feature selection approach that draws inspiration from the unique movement patterns of the narwhal, a fascinating marine mammal, and the power of binary optimization. The proposed method, named BNO-FS is based on Narwhals Optimizer (NO) which is a new meta-heuristic recently developed recently and never been tested on feature selection problem. A binary version is proposed in this study. A new fitness function is proposed composed of two important terms: the classification accuracy rate obtained by three classifiers and the number of selected features. The algorithm aims to identify the optimal subset of features that maximizes the predictive performance of the model while minimizing the number of selected features. The effectiveness of the Binary Narwhals Optimizer approach is demonstrated through a series of experiments on benchmark datasets, where it is compared to other state-of-the-art feature selection techniques.


---
# Improving CNC Lathe machine Precision through Vibration Analysis for Clamping Error Detection Employing PCA

## 通过振动分析提高数控车床精度，采用PCA进行夹紧误差检测

Link: https://www.researchsquare.com/article/rs-5309749/latest

The vibration generated during mechanical manufacturing can lead to unpredictable variations in product quality, increasing production costs. Extensive research has been conducted to establish standard vibration coefficients and optimize efficient production processes. Various health monitoring methods have been explored, such as dynamic feature detection, machine tool state detection, cutting chatter analysis, and health state feedback for specific machine components. This study focuses on vibration analysis and health diagnostics for NC and traditional lathes, based on vibration signals under different clamping conditions. Five experiments were conducted, increasing spindle speed from 0 to 2000 rpm in 250-rpm increments across three clamping states. Vibration signals were collected using an intelligent prediction and diagnostic system, analyzed in the frequency domain, and validated through root mean square calculations and vibration eigenvalue assessment. Digital filtering was applied to remove outliers, followed by feature extraction and matching. Principal Component Analysis (PCA) was employed to evaluate 37 features and reduce data dimensionality, resulting in a vibration data distribution map across different speeds for each clamping state. The findings demonstrate that the PCA approach effectively identifies changes in vibration patterns, enabling the establishment of a health state feedback dataset for NC lathes based on vibration characteristics


---
# Deep-Multiscale Stratified Aggregation

## 深度多尺度分层聚合

Link: https://www.researchsquare.com/article/rs-5315936/latest

In deep learning based vision tasks, improving multiscale representation by combining shallow and deep features has consistently led to performance gains across a wide range of applications. However, significant discrepancies in both scale and semantic content often occur during the fusion of shallow and deep features. Most existing approaches rely on standard convolutional structures for representing multiscale features, which may not fully capture the complexity of the underlying data. To address this, we propose a novel deep-multiscale stratified aggregation (D-MSA) module, which could improve the extraction and fusion of multiscale features by efficiently aggregating features across multiple receptive fields. The novel D-MSA module was integrated into the YOLO architecture to enhance the capacity for processing complex multiscale features. Experiments on the PASCAL VOC 2012 dataset demonstrate that D-MSA could effectively handle complex multiscale features while improving computational efficiency, making it suitable for object detection in challenging environments.


---
# Stock index trend prediction based on multiscale random forests

## 基于多尺度随机森林的股指趋势预测

Link: https://www.researchsquare.com/article/rs-5295641/latest

This paper describes the implementation of a multiscale bootstrap method to improve the random forest algorithm. We construct a multiscale random forest model with the aim of enhancing the classification accuracy of the conventional random forest method, and we apply it to stock index predictions. First, the basic indicators of the CSI 300 stock index are analyzed through stepwise regression analysis to obtain a smaller number of input indicators. Second, using the multiscale bootstrap method, the training samples are resampled multiple times during the model construction stage to generate multiple random forests. These random forests are integrated to obtain the multiscale random forest. In the prediction stage, the multiscale bootstrap probability is obtained and the unbiased p-value with third-order accuracy is computed through regression analysis and extrapolation. Finally, we apply the proposed method to the original dataset and to the dataset obtained after stepwise regression analysis. The predictive performance of multiscale random forest, ordinary random forest, support vector machine, and weighted k-nearest neighbors models are evaluated in terms of accuracy, precision, recall, and F1 score. The results show that the proposed multiscale random forest model outperforms the other models on the accuracy, precision, and F1 score metrics when using the first dataset, but gives a worse recall value than the support vector machine model. On the second dataset, the proposed multiscale random forest model achieves the highest precision. Therefore, the multiscale random forest prediction model is suitable for stock index forecasting, providing theoretical and technical support for the subsequent construction of quantitative timing strategies, option pricing models, and financial early-warning models of listed companies for higher-level theoretical research and development of new application systems.


---
# Designing and implementing the flipped Classroom Model for teaching first aids course and evaluating it with the Kirkpatrick model

## 设计和实施用于教授第一艾滋病课程的翻转课堂模型，并使用柯克帕特里克模型对其进行评估

Link: https://www.researchsquare.com/article/rs-5291638/latest

Background The use of interactive teaching patterns and appropriate educational design approaches is an essential requirement emphasized in medical education, especially for courses such as first aids. Therefore, the purpose of this study was to design, implement, and evaluate the presentation of a first aid course using the flipped Classroom Model.Methods This scholarly study was conducted for the first aids course in the field of occupational health and safety engineering at Mazandaran University of Medical Sciences, Sari, Iran. For course design, the instructional design model proposed in the study by Elmagzoub and Eltahir (2017) was used, which was a combination of the flipped classroom model and the ADDIE instructional design model stages. Therefore, the study included 5 stages: "planning and needs assessment, programming, coaching, assessing and evaluating, and revising". The first two steps of the Kirkpatrick model were used to evaluate course.Results The results showed that the average student satisfaction score (51.60&amp;thinsp;&amp;plusmn;&amp;thinsp;3.09) was at a satisfactory level. The results of the independent t-test showed that there was no significant difference in satisfaction scores based on gender, marital status, and age (P&amp;thinsp;&amp;gt;&amp;thinsp;0.05). Also, the average score of the students in the post-test was 17.75&amp;thinsp;&amp;plusmn;&amp;thinsp;1.56. Comparing the students' scores in the pre-test and post-test using the paired t-test showed that the average score of the students in the post-test was higher than the pre-test, and the difference between the students' scores was statistically significant (P&amp;thinsp;&amp;lt;&amp;thinsp;0.05).Conclusion Based on the results of the evaluation and the needs assessment data, it can be inferred that having an educational design appropriate for each generation, using interactive teaching approaches, and involving learners in their own learning is both a demand of students and leads to desirable outcomes. Therefore, it is a positive step in improving the quality of education and it is recommended to be included in the educational planning of practical courses as well.


---
# Synergistic Effects of Urban Mitigation and Adaptation Pilot Policies in China: An Analysis Based on Low-Carbon Resilience

## 中国城市减缓与适应试点政策的协同效应 -- 基于低碳韧性的分析

Link: https://www.researchsquare.com/article/rs-5309703/latest

Low-carbon cities and climate resilient cities represent urban development models in China aimed at achieving urban mitigation and adaptation objectives. This study focuses on the dual pilot policy of low-carbon cities and climate resilient cities, establishing a comprehensive evaluation index system for urban low-carbon resilience that encompasses ecological, economic, social, and institutional dimensions. Utilizing panel data from 286 prefecture-level cities and above in China from 2005 to 2021, this study employs Difference-in-Differences, K-means clustering, Double Machine Learning, and a tri-dimensional policy analysis framework of "policy instruments&amp;mdash;policy pathways&amp;mdash;policy objectives." It provides an in-depth assessment of the dual pilot policy's impact through policy synergy effects, policy tool analysis, and key case studies, supplemented by heterogeneity analysis, mechanism analysis, and cluster analysis. Results indicate that the dual pilot policy significantly enhances the low-carbon resilience of pilot cities, outperforming the effects seen in cities with a singular pilot policy. The policy effects vary among different types of pilot cities, with notably significant impacts in cities facing high temperatures, low temperatures, heavy rainfall, and high disaster risks. Cities characterized by higher levels of low-carbon resilience (categorized as MMHM) manifest more consistent policy synergy effects, whereas cities with lower levels of resilience (classified as LLLL) exhibit some disparities. The study also identifies the strengthening of green technology innovation, human capital development, and communication infrastructure construction as key factors enhancing policy effectiveness. Ultimately, this research underscores the importance of the diversity and combination of policy tools, as well as the multidimensionality and synergy of policy objectives, for effective climate action. It recommends that urban managers consider the synergistic effects of climate change mitigation and adaptation measures when formulating climate policies.


---
# An Interpretable Framework for Gastric Cancer Classification Using Multi-Channel Attention Mechanisms and Transfer Learning Approach on Histopathology Images

## 在组织病理学图像上使用多通道注意力机制和迁移学习方法进行胃癌分类的可解释框架

Link: https://www.researchsquare.com/article/rs-5316440/latest

The importance of gastric cancer and the role of deep learning techniques in categorizing gastric cancer histopathology images have recently increased. Identifying the drawbacks of traditional deep learning models, including lack of interpretability, inability to capture complex patterns, lack of adaptability, and sensitivity to noise. We suggest a multi-channel attention mechanism-based framework that can overcome the limitations of conventional deep learning models by dynamically focusing on relevant features, enhancing extraction, and capturing complex relationships in medical data. The proposed framework uses three different attention mechanism channels and convolutional neural networks to extract multichannel features during the classification process. The proposed framework&rsquo;s strong performance is confirmed by comparative experiments conducted on a publicly available Gastric Histopathology Sub-size Image Database, which yielded remarkable classification accuracies of 99.07% and 98.48% on the validation and testing sets, respectively. Additionally, on the HCRF dataset, the framework achieved high classification accuracy of 99.84% and 99.65% on the validation and testing sets, respectively. The effectiveness and interchangeability of the three channels are further confirmed by ablation and interchangeability experiments, highlighting the remarkable performance of the framework in gastric cancer histopathological image classification tasks. This offers an advanced and pragmatic artificial intelligence solution that addresses challenges posed by unique medical image characteristics for intricate image analysis. The proposed approach in artificial intelligence medical engineering demonstrates significant potential for enhancing diagnostic precision by achieving high classification accuracy and treatment outcomes.


---
# Deep Generative Optimization of mRNA Codon Sequences for Enhanced Protein Production and Therapeutic Efficacy

## mRNA密码子序列的深度生成优化，以增强蛋白质的产生和治疗效果

Link: https://www.researchsquare.com/article/rs-5040961/latest

Messenger RNA (mRNA) therapeutics show immense promise, but their efficacy is limited by suboptimal protein expression. Here, we present RiboCode, a deep learning framework that generates mRNA codon sequences for enhanced protein production. RiboCode introduces several advances, including direct learning from large-scale ribosome profiling data, context-aware mRNA optimization and generative exploration of a large sequence space. In silico analysis demonstrate RiboCode&amp;rsquo;s robust predictive accuracy for unseen genes and cellular environments. In vitro experiments show substantial improvements in protein expression, with up to a 72-fold increase, significantly outperforming past methods. In addition, RiboCode achieves cell-type specific expression and demonstrates robust performance across different mRNA formats, including m1&Psi;-modified and circular mRNAs, an important feature for mRNA therapeutics. In vivo mouse studies show that optimized influenza hemagglutinin mRNAs induce ten times stronger neutralizing antibody responses against influenza virus compared to the unoptimized sequence. In an optic nerve crush model, optimized nerve growth factor mRNAs achieve equivalent neuroprotection of retinal ganglion cells at one-fifth the dose of the unoptimized sequence. Collectively, RiboCode represents a paradigm shift from rule-based to data-driven, context-sensitive approach for mRNA therapeutic applications, enabling the development of more potent and dose-efficient treatments.


---
# Design and Evaluation of an Impact-Type Cacao Bean Huller

## 冲击式可可豆壳的设计与评价

Link: https://www.researchsquare.com/article/rs-5385215/latest

The study mainly aimed to develop an impact-type cacao bean hulling machine and evaluate its performance in producing cacao nibs in terms of input capacity, hulling capacity, hulling efficiency, nib recovery, large nib recovery, purity, noise level, and power consumption. The cacao huller was subjected to three varying tangential velocities in the cracking mechanism, specifically at 40m/s, 47m/s, and 54m/s, and using three different volumes of air in the winnowing mechanism with 41m3/hr, 45m3/hr, and 49m3/hr. The data gathered were arranged in a Completely Randomized Design-Two Factorial and comparison among means using Statistical Tool for Agricultural Research (STAR) software. The analysis showed that the tangential speed of the machine significantly affected all parameters except purity and noise level; moreover, the air volume significantly affected the hulling efficiency, nib recovery, large nib recovery, and purity. Impact-type cacao bean huller with 47m/s and 41m3/hr gave the highest input and hulling capacities of 195.60kg/hr and 156.53kg/hr, respectively. Furthermore, the highest hulling efficiency, nib recovery, and large nib recovery of 96.84%, 96.98%, and 86.75%, respectively, were obtained from tangential velocity of 40m/s and volume of air of 41m3/hr. The lowest power consumption and noise level were obtained from the 40m/s and 45m3/hr combination with 3.99kwh and 88.20dB, respectively. Cost analysis showed that the machine was financially feasible with a payback period of 0.24 years and an annual net income of Php410,747.00. When considering mass production of cacao nibs, the most desirable setup of the machine was the combination of 40 m/s tangential velocity and 41 m3/hr volume of air.


---
# A Subsampling Based Neural Network for Spatial Data

## 基于子采样的空间数据神经网络

Link: https://www.researchsquare.com/article/rs-5376863/latest

The application of deep neural networks in geospatial data has become a trending research problem in the present day. A significant amount of statistical research has already been introduced, such as generalized least square optimization by incorporating spatial variance-covariance matrix, considering basis functions in the input nodes of the neural networks, and so on. However, for lattice data, there is no available literature about the utilization of asymptotic analysis of neural networks in regression for spatial data. This article proposes a consistent localized two-layer deep neural network-based regression for spatial data. We have proved the consistency of this deep neural network for bounded and unbounded spatial domains under a fixed sampling design of mixed-increasing spatial regions. We have proved that its asymptotic convergence rate is faster than that of [1]'s neural network and an improved generalization of [2]'s neural network structure. We empirically observe the rate of convergence of discrepancy measures between the empirical probability distribution of observed and predicted data, which will become faster for a less smooth spatial surface. We have applied our asymptotic analysis of deep neural networks to the estimation of the monthly average temperature of major cities in the USA from its satellite image. This application is an effective showcase of non-linear spatial regression. We demonstrate our methodology with simulated lattice data in various scenarios.


---
# A Novel Approach of Ransomware Detection with Dynamic Obfuscation Signature Analysis

## 一种基于动态混淆签名分析的勒索软件检测方法

Link: https://www.researchsquare.com/article/rs-5375812/latest

The exponential rise in ransomware attacks has intensified the demand for sophisticated detection methodologies capable of addressing complex evasion tactics. Dynamic Obfuscation Signature Analysis (DOSA) offers an adaptive, multi-layered framework designed to counter ransomware&rsquo;s polymorphic transformations through a hybrid approach that combines static analysis, dynamic signature mapping, and machine learning-based adaptation. DOSA&rsquo;s architecture enhances detection accuracy and operational efficiency, with a modular design that supports real-time processing across file-based, network-based, and memory-based detection layers. Experiments demonstrated that DOSA achieved high accuracy rates, maintaining detection efficacy across a diverse array of ransomware variants by continuously evolving signature profiles based on obfuscation patterns. The framework also exhibited substantial resource efficiency, making it suitable for deployment in diverse environments with varied computational constraints. By providing precise and adaptable threat detection, DOSA contributes a significant advancement to the field of ransomware resilience, offering a robust methodology for preemptive ransomware management within modern cybersecurity infrastructures.


---
# Failure Analysis and Size Optimization of CFRP Composite Single-lap Bonded Joints Based on the Influence of Multiple Parameters

## 基于多参数影响的CFRP复合材料单搭接接头失效分析及尺寸优化

Link: https://www.researchsquare.com/article/rs-5295550/latest

This paper had conducted tensile shear tests on single-lap joints (SLJs)bonded structures of carbon fiber reinforced resin matrix (CFRP) composite laminates with different overlap lengths, overlap widths, overlap model, adherend material, and adhesive layer thicknesses under two environments: room temperature dry state (RTD) and elevated temperature wet state (ETW). The failure modes were observed, and load-displacement curves were obtained. The microscopic morphology of the fracture surface was observed by scanning electron microscope (SEM). At the same time, a finite element simulation model was established to simulate the damage initiation and evolution process between layers and in the adhesive layer, and analyze the distribution laws of peel stress and shear stress in the adhesive layer. Through the combination of test data and simulation results, the influences of geometric parameters, material parameters and environmental parameters on the structure were explored, and the joint failure mechanism was revealed. Finally, the ACO-BP neural network was used to optimize the geometric parameters through test data. The research results showed that the geometric parameters of the structure mainly affect the bearing capacity and failure type. Reducing the overlap length and increasing the overlap width within a certain range can weaken the peeling phenomenon, so that a smaller overlap area has a higher shear strength. The material parameters of the adherend mainly affect the stress distribution law and stress transfer process of the adhesive layer in the overlap area. The joint mainly bore shear stress and peel stress, and shear stress is the main cause of damage initiation. When the types of adherend materials are different, the stress distribution law shows obvious asymmetric offset. The lap model mainly affects the location distribution of the failure area, and the environmental parameters mainly affect the area proportion relationship of various fracture forms in the mixed failure mode.


---
# Enhancing Security in CPS Industry 5.0 Using Lightweight MobileNetV3 with Adaptive Optimization Technique

## 使用轻量级MobileNetV3和自适应优化技术增强CPS行业5.0中的安全性

Link: https://www.researchsquare.com/article/rs-5296157/latest

The Industrial Revolution of technologies such as the Industrial Internet of Things (IIoT), cloud and Artificial Intelligence (AI) is breaking new frontiers in industrial process automation. Under the Industry 5.0 revolution, AI based manufacturing units are more sophisticated Cyber-Physical Systems (CPS) that allow the interaction of people, objects and machines at any given supply chain level. One of the key advantages of this transformation is that it enables implementing individual-focused and adaptable manufacturing systems. However, this interconnection poses various threats, especially the phenomenon referred to as attacks that are sophisticated in nature sometimes known as distributed denial of service (Ddos) attacks. In the quest to prevent cyber security challenges in the CPS Industry 5.0, this paper proposes a simple and effective System based on Deep Learning architecture. The very first stage concerns data acquisition which entails careful monitoring and collection of raw data from inbuilt sensors for real time performance. In this case, the data is also processed further in order to clean the data, handle missing values within the data set and fix any errors present in the data set, improving it. The next step involves Normalization and feature extraction which takes on the shape of reducing the data into shapes acceptable by the key features; flow-based, time-based and statistical features as well as deep features using ResNet-101. To process the models, MobileNetV3 which are light weight models of deep learning, are predicted to be utilized in the edge devices that are low in resources through quantization and pruning methods. This quantization and pruning is going to reduce the weight of the model or data. The efficient local search method CTPOA is applied for adjustment of parameters, data optimization and performance improvement of the model. Finally, the data in the CPS is safeguarded by the use of AES encryption and Discretionary Access Control policies.

