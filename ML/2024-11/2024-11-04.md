# Capturing forceful interaction with deformable objects using a deep learning-powered stretchable tactile array

## 使用深度学习驱动的可伸缩触觉阵列捕获与可变形物体的有力交互

Link: https://www.nature.com/articles/s41467-024-53654-y

<p>Nature Communications, Published online: 04 November 2024; <a href="https://www.nature.com/articles/s41467-024-53654-y">doi:10.1038/s41467-024-53654-y</a></p>The authors report a stretchable tactile array with strain insensitivity, and a visual-tactile joint learning framework, achieving high-accuracy force measurement and replicating full states of hand and manipulated objects with fine-grained geometry.


---
# High-throughput screening and machine learning classification of van der Waals dielectrics for 2D nanoelectronics

## 用于二维纳米电子的范德华电介质的高通量筛选和机器学习分类

Link: https://www.nature.com/articles/s41467-024-53864-4

<p>Nature Communications, Published online: 04 November 2024; <a href="https://www.nature.com/articles/s41467-024-53864-4">doi:10.1038/s41467-024-53864-4</a></p>New van der Waals (vdW) dielectrics with high dielectric constants are required to enhance the performance of 2D electronic devices. Here, the authors report high-throughput first-principles calculations and a machine learning classifier to identify >50 promising vdW dielectrics suitable for 2D field-effect transistors.


---
# Predicting tremor improvement after MRgFUS thalamotomy in essential tremor from preoperative spontaneous brain activity: A machine learning approach

## 从术前自发性脑活动预测原发性震颤MRgFUS丘脑切开术后震颤改善: 一种机器学习方法

Link: https://www.sciencedirect.com/science/article/pii/S2095927324005887?dgcid=rss_sd_all

<p>Publication date: 15 October 2024</p><p><b>Source:</b> Science Bulletin, Volume 69, Issue 19</p><p>Author(s): Dong Zhang, Yongqin Xiong, Haoxuan Lu, Caohui Duan, Jiayu Huang, Yan Li, Xiangbing Bian, Dekang Zhang, Jiayou Zhou, Longsheng Pan, Xin Lou</p>


---
# An approach for full space inverse materials design by combining universal machine learning potential, universal property model, and optimization algorithm

## 结合通用机器学习潜力，通用属性模型和优化算法的全空间逆材料设计方法

Link: https://www.sciencedirect.com/science/article/pii/S2095927324004948?dgcid=rss_sd_all

<p>Publication date: 15 October 2024</p><p><b>Source:</b> Science Bulletin, Volume 69, Issue 19</p><p>Author(s): Guanjian Cheng, Xin-Gao Gong, Wan-Jian Yin</p>


---
# [ASAP] Deep Learning Enhanced in Situ Atomic Imaging of Ion Migration at Crystalline–Amorphous Interfaces

## [ASAP] 深度学习增强晶体-非晶界面离子迁移的原位原子成像

Link: http://dx.doi.org/10.1021/acs.nanolett.4c04472

<p><img alt="TOC Graphic" src="https://pubs.acs.org/cms/10.1021/acs.nanolett.4c04472/asset/images/medium/nl4c04472_0006.gif" /></p><div><cite>Nano Letters</cite></div><div>DOI: 10.1021/acs.nanolett.4c04472</div>


---
# Predicting magnetic properties of van der Waals magnets using graph neural networks

## 用图神经网络预测范德华磁体的磁性能

Link: http://link.aps.org/doi/10.1103/PhysRevMaterials.8.114002

Author(s): Peter Minch, Romakanta Bhattarai, Kamal Choudhary, and Trevor David Rhone<br /><p>We study two-dimensional (2D) magnetic materials using state-of-the-art machine learning models that use a graph-theory framework. We find that representing materials as graphs allows us to better learn structure-property relationships by leveraging both the chemical properties of the constituent at…</p><br />[Phys. Rev. Materials 8, 114002] Published Mon Nov 04, 2024


---
# Structure-driven prediction of magnetic order in uranium compounds

## 结构驱动的铀化合物磁序预测

Link: http://link.aps.org/doi/10.1103/PhysRevMaterials.8.114405

Author(s): Christopher Broyles, William Charles, and Sheng Ran<br /><p>The advancement of machine learning technologies has revolutionized the search and optimization of material properties. These algorithms often rely on theoretical calculations, such as density functional theory (DFT), for data inputs and validation, which are not always effective for uranium-based m…</p><br />[Phys. Rev. Materials 8, 114405] Published Mon Nov 04, 2024


---
# Crystal structure prediction of lithium-beryllium alloys under pressure with distinctive electronic and dynamic behaviors

## 具有独特电子和动力学行为的锂铍合金在压力下的晶体结构预测

Link: http://link.aps.org/doi/10.1103/PhysRevB.110.174101

Author(s): Zhongwei Zhang, Qing Lu, Chi Ding, Tianheng Huang, Yijie Zhu, Yu Han, Junjie Wang, Xiaomeng Wang, and Jian Sun<br /><p>Using machine learning–assisted crystal structure search and first-principles calculations, we have unveiled two hitherto undiscovered thermodynamically stable stoichiometries, namely, <i>Cmmm</i> $\mathrm{Li}{\mathrm{Be}}_{5}$ and $R\overline{3}m\phantom{\rule{4pt}{0ex}}\mathrm{Li}{\mathrm{Be}}_{6}$, alon…</p><br />[Phys. Rev. B 110, 174101] Published Mon Nov 04, 2024


---
# Renormalized density matrix downfolding: A rigorous framework in learning emergent models from <i>ab initio</i> many-body calculations

## 重归一化密度矩阵向下折叠: 从 &lt;i&gt; 从头开始 &lt;/i&gt; 多体计算学习新兴模型的严格框架

Link: http://link.aps.org/doi/10.1103/PhysRevB.110.195103

Author(s): Yueqing Chang, Sonali Joshi, and Lucas K. Wagner<br /><p>We present a generalized framework, renormalized density matrix downfolding (RDMD), to derive systematically improvable, highly accurate, and nonperturbative effective models from <i>ab initio</i> calculations. This framework moves beyond the common role of <i>ab initio</i> calculations as calculating the paramet…</p><br />[Phys. Rev. B 110, 195103] Published Mon Nov 04, 2024


---
# Designing the next generation of polymers with machine learning and physics-based models

## 使用机器学习和基于物理的模型设计下一代聚合物

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad88d7

The development of next-generation polymers necessitates optimizing several key properties simultaneously, a task that is expensive and infeasible using traditional trial-and-error experimental approaches. A promising alternative is employing a combination of machine learning and physics-based tools to rapidly screen the polymer design space and provide suggestions of new polymers that meet the critical properties required for industrial applications. In this study, we introduce a comprehensive workflow that utilizes machine learning and molecular modeling approaches to design new polymers with the focus on improving five polymer properties: (1) glass transition temperature, (2) dielectric constant, (3) refractive index, (4) stress optic coefficient, and (5) linear coefficient of thermal expansion. Using a small dataset ( 200 unique polymers), we developed quantitative structure-property relationships (QSPRs) models to accurately predict the experimental polymer properties for both homo- and co-polymer systems. We tested several ML algorithms and identified the best models for predicting these polymer properties, achieving test set R2 greater than 0.77 across all properties. We then explored new polymers by creating a library of over ∼10 000 homopolymers using R-group enumeration tools and applied the trained QSPR models to rapidly predict the five polymer properties. The predictions of QSPR models were used to create a multi-parameter optimization score, which helped downselect the large polymer space to ∼10 promising candidates. The properties of these selected polymer candidates were subsequently validated with classical molecular dynamics simulations and density functional theory, revealing a strong correlation with the QSPR model predictions. Finally, one of the top candidates was validated by experiments, which showed good agreement against QSPR and physics-based models. Our workflow underscores the power of combining data-driven and theoretical methods in the polymer design process given a small dataset size, offering a valuable resource for experimentalists looking to leverage computer-aided strategies in materials innovation.


---
# Machine Learning-Assisted Profiling of Ladder Polymer Structure using Scattering

## 使用散射的机器学习辅助的梯形聚合物结构轮廓分析

Link: https://arxiv.org/abs/2411.00134

arXiv:2411.00134v1 Announce Type: new 
Abstract: Ladder polymers, known for their rigid, ladder-like structures, exhibit exceptional thermal stability and mechanical strength, positioning them as candidates for advanced applications. However, accurately determining their structure from solution scattering remains a challenge. Their chain conformation is largely governed by the intrinsic orientational properties of the monomers and their relative orientations, leading to a bimodal distribution of bending angles, unlike conventional polymer chains whose bending angles follow a unimodal Gaussian distribution. Meanwhile, traditional scattering models for polymer chains do not account for these unique structural features. This work introduces a novel approach that integrates machine learning with Monte Carlo simulations to address this challenge. We first develop a Monte Carlo simulation for sampling the configuration space of ladder polymers, where each monomer is modeled as a biaxial segment. Then, we establish a machine learning-assisted scattering analysis framework based on Gaussian Process Regression. Finally, we conduct small-angle neutron scattering experiments on a ladder polymer solution to apply our approach. Our method uncovers structural details of ladder polymers that conventional methods fail to capture.


---
# A Toffoli Gadget for Magnetic Tunnel Junctions Boltzmann Machines

## 用于磁隧道结玻尔兹曼机的Toffoli小工具

Link: https://arxiv.org/abs/2411.00203

arXiv:2411.00203v1 Announce Type: new 
Abstract: Magnetic Tunnel Junctions (MTJs) are of great interest for non-conventional computing applications. The Toffoli gate is a universal reversible logic gate, enabling the construction of arbitrary boolean circuits. Here, we present a proof-of-concept construction of a gadget which encodes the Toffoli gate's truth table into the ground state of coupled uniaxial nanomagnets that could form the free layers of perpendicularly magnetized MTJs. This construction has three input bits, three output bits, and one ancilla bit. We numerically simulate the seven macrospins evolving under the stochastic Landau-Lifshitz-Gilbert (s-LLG) equation. We investigate the effect of the anisotropy-to-exchange-coupling strength ratio $H_A/H_\text{ex}$ on the working of the gadget. We find that for $H_A/H_\text{ex} \lesssim 0.93$, the spins evolve to the Toffoli gate truth table configurations under LLG dynamics alone, while higher $H_A/H_\text{ex}$ ratios require thermal annealing due to suboptimal metastable states. Under our chosen annealing procedure, the s-LLG simulation with thermal annealing achieves a 100% success rate up to $H_A/H_\text{ex}\simeq3.0$. The feasibility of constructing MTJ-free-layer-based Toffoli gates highlights their potential in designing new types of MTJ-based circuits.


---
# In-situ Self-optimization of Quantum Dot Emission for Lasers by Machine-Learning Assisted Epitaxy

## 基于机器学习辅助外延的激光器量子点发射原位自优化

Link: https://arxiv.org/abs/2411.00332

arXiv:2411.00332v1 Announce Type: new 
Abstract: Traditional methods for optimizing light source emissions rely on a time-consuming trial-and-error approach. While in-situ optimization of light source gain media emission during growth is ideal, it has yet to be realized. In this work, we integrate in-situ reflection high-energy electron diffraction (RHEED) with machine learning (ML) to correlate the surface reconstruction with the photoluminescence (PL) of InAs/GaAs quantum dots (QDs), which serve as the active region of lasers. A lightweight ResNet-GLAM model is employed for the real-time processing of RHEED data as input, enabling effective identification of optical performance. This approach guides the dynamic optimization of growth parameters, allowing real-time feedback control to adjust the QDs emission for lasers. We successfully optimized InAs QDs on GaAs substrates, with a 3.2-fold increase in PL intensity and a reduction in full width at half maximum (FWHM) from 36.69 meV to 28.17 meV under initially suboptimal growth conditions. Our automated, in-situ self-optimized lasers with 5-layer InAs QDs achieved electrically pumped continuous-wave operation at 1240 nm with a low threshold current of 150 A/cm2 at room temperature, an excellent performance comparable to samples grown through traditional manual multi-parameter optimization methods. These results mark a significant step toward intelligent, low-cost, and reproductive light emitters production.


---
# Modelling Silica using MACE-MP-0 Machine Learnt Interatomic Potentials

## 使用MACE-MP-0机器学习原子间势对二氧化硅进行建模

Link: https://arxiv.org/abs/2411.00436

arXiv:2411.00436v1 Announce Type: new 
Abstract: Silica polymorphs and zeolites are fundamental to a wide range of industrial applications owing to their diverse structural characteristics, thermodynamic and mechanical stability under varying conditions and due to their geological importance. Computational modelling has played a crucial role in understanding the relationship between the structure and functionality of silicas and silicates including zeolites. In this study, we apply the MACE-MP-0 machine learnt interatomic potentials (ML-IP) to model the framework energies of siliceous zeolites and examine the phase transitions of silica and ZSM-5 polymorphs under high-pressure conditions. The results reproduce the known metastability of siliceous zeolites relative to {\alpha}-quartz, with energy differences between microporous and dense phases calculated by MACE-MP-0 medium ML-IP and density functional theory (DFT) methods closely aligning with experimental calorimetric data. The high-pressure simulations reveal distinct compression behaviour in the quartz, coesite, and stishovite polymorphs of silica, with coesite and stishovite showing increased stability at elevated pressures in line with experimental data. The calculated phase transition pressures from quartz to coesite (~3.5 GPa) and coesite to stishovite (~9 GPa) are close to experimental findings, demonstrating the reliability of MACE ML-IP in modelling the structural and energetic properties of silica polymorphs.


---
# Latent heat estimation with machine learning

## 基于机器学习的潜热估计

Link: https://arxiv.org/abs/2411.00733

arXiv:2411.00733v1 Announce Type: new 
Abstract: We set out to explore the possibility of investigating the critical behavior of systems with first-order phase transition using deep machine learning. We propose a machine learning protocol with ternary classification of instantaneous spin configurations using known values of disordered phase energy and ordered phase energy. The trained neural network is used to predict whether a given sample belong to one or the other phase of matter. This allows us to estimate the probability that configurations with a certain energy belong to the ordered phase, mixed phase and, disordered phase. From these probabilities, we obtained estimates of the values of the critical energies and the latent heat for the Potts model with 10 and 20 components, which undergoes a strong discontinuous transition. We also find that the probabilities can reflect geometric transitions in the mixed phase.


---
# Lagrangian neural networks for nonholonomic mechanics

## 非完整力学的拉格朗日神经网络

Link: https://arxiv.org/abs/2411.00110

arXiv:2411.00110v1 Announce Type: cross 
Abstract: Lagrangian Neural Networks (LNNs) are a powerful tool for addressing physical systems, particularly those governed by conservation laws. LNNs can parametrize the Lagrangian of a system to predict trajectories with nearly conserved energy. These techniques have proven effective in unconstrained systems as well as those with holonomic constraints. In this work, we adapt LNN techniques to mechanical systems with nonholonomic constraints. We test our approach on some well-known examples with nonholonomic constraints, showing that incorporating these restrictions into the neural network's learning improves not only trajectory estimation accuracy but also ensures adherence to constraints and exhibits better energy behavior compared to the unconstrained counterpart.


---
# Machine Learning Potentials for Heterogeneous Catalysis

## 非均相催化的机器学习潜力

Link: https://arxiv.org/abs/2411.00720

arXiv:2411.00720v1 Announce Type: cross 
Abstract: The sustainable production of many bulk chemicals relies on heterogeneous catalysis. The rational design or improvement of the required catalysts critically depends on insights into the underlying mechanisms at the atomic scale. In recent years, substantial progress has been made in applying advanced experimental techniques to complex catalytic reactions in operando, but in order to achieve a comprehensive understanding, additional information from computer simulations is indispensable in many cases. In particular, ab initio molecular dynamics (AIMD) has become an important tool to explicitly address the atomistic level structure, dynamics, and reactivity of interfacial systems, but the high computational costs limit applications to systems consisting of at most a few hundred atoms for simulation times of up to tens of picoseconds. Rapid advances in the development of modern machine learning potentials (MLP) now offer a new approach to bridge this gap, enabling simulations of complex catalytic reactions with ab initio accuracy at a small fraction of the computational costs. In this perspective, we provide an overview of the current state of the art of applying MLPs to systems relevant for heterogeneous catalysis along with a discussion of the prospects for the use of MLPs in catalysis science in the years to come.


---
# Analysis of Bootstrap and Subsampling in High-dimensional Regularized Regression

## 高维正则化回归中的Bootstrap和子采样分析

Link: https://arxiv.org/abs/2402.13622

arXiv:2402.13622v2 Announce Type: replace-cross 
Abstract: We investigate popular resampling methods for estimating the uncertainty of statistical models, such as subsampling, bootstrap and the jackknife, and their performance in high-dimensional supervised regression tasks. We provide a tight asymptotic description of the biases and variances estimated by these methods in the context of generalized linear models, such as ridge and logistic regression, taking the limit where the number of samples $n$ and dimension $d$ of the covariates grow at a comparable fixed rate $\alpha\!=\! n/d$. Our findings are three-fold: i) resampling methods are fraught with problems in high dimensions and exhibit the double-descent-like behavior typical of these situations; ii) only when $\alpha$ is large enough do they provide consistent and reliable error estimations (we give convergence rates); iii) in the over-parametrized regime $\alpha\!<\!1$ relevant to modern machine learning practice, their predictions are not consistent, even with optimal regularization.


---
# Neural network backflow for ab-initio quantum chemistry

## 从头算量子化学的神经网络回流

Link: https://arxiv.org/abs/2403.03286

arXiv:2403.03286v2 Announce Type: replace-cross 
Abstract: The ground state of second-quantized quantum chemistry Hamiltonians provides access to an important set of chemical properties. Wavefunctions based on ML architectures have shown promise in approximating these ground states in a variety of physical systems. In this work, we show how to achieve state-of-the-art energies for molecular Hamiltonians using the the neural network backflow wave-function. To accomplish this, we optimize this ansatz with a variant of the deterministic optimization scheme based on SCI introduced by [Li, et. al JCTC (2023)] which we find works better than standard MCMC sampling. For the molecules we studied, NNBF gives lower energy states than both CCSD and other neural network quantum states. We systematically explore the role of network size as well as optimization parameters in improving the energy. We find that while the number of hidden layers and determinants play a minor role in improving the energy, there is significant improvements in the energy from increasing the number of hidden units as well as the batch size used in optimization with the batch size playing a more important role.


---
# Neural Network Matrix Product Operator: A Multi-Dimensionally Integrable Machine Learning Potential

## 神经网络矩阵乘积算子: 一种多维可积的机器学习势

Link: https://arxiv.org/abs/2410.23858

arXiv:2410.23858v2 Announce Type: replace-cross 
Abstract: A neural network-based machine learning potential energy surface (PES) expressed in a matrix product operator (NN-MPO) is proposed. The MPO form enables efficient evaluation of high-dimensional integrals that arise in solving the time-dependent and time-independent Schr\"odinger equation and effectively overcomes the so-called curse of dimensionality. This starkly contrasts with other neural network-based machine learning PES methods, such as multi-layer perceptrons (MLPs), where evaluating high-dimensional integrals is not straightforward due to the fully connected topology in their backbone architecture. Nevertheless, the NN-MPO retains the high representational capacity of neural networks. NN-MPO can achieve spectroscopic accuracy with a test mean absolute error (MAE) of 3.03 cm$^{-1}$ for a fully coupled six-dimensional ab initio PES, using only 625 training points distributed across a 0 to 17,000 cm$^{-1}$ energy range. Our Python implementation is available at https://github.com/KenHino/Pompon.


---
# Photonic neural networks with spatiotemporal chaos in multimode fibers

## 多模光纤中具有时空混沌的光子神经网络

Link: https://arxiv.org/abs/2411.00189

arXiv:2411.00189v1 Announce Type: new 
Abstract: Optical computing has gained significant attention as a potential solution to the growing computational demands of machine learning, particularly for tasks requiring large-scale data processing and high energy efficiency. Optical systems offer promising alternatives to digital neural networks by exploiting light's parallelism. This study explores a photonic neural network design using spatiotemporal chaos within grad-ed-index multimode fibers to improve machine learning performance. Through numerical simulations and experiments, we show that chaotic light propagation in multimode fibers enhances data classification accu-racy across domains, including biomedical imaging, fashion, and satellite geospatial analysis. This chaotic optical approach enables high-dimensional transformations, amplifying data separability and differentiation for greater accuracy. Fine-tuning parameters such as pulse peak power optimizes the reservoir's chaotic properties, highlighting the need for careful calibration. These findings underscore the potential of chaos-based nonlinear photonic neural networks to advance optical computing in machine learning, paving the way for efficient, scalable architectures.


---
# Denoising study of Fluoroscopic Images in real time tumor tracking System based on Statistical model of noise

## 基于噪声统计模型的实时肿瘤跟踪系统透视图像去噪研究

Link: https://arxiv.org/abs/2411.00199

arXiv:2411.00199v1 Announce Type: new 
Abstract: This study investigates the noise characteristics of intraoperative X-ray fluoroscopic images acquired during real-time image-guided radiotherapy (IGRT), and presents a novel noise image generation method based on the identified noise amplitude and spatial probability patterns. Initially, noise-free digitally reconstructed radiographs (DRRs) were generated using patient CT data combined with projection algorithms and the spatial configuration of the real-time tumor tracking system. Based on the observed noise probability and amplitude distributions, noise was then added to these DRRs to create Dataset 1. As a control, Dataset 2 was generated by adding Gaussian noise with the same mean and variance as Dataset 1; however, the noise probability in Dataset 2 is independent of pixel location and pixel intensity. Both datasets were used to fine-tune a pre-trained SwinIR model with identical training parameters. Tests on phantom images containing real noise show that the SwinIR model trained with the proposed noise model dataset achieves superior denoising performance over the model trained with Gaussian noise and the model without transfer learning, with an average PSNR improvement of 1.45 dB. This study contributes to a deeper understanding of noise patterns in these fluoroscopic images and is crucial for enhancing image quality and the accuracy of real-time tumor tracking in radiotherapy.


---
# All-Optical Excitable Spiking Laser Neuron in InP Generic Integration Technology

## InP通用集成技术中的全光可激发脉冲激光神经元

Link: https://arxiv.org/abs/2411.00697

arXiv:2411.00697v1 Announce Type: new 
Abstract: Brain-inspired, neuromorphic devices implemented in integrated photonic hardware have attracted significant interest recently as part of efforts towards novel non-von Neumann computing paradigms that make use of the low loss, high-speed and parallel operations in optics. An all-optical spiking laser neuron fabricated on the indium-phosphide generic integration technology platform may be a practical alternative to other semi-integrated photonic and electronic-based spiking neuron implementations. Owing to the large number of predefined building blocks, a plethora of applications have benefitted already from the generic integration process. This technology platform has now been utilised for the first time to demonstrate an all-optical spiking laser neuron. This paper present and discusses the design and measurement of the ultra-fast and rich spiking dynamics in these devices. We show that under external pulse injection and operated slightly below the lasing threshold, the laser neuron exhibits an excitable mode, in addition to a self-spiking mode far above the threshold when no pulse is injected. In the excitable mode, the required injected pulse energy is much lower than that of the generated excited response, meeting an important requirement for neuron cascadability. In addition, we investigate excitability at different injection wavelengths below the lasing wavelength, as well as the ultra-fast temporal properties of the spiking response. All of the discussed characteristics point to the laser neuron being an important candidate for scaling up to future fully-connected, multi-wavelength all-optical photonic spiking neural networks in indium-phosphide generic integration technology.


---
# Machine Learning Potentials for Heterogeneous Catalysis

## 非均相催化的机器学习潜力

Link: https://arxiv.org/abs/2411.00720

arXiv:2411.00720v1 Announce Type: new 
Abstract: The sustainable production of many bulk chemicals relies on heterogeneous catalysis. The rational design or improvement of the required catalysts critically depends on insights into the underlying mechanisms at the atomic scale. In recent years, substantial progress has been made in applying advanced experimental techniques to complex catalytic reactions in operando, but in order to achieve a comprehensive understanding, additional information from computer simulations is indispensable in many cases. In particular, ab initio molecular dynamics (AIMD) has become an important tool to explicitly address the atomistic level structure, dynamics, and reactivity of interfacial systems, but the high computational costs limit applications to systems consisting of at most a few hundred atoms for simulation times of up to tens of picoseconds. Rapid advances in the development of modern machine learning potentials (MLP) now offer a new approach to bridge this gap, enabling simulations of complex catalytic reactions with ab initio accuracy at a small fraction of the computational costs. In this perspective, we provide an overview of the current state of the art of applying MLPs to systems relevant for heterogeneous catalysis along with a discussion of the prospects for the use of MLPs in catalysis science in the years to come.


---
# Machine Learning-Assisted Profiling of Ladder Polymer Structure using Scattering

## 使用散射的机器学习辅助的梯形聚合物结构轮廓分析

Link: https://arxiv.org/abs/2411.00134

arXiv:2411.00134v1 Announce Type: cross 
Abstract: Ladder polymers, known for their rigid, ladder-like structures, exhibit exceptional thermal stability and mechanical strength, positioning them as candidates for advanced applications. However, accurately determining their structure from solution scattering remains a challenge. Their chain conformation is largely governed by the intrinsic orientational properties of the monomers and their relative orientations, leading to a bimodal distribution of bending angles, unlike conventional polymer chains whose bending angles follow a unimodal Gaussian distribution. Meanwhile, traditional scattering models for polymer chains do not account for these unique structural features. This work introduces a novel approach that integrates machine learning with Monte Carlo simulations to address this challenge. We first develop a Monte Carlo simulation for sampling the configuration space of ladder polymers, where each monomer is modeled as a biaxial segment. Then, we establish a machine learning-assisted scattering analysis framework based on Gaussian Process Regression. Finally, we conduct small-angle neutron scattering experiments on a ladder polymer solution to apply our approach. Our method uncovers structural details of ladder polymers that conventional methods fail to capture.


---
# A Toffoli Gadget for Magnetic Tunnel Junctions Boltzmann Machines

## 用于磁隧道结玻尔兹曼机的Toffoli小工具

Link: https://arxiv.org/abs/2411.00203

arXiv:2411.00203v1 Announce Type: cross 
Abstract: Magnetic Tunnel Junctions (MTJs) are of great interest for non-conventional computing applications. The Toffoli gate is a universal reversible logic gate, enabling the construction of arbitrary boolean circuits. Here, we present a proof-of-concept construction of a gadget which encodes the Toffoli gate's truth table into the ground state of coupled uniaxial nanomagnets that could form the free layers of perpendicularly magnetized MTJs. This construction has three input bits, three output bits, and one ancilla bit. We numerically simulate the seven macrospins evolving under the stochastic Landau-Lifshitz-Gilbert (s-LLG) equation. We investigate the effect of the anisotropy-to-exchange-coupling strength ratio $H_A/H_\text{ex}$ on the working of the gadget. We find that for $H_A/H_\text{ex} \lesssim 0.93$, the spins evolve to the Toffoli gate truth table configurations under LLG dynamics alone, while higher $H_A/H_\text{ex}$ ratios require thermal annealing due to suboptimal metastable states. Under our chosen annealing procedure, the s-LLG simulation with thermal annealing achieves a 100% success rate up to $H_A/H_\text{ex}\simeq3.0$. The feasibility of constructing MTJ-free-layer-based Toffoli gates highlights their potential in designing new types of MTJ-based circuits.


---
# Deep learning-based auto-contouring of organs/structures-at-risk for pediatric upper abdominal radiotherapy

## 基于深度学习的小儿上腹部放射治疗高危器官/结构自动轮廓

Link: https://arxiv.org/abs/2411.00594

arXiv:2411.00594v1 Announce Type: cross 
Abstract: Purposes: This study aimed to develop a computed tomography (CT)-based multi-organ segmentation model for delineating organs-at-risk (OARs) in pediatric upper abdominal tumors and evaluate its robustness across multiple datasets. Materials and methods: In-house postoperative CTs from pediatric patients with renal tumors and neuroblastoma (n=189) and a public dataset (n=189) with CTs covering thoracoabdominal regions were used. Seventeen OARs were delineated: nine by clinicians (Type 1) and eight using TotalSegmentator (Type 2). Auto-segmentation models were trained using in-house (ModelPMC-UMCU) and a combined dataset of public data (Model-Combined). Performance was assessed with Dice Similarity Coefficient (DSC), 95% Hausdorff Distance (HD95), and mean surface distance (MSD). Two clinicians rated clinical acceptability on a 5-point Likert scale across 15 patient contours. Model robustness was evaluated against sex, age, intravenous contrast, and tumor type. Results: Model-PMC-UMCU achieved mean DSC values above 0.95 for five of nine OARs, while spleen and heart ranged between 0.90 and 0.95. The stomach-bowel and pancreas exhibited DSC values below 0.90. Model-Combined demonstrated improved robustness across both datasets. Clinical evaluation revealed good usability, with both clinicians rating six of nine Type 1 OARs above four and six of eight Type 2 OARs above three. Significant performance 2 differences were only found across age groups in both datasets, specifically in the left lung and pancreas. The 0-2 age group showed the lowest performance. Conclusion: A multi-organ segmentation model was developed, showcasing enhanced robustness when trained on combined datasets. This model is suitable for various OARs and can be applied to multiple datasets in clinical settings.


---
# RAIDER: Rapid, anatomy-independent, deep learning-based PDFF and R2* estimation using magnitude-only signals

## RAIDER: 使用仅幅度信号的快速、独立于解剖学、基于深度学习的PDFF和R2 * 估计

Link: https://arxiv.org/abs/2403.01178

arXiv:2403.01178v2 Announce Type: replace 
Abstract: Purpose: There has been substantial recent interest in magnitude-based fitting methods for estimating proton density fat fraction (PDFF) and R2* from chemical shift-encoded MRI data, since these methods can still be used when complex-based methods fail or when phase data are inaccessible or unreliable, and may also be used as a final processing step with complex-based methods. However, conventional fitting techniques are computationally expensive. Deep learning (DL)-based methods promise to accelerate parameter estimation, but previous attempts have used convolutional neural networks (CNNs), which are limited by training requirements and poor generalizability (anatomy-dependence). To address these limitations, we propose RAIDER, a voxelwise method for rapid, anatomy-independent deep learning-based PDFF and R2* estimation using multi-echo magnitude-data. Theory and Methods: RAIDER uses two multilayer perceptrons, each trained separately with simulated single-voxel multi-echo magnitude signals, to estimate PDFF and R2*. The use of two networks, each with restricted training distribution, solves the problem of degeneracy during training. During inference, the solution from one of the two networks is chosen based on likelihood. Performance and speed are investigated in a series of simulation experiments, in phantoms and in vivo. Results: RAIDER is 285-1450 times faster than conventional magnitude fitting, taking 1.4-2.3s per slice rather than 8-56minutes, and offers performance similar to conventional fitting. It produces accurate PDFF measurements in phantoms and in vivo images with different anatomies, despite having been trained only on simulation data. Conclusion: RAIDER can substantially accelerate magnitude-based PDFF and R2* estimation, whilst avoiding intrinsic limitations of CNN-based methods.


---
# Neural network backflow for ab-initio quantum chemistry

## 从头算量子化学的神经网络回流

Link: https://arxiv.org/abs/2403.03286

arXiv:2403.03286v2 Announce Type: replace 
Abstract: The ground state of second-quantized quantum chemistry Hamiltonians provides access to an important set of chemical properties. Wavefunctions based on ML architectures have shown promise in approximating these ground states in a variety of physical systems. In this work, we show how to achieve state-of-the-art energies for molecular Hamiltonians using the the neural network backflow wave-function. To accomplish this, we optimize this ansatz with a variant of the deterministic optimization scheme based on SCI introduced by [Li, et. al JCTC (2023)] which we find works better than standard MCMC sampling. For the molecules we studied, NNBF gives lower energy states than both CCSD and other neural network quantum states. We systematically explore the role of network size as well as optimization parameters in improving the energy. We find that while the number of hidden layers and determinants play a minor role in improving the energy, there is significant improvements in the energy from increasing the number of hidden units as well as the batch size used in optimization with the batch size playing a more important role.


---
# Robustness of graph embedding methods for community detection

## 用于社区检测的图嵌入方法的鲁棒性

Link: https://arxiv.org/abs/2405.00636

arXiv:2405.00636v2 Announce Type: replace 
Abstract: This study investigates the robustness of graph embedding methods for community detection in the face of network perturbations, specifically edge deletions. Graph embedding techniques, which represent nodes as low-dimensional vectors, are widely used for various graph machine learning tasks due to their ability to capture structural properties of networks effectively. However, the impact of perturbations on the performance of these methods remains relatively understudied. The research considers state-of-the-art graph embedding methods from two families: matrix factorization (e.g., LE, LLE, HOPE, M-NMF) and random walk-based (e.g., DeepWalk, LINE, node2vec). Through experiments conducted on both synthetic and real-world networks, the study reveals varying degrees of robustness within each family of graph embedding methods. The robustness is found to be influenced by factors such as network size, initial community partition strength, and the type of perturbation. Notably, node2vec and LLE consistently demonstrate higher robustness for community detection across different scenarios, including networks with degree and community size heterogeneity. These findings highlight the importance of selecting an appropriate graph embedding method based on the specific characteristics of the network and the task at hand, particularly in scenarios where robustness to perturbations is crucial.


---
# NeuralFluid: Neural Fluidic System Design and Control with Differentiable Simulation

## 神经流体: 可微模拟的神经流体系统设计和控制

Link: https://arxiv.org/abs/2405.14903

arXiv:2405.14903v2 Announce Type: replace 
Abstract: We present a novel framework to explore neural control and design of complex fluidic systems with dynamic solid boundaries. Our system features a fast differentiable Navier-Stokes solver with solid-fluid interface handling, a low-dimensional differentiable parametric geometry representation, a control-shape co-design algorithm, and gym-like simulation environments to facilitate various fluidic control design applications. Additionally, we present a benchmark of design, control, and learning tasks on high-fidelity, high-resolution dynamic fluid environments that pose challenges for existing differentiable fluid simulators. These tasks include designing the control of artificial hearts, identifying robotic end-effector shapes, and controlling a fluid gate. By seamlessly incorporating our differentiable fluid simulator into a learning framework, we demonstrate successful design, control, and learning results that surpass gradient-free solutions in these benchmark tasks.


---
# WindsorML: High-Fidelity Computational Fluid Dynamics Dataset For Automotive Aerodynamics

## WindsorML: 汽车空气动力学的高保真计算流体动力学数据集

Link: https://arxiv.org/abs/2407.19320

arXiv:2407.19320v3 Announce Type: replace 
Abstract: This paper presents a new open-source high-fidelity dataset for Machine Learning (ML) containing 355 geometric variants of the Windsor body, to help the development and testing of ML surrogate models for external automotive aerodynamics. Each Computational Fluid Dynamics (CFD) simulation was run with a GPU-native high-fidelity Wall-Modeled Large-Eddy Simulations (WMLES) using a Cartesian immersed-boundary method using more than 280M cells to ensure the greatest possible accuracy. The dataset contains geometry variants that exhibits a wide range of flow characteristics that are representative of those observed on road-cars. The dataset itself contains the 3D time-averaged volume & boundary data as well as the geometry and force & moment coefficients. This paper discusses the validation of the underlying CFD methods as well as contents and structure of the dataset. To the authors knowledge, this represents the first, large-scale high-fidelity CFD dataset for the Windsor body with a permissive open-source license (CC-BY-SA).


---
# Highly Accurate Real-space Electron Densities with Neural Networks

## 使用神经网络实现高精度的实空间电子密度

Link: https://arxiv.org/abs/2409.01306

arXiv:2409.01306v2 Announce Type: replace 
Abstract: Variational ab-initio methods in quantum chemistry stand out among other methods in providing direct access to the wave function. This allows in principle straightforward extraction of any other observable of interest, besides the energy, but in practice this extraction is often technically difficult and computationally impractical. Here, we consider the electron density as a central observable in quantum chemistry and introduce a novel method to obtain accurate densities from real-space many-electron wave functions by representing the density with a neural network that captures known asymptotic properties and is trained from the wave function by score matching and noise-contrastive estimation. We use variational quantum Monte Carlo with deep-learning ans\"atze (deep QMC) to obtain highly accurate wave functions free of basis set errors, and from them, using our novel method, correspondingly accurate electron densities, which we demonstrate by calculating dipole moments, nuclear forces, contact densities, and other density-based properties.


---
# Monte-Carlo/Moments micro-macro Parareal method for unimodal and bimodal scalar McKean-Vlasov SDEs

## 单峰和双峰标量mckeans-vlasov SDEs的蒙特卡洛/矩微宏副面方法

Link: https://arxiv.org/abs/2310.11365

arXiv:2310.11365v2 Announce Type: replace-cross 
Abstract: We propose a micro-macro parallel-in-time Parareal method for scalar McKean-Vlasov stochastic differential equations (SDEs). In the algorithm, the fine Parareal propagator is a Monte Carlo simulation of an ensemble of particles, while an approximate ordinary differential equation (ODE) description of the mean and the variance of the particle distribution is used as a coarse Parareal propagator to achieve speedup. We analyse the convergence behaviour of our method for a linear problem and provide numerical experiments indicating the parallel weak scaling of the algorithm on a set of examples. We show, with numerical experiments, that convergence typically takes place in a low number of iterations, depending on the quality of the ODE predictor. For bimodal SDEs, we avoid quality deterioration of the coarse predictor (compared to unimodal SDEs) through the usage of multiple ODEs, each describing the mean and variance of the particle distribution in locally unimodal regions of the phase space. The benefit of the proposed algorithm can be viewed through two lenses: (i) through the parallel-in-time lens, speedup is obtained through the use of a very cheap coarse integrator (an ODE moment model), and (ii) through the moment models lens, accuracy is iteratively gained through the use of parallel machinery as a corrector. In contrast to the isolated use of a moment model, the proposed method (iteratively) converges to the true distribution generated by the SDE.


---
# Scalable Training of Trustworthy and Energy-Efficient Predictive Graph Foundation Models for Atomistic Materials Modeling: A Case Study with HydraGNN

## 用于原子材料建模的可信赖且节能的预测图基础模型的可扩展训练: HydraGNN的案例研究

Link: https://arxiv.org/abs/2406.12909

arXiv:2406.12909v4 Announce Type: replace-cross 
Abstract: We present our work on developing and training scalable, trustworthy, and energy-efficient predictive graph foundation models (GFMs) using HydraGNN, a multi-headed graph convolutional neural network architecture. HydraGNN expands the boundaries of graph neural network (GNN) computations in both training scale and data diversity. It abstracts over message passing algorithms, allowing both reproduction of and comparison across algorithmic innovations that define nearest-neighbor convolution in GNNs. This work discusses a series of optimizations that have allowed scaling up the GFMs training to tens of thousands of GPUs on datasets consisting of hundreds of millions of graphs. Our GFMs use multi-task learning (MTL) to simultaneously learn graph-level and node-level properties of atomistic structures, such as energy and atomic forces. Using over 154 million atomistic structures for training, we illustrate the performance of our approach along with the lessons learned on two state-of-the-art United States Department of Energy (US-DOE) supercomputers, namely the Perlmutter petascale system at the National Energy Research Scientific Computing Center and the Frontier exascale system at Oak Ridge Leadership Computing Facility. The HydraGNN architecture enables the GFM to achieve near-linear strong scaling performance using more than 2,000 GPUs on Perlmutter and 16,000 GPUs on Frontier.


---
# Neural Network Matrix Product Operator: A Multi-Dimensionally Integrable Machine Learning Potential

## 神经网络矩阵乘积算子: 一种多维可积的机器学习势

Link: https://arxiv.org/abs/2410.23858

arXiv:2410.23858v2 Announce Type: replace-cross 
Abstract: A neural network-based machine learning potential energy surface (PES) expressed in a matrix product operator (NN-MPO) is proposed. The MPO form enables efficient evaluation of high-dimensional integrals that arise in solving the time-dependent and time-independent Schr\"odinger equation and effectively overcomes the so-called curse of dimensionality. This starkly contrasts with other neural network-based machine learning PES methods, such as multi-layer perceptrons (MLPs), where evaluating high-dimensional integrals is not straightforward due to the fully connected topology in their backbone architecture. Nevertheless, the NN-MPO retains the high representational capacity of neural networks. NN-MPO can achieve spectroscopic accuracy with a test mean absolute error (MAE) of 3.03 cm$^{-1}$ for a fully coupled six-dimensional ab initio PES, using only 625 training points distributed across a 0 to 17,000 cm$^{-1}$ energy range. Our Python implementation is available at https://github.com/KenHino/Pompon.


---
# Learning Macroscopic Dynamics from Partial Microscopic Observations

## 从部分微观观察中学习宏观动力学

Link: https://arxiv.org/abs/2410.23938

arXiv:2410.23938v2 Announce Type: replace-cross 
Abstract: Macroscopic observables of a system are of keen interest in real applications such as the design of novel materials. Current methods rely on microscopic trajectory simulations, where the forces on all microscopic coordinates need to be computed or measured. However, this can be computationally prohibitive for realistic systems. In this paper, we propose a method to learn macroscopic dynamics requiring only force computations on a subset of the microscopic coordinates. Our method relies on a sparsity assumption: the force on each microscopic coordinate relies only on a small number of other coordinates. The main idea of our approach is to map the training procedure on the macroscopic coordinates back to the microscopic coordinates, on which partial force computations can be used as stochastic estimation to update model parameters. We provide a theoretical justification of this under suitable conditions. We demonstrate the accuracy, force computation efficiency, and robustness of our method on learning macroscopic closure models from a variety of microscopic systems, including those modeled by partial differential equations or molecular dynamics simulations.


---
# Designing Target-Specific Datasets for Regioselectivity Predictions on Complex Substrates

## 设计用于复杂基质上区域选择性预测的特定于目标的数据集

Link: https://dx.doi.org/10.26434/chemrxiv-2024-skgxb-v2?rft_dat=source%3Ddrss

The development of machine learning models to predict the regioselectivity of C(sp3)–H functionalization reactions is reported. A dataset for dioxirane oxidations was curated from the literature and used to generate a model to predict the regioselectivity of C–H oxidation. To assess whether smaller, intentionally designed datasets could provide ac-curacy on complex targets, a series of acquisition functions were developed to select the most informative mole-cules for the specific target. Active learning-based acquisition functions that leverage predicted reactivity and model uncertainty were found to outperform those based on molecular and site similarity alone. The use of acquisition functions for dataset elaboration significantly reduced the number of datapoints needed to perform accurate predic-tion, and it was found that smaller, machine-designed datasets can give accurate predictions when larger, randomly selected datasets fail. Finally, the workflow was experimentally validated on five complex substrates and shown to be applicable to predicting the regioselectivity of arene C–H radical borylation. These studies provide a quantitative alternative to the intuitive extrapolation from “model substrates” that is frequently used to estimate reactivity on complex molecules.


---
# Highly Efficient Crystallization Studies through Machine Learning and Automation

## 通过机器学习和自动化进行高效结晶研究

Link: https://dx.doi.org/10.26434/chemrxiv-2024-5w5rp-v2?rft_dat=source%3Ddrss

Crystallization is an important process in a broad range of industries, though studies on this topic remain complicated. Recently, machine learning has been applied to resolve complex issues in chemistry and material science. Here we present a machine learning model integrated into a robotic platform to effectively propose and automatically perform crystallization experiments for organic small molecules. The model was pretrained on around 140000 simulated data generated by a kinetic model, and fine-tuned by over 7000 experimental data obtained on the automated workstation. The improved prediction accuracy and working efficiency of our integrated platform were presented in case studies compared with the traditional approach by humans. A feature contribution analysis demonstrates that this model provides a holistic data-based perspective of promoting and inhibiting influences to crystallization. This work thereby demonstrates the feasibility of applying machine learning techniques to solid-state studies to reduce cost, boost efficiency and deepen understanding.


---
# Practically significant method comparison protocols for machine learning in small molecule drug discovery.

## 小分子药物发现中机器学习的实际重要方法比较方案。

Link: https://dx.doi.org/10.26434/chemrxiv-2024-6dbwv?rft_dat=source%3Ddrss

Machine Learning (ML) methods that relate molecular structure to properties are frequently proposed as in-silico surrogates for expensive or time-consuming experiments. In small molecule drug discovery, such methods inform high-stakes decisions like compound synthesis and in-vivo studies. This application lies at the intersection of multiple scientific disciplines. When comparing new ML methods
to baseline or state-of-the-art approaches, statistically rigorous method comparison protocols and domain-appropriate performance metrics are essential to
ensure replicability and ultimately the adoption of ML in small molecule drug discovery. This paper proposes a set of guidelines to incentivize rigorous and domain-appropriate techniques for method comparison tailored to small molecule property modeling. These guidelines, accompanied by annotated examples and open-source software tools, lay a foundation for robust ML benchmarking and thus the development of more impactful methods.


---
# &shy;&shy;&shy;Utilizing cloud-based BIM platforms for sustainable decision making in educational architecture design

## & shy; 利用基于云的BIM平台在教育建筑设计中进行可持续决策

Link: https://www.researchsquare.com/article/rs-5281199/latest

With the search for a sustainable construction process, building information modeling (BIM) emerged as a powerful agent. BIM is an innovative technology and technique that evolved the perspective of buildings like how they are planned, imagined, managed, and created. Designers are using BIM expertise to improve quality, save costs, and even create solutions to tackle the above-mentioned issues the study aims to propose the utilization of cloud-based BIM platforms for sustainable decision making in educational architectural design. The following methods are used for cloud-based BIM technology Data Collection. In this method, architectural designs, structural characteristics, material specifications, and energy use of educational buildings will be generated using cloud-based BIM systems. After collecting the data, accuracy, and consistency should be ensured by cleaning and standardizing the collected data which is called pre-processing. Moving on to the next step is reducing dimensionality with the use of &amp;ldquo;Principal Component Analysis (PCA)&amp;rdquo;, to overcome the issue which focuses on important factors that have a major influence on energy usage and sustainability. Following dimensionality reduction comes the Regression analysis which is done by Light Gradient Boosting Machine - Neural Network - Model Predictive Control (LightGBM-NN based MPC) is used in this case for Analyzing. For Classification, a hybrid technique Support Vector Machine - Neural Network - Genetic Algorithm (SVM-NN-GA) is used here. At last, ultimately, we create Sustainable decision-making frameworks that include classification outcomes while considering sustainability in the long term. Finally, the performance of this work is measured through the following performance metrics, Accuracy, Precision, Recall, F-1 Score, Root Mean Square Error.


---
# AI-Enhanced Data-Driven Approach to Model the Mechanical Behavior of Sustainable Geopolymer Concrete

## AI增强的数据驱动方法对可持续地质聚合物混凝土的力学行为进行建模

Link: https://www.researchsquare.com/article/rs-5307352/latest

The increasing environmental concerns associated with Ordinary Portland Cement (OPC) production have driven research towards alternative, sustainable construction materials. Geopolymer concrete (GPC) has emerged as a promising eco-friendly substitute, offering reduced carbon emissions and improved mechanical properties. However, accurately predicting the compressive strength of GPC remains a complex task due to the numerous variables influencing its performance, such as material properties, mix proportions, and curing conditions. This study develops an interpretable machine learning (ML) model to predict the compressive strength of geopolymer concrete, leveraging various ML techniques, including linear regression, decision trees (DT), gradient boosting, support vector regression (SVR), artificial neural networks (ANN), and random forests (RF). To enhance prediction accuracy, a super learner model is employed, integrating these individual techniques. The model's performance is evaluated using metrics such as the coefficient of determination (R&amp;sup2;), mean absolute percentage error (MAPE), mean square error (MSE), and root mean square error (RMSE). Additionally, SHAP values and sensitivity analysis are conducted to quantify the impact of each input parameter on the predictions, ensuring the model's transparency and reliability. The proposed approach provides a robust framework for accurately forecasting the compressive strength of geopolymer concrete, thereby contributing to the advancement of sustainable construction practices.


---
# Perceived teacher support profiles and mathematics engagement, mathematics anxiety, mathematics attitude: A latent profile analysis approach

## 感知到的教师支持概况和数学参与，数学焦虑，数学态度: 潜在概况分析方法

Link: https://www.researchsquare.com/article/rs-5293099/latest

Background The critical role of perceived teacher support in mathematics learning has been widely recognized, but individual student differences have often been overlooked in previous studies.Methods This study adopts a person-centered approach to study the perceived teacher support in the process of mathematics learning, uses latent profile analysis to classify 1314 students, and uses one-way analysis of variance to explore the differences between students with different profiles. Further, a mediation model is established to explore the relationship between different perceived teacher support profiles and and mathematics engagement, mathematics anxiety, and mathematics attitude.Results Latent profile analysis identified three profiles: low (5.78%), medium (44.29%), and high perceived teacher support (49.93%). There were no significant differences in gender or grade among students with different profiles. But they show significant differences in mathematics engagement, mathematics anxiety, and mathematics attitude. Further analysis revealed that there are differences in behavioral engagement, cognitive engagement, emotional engagement, classroom anxiety, learning motivation, and learning strategies. The mediation effect analysis showed that students with higher perceived teacher support exhibited stronger mathematics attitudes, which in turn increased their mathematics engagement. However, mathematics anxiety did not serve as a mediating factor.Conclusion The study showed that individual differences in perceived teacher support affect students&amp;rsquo; mathematics engagement mathematics anxiety, and mathematics attitudes. Students who perceive a higher level of teacher support show a more positive attitude toward mathematics, which promotes mathematics engagement. This study provides empirical evidence for teachers to implement personalized support.


---
# Predicting 90-day mortality in patients with HBV-ACLF using machine learning tools

## 使用机器学习工具预测hbv-aclf患者的90天死亡率

Link: https://www.researchsquare.com/article/rs-5289373/latest

Background Acute chronic liver failure (ACLF) is characterized by a systemic inflammatory response, mainly associated with hepatitis B virus (HBV) in the Asia-Pacific region, and has a high mortality rate. We aimed to develop a stable and feasible prognostic prediction model based on machine learning (ML) tools to predict 90-day mortality in patients with hepatitis B virus-associated acute-on-chronic liver failure (HBV-ACLF).Method Clinical data from 573 patients with HBV-ACLF across two hospitals were retrospectively collected. Prognostic models of HBV-ACLF were constructed using support vector machine (SVM), decision tree (DT), random forest (RF), K nearest neighbour (KNN), least absolute shrinkage selection operator (LASSO), and logistic regression (LR). Model performance metrics included accuracy, area under the (AUC) receiver operating characteristic curve, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV).Results In the training cohort, the RF prediction model demonstrated significantly higher AUC, sensitivity, specificity, PPV, and NPV than the LASSO, LR, SVM, DT, and KNN prediction models. However, the AUC of RF in the validation cohort was 0.728, with a decline in accuracy, specificity, and PPV to 0.688, 0.545, and 0.655, respectively. In the training cohort, the LASSO model had the lowest PPV at 0.739, while the KNN model had the lowest sensitivity at 0.694. In the testing and validation cohorts, the SVM and DT models exhibited the lowest sensitivity, both at 0.581. Although LR performed less effectively than RF in the training cohort, it outperformed the RF model in the testing and validation cohorts.Conclusions In summary, the LR predictive model demonstrates higher predictive efficacy and greater stability, making it more practical for clinical treatment decision-making.


---
# Detection of small-magnitude events using unsupervised machine learning for waveform-based source imaging through grouped time reversals

## 使用无监督机器学习通过分组时间反转检测基于波形的源成像的小事件

Link: https://www.researchsquare.com/article/rs-5284459/latest

Efficient arrival picking is one of the crucial steps for seismic data processing both in active and passive seismology. We employ the unsupervised Fuzzy C-means clustering to improve the picking of the arrivals of small magnitude earthquake events, and then source location is computed by grouped time-reversal imaging approach by first splitting the receivers into groups and then backward propagating the wavefield. Once the arrivals are auto picked, P-wave signals are identified and extracted from the entire waveforms. Finally, a high-resolution source location image is obtained by multidimensional cross-correlation of the wavefields. The performance of the approach has been tested on a suite of synthetic data and field data sets obtained from the North-West Himalayan region of Jammu and Kashmir. The estimated uncertainties reveal the improvement of the locations over the conventional travel time inversion method. We demonstrate that these two independent approaches can effectively be used to analyze seismological data sets in a complex medium, and even works with sparse seismic networks for locating the small-magnitude earthquakes. The present approach can be used to locate the seismic sources utilizing the single-component waveform data.


---
# Intelligent Adaptive Service Grid Architecture Design and Performance Optimization for Future Networks

## 面向未来网络的智能自适应服务网格体系结构设计与性能优化

Link: https://www.researchsquare.com/article/rs-5289129/latest

With the development of future networks, the popularization of technologies such as 5G and the Internet of Things (IoT) has led to new characteristics of network environments with high dynamics, low latency, and complexity. Traditional service grid architectures have limitations in coping with the dynamics and complex traffic management of future networks, such as increased latency and inflexible traffic management. This study aims to design an intelligent and adaptive service grid architecture to optimize the performance to cope with the new challenges in future networks. To address the network routing optimization problem, this study uses deep Q-learning algorithms to achieve intelligent routing, which effectively reduces the network delay and packet loss rate. To address the complexity of traffic management in large-scale distributed systems, a dynamic traffic management module combining convolutional neural networks and long and short-term memory networks is designed to improve the accuracy of traffic prediction. To enhance network adaptability and fault recovery, the study introduces a network resilience enhancement module, which ensures service continuity under high load and fault conditions. In addition, efficient transmission and low resource consumption under multiple network protocols are realized by the design of protocol adaptive module. Experimental evaluation of the entire optimized architecture shows that this intelligent service grid architecture exhibits excellent performance in future network environments. The intelligent routing module effectively reduces network delay and packet loss, the dynamic traffic management module improves the accuracy of traffic prediction, the network resilience enhancement module ensures service continuity under high load and fault conditions, and the protocol adaptation module demonstrates efficient transmission and low resource consumption under multiple network protocols. Through the optimal design of the service grid architecture and the introduction of intelligent technologies, the performance and adaptability of service grids in future network environments are successfully enhanced, and the deficiencies faced by traditional service grids in dynamic network environments are addressed. This research provides important technical support and development direction for intelligent service grids in future networks.


---
# PCCA: Point Cloud Clusters Attention

## PCCA: 点云集群注意

Link: https://www.researchsquare.com/article/rs-5294741/latest

In this research, a K-means clustering algorithm and attention mechanism is used to improve object classification by preprocessing 3D point clouds. Robotics and autonomous driving depend heavily on point clouds obtained by LiDAR. Big data quantities and noise present challenges for traditional approaches. Post-clustering, the data is processed by an improved PointNet&amp;thinsp;+&amp;thinsp;+&amp;thinsp;neural network with embedded attention mechanisms for object classification. PointNet&amp;thinsp;+&amp;thinsp;+&amp;thinsp;effectively classifies objects in complicated scenarios by utilizing a hierarchical structure and attention methods to concentrate on the most pertinent portions of the input. Tests carried out on the KITTI dataset show that pre-clustering improves classification accuracy while cutting down on processing time. As evidence of the effectiveness of the suggested strategy, the findings show a notable improvement in performance measures. This approach holds potential for creating more reliable and effective perception systems for self-driving cars and other applications involving 3D data analysis. The combination of PointNet&amp;thinsp;+&amp;thinsp;+&amp;thinsp;and K-means clustering offers improvements in speed and accuracy while reducing computing costs, addressing important issues in managing large-scale 3D point cloud data. This study highlights the potential of cluster analysis as a preprocessing step to optimize neural network-based systems, paving the way for more reliable and faster processing of 3D point cloud data in real-world scenarios.


---
# Using a modified whale optimization algorithm to solve dynamic arrival flights sequencing problem

## 使用改进的鲸鱼优化算法解决动态到达航班排序问题

Link: https://www.researchsquare.com/article/rs-5301260/latest

For solving dynamic arrival flights sequencing problem, a Modified Whale Optimization Algorithm (MWOA) is proposed. The method can avoid WOA&rsquo;s disadvantage in several aspects, such as local optimum stuck and solution accuracy degradation. To balance the exploration and exploitation abilities, a nonlinear dynamic strategy based on Branin function for updating the control parameter is given. Chaotic mutation based on a sine function is applied to avoid its falling into local optimum. Mirror selection strategy is adopted in iteration to increase convergence speed. The early maturity detection through Gauss vibration is added to improve local mining and global searching abilities. Twenty-five well-known benchmark test functions are used to test the algorithm. The results show MWOA outperforms other six state-of-the-art optimization algorithms which include Particle Swarm Optimization(PSO), Whale Optimization Algorithm(WOA), Improved PSO(IPSO), &beta;-hill Climbing Modified WOA(BMWOA), Harris Hawks Optimization(HHO), WOA-PSO in terms of solution accuracy andconvergence speed. Then, all the above-mentioned seven algorithms, traditional first-come-first-serve(FCFS) sequencing strategy, Immune Teaching-Learning Based Optimization(ITLBO), PSO based on the Random Key representation(PSORK) and Genetic Algorithm-PSO(GA-PSO) are applied to solve the arrival flights sequencing model. The results show MWOA outperforms the nine algorithms and FCFS strategy. The landing efficiency improved is 16.90%, 2.26%, 2.26%, 2.89%, 2.75%, 2.40%, 1.99%, 2.26%, 7.26% and 3.55% respectively compared with FCFS, PSO, WOA, IPSO, BMWOA, HHO, WOA-PSO, GA-PSO, ITLBO and PSORK. Furthermore, the proposed algorithm also has best performance in terms of optimality, reliability, robustness and will-time delay. The Wilcoxon tests show MWOA is significantly different to other algorithms.


---
# Polyimide nanofiber aerogel with hierarchical porosity: a novel platform in high-temperature oil absorption

## 具有分级孔隙率的聚酰亚胺纳米纤维气凝胶: 高温吸油的新平台

Link: https://www.researchsquare.com/article/rs-5301622/latest

The development of advanced oil sorbents with superior thermal stability, high adsorption capacity, and excellent reusability is crucial for addressing hot oil leakage challenges, particularly in the petrochemical and machinery industries. This study presents a novel polyimide (PI) nanofiber aerogel (PIF-a) designed for high-temperature oil absorption. Utilizing electrospinning and post-treatment, PIF-a exhibits a hierarchical pore structure, ultralow density, and remarkable flexibility. At room temperature, PIF-a demonstrates an oil adsorption capacity of 83.1 g/g, surpassing conventional materials. Notably, PIF-a retains structural integrity up to 250&amp;deg;C, with a hot oil adsorption capacity of 78.6 g/g at 200&amp;deg;C. Despite repeated adsorption-desorption cycles, PIF-a's capacity remains stable, retaining over 90% of its initial performance. This breakthrough material, with its exceptional thermal stability, rapid adsorption kinetics, and durable reusability, represents a significant advancement in high-temperature oil absorption technology, broadening the application potential of nanofiber-based materials in addressing environmental oil spill emergencies.


---
# Load Identification with Photovoltaic Distributed Generation and a Novel Public High-Frequency Dataset

## 基于光伏分布式发电和新型公共高频数据集的负荷识别

Link: https://www.researchsquare.com/article/rs-5239291/latest

This paper addresses the identification and classification of Distributed Generation (DG) connected to the secondary distribution network based on the Non-Intrusive Load Monitoring framework. We built a new public dataset with real-world data comprising samples of electrical variables aggregating loads and distributed generation data. Traditionally, NILM methods are concerned with disaggregating, identifying, and classifying electrical loads. On the other hand, Behind the Meter (BTM) estimation methods separate the consumption of electrical loads from the DG power generated by prosumers. Our work expands the traditional NILM and BTM analysis, presenting an ablation study of DG&rsquo;s impact on the identification of electrical loads and the impact that aggregate loads represent for the identification of DG. We use state-of-the-art deep learning-based methods for disaggregation and classification on our new dataset and achieved up to 100% F1-Score for DG identification and up to 98% F1-Score for load disaggregation with the presence of DG.


---
# Visual Localization in 3D Maps: Comparing Point Cloud, Mesh, and NeRF Representations

## 三维地图中的视觉定位: 比较点云、网格和NeRF表示

Link: https://www.researchsquare.com/article/rs-5293991/latest

Recent advances in mapping techniques have enabled the creation of highly accurate dense 3D maps during robotic missions, such as point clouds, meshes, or NeRF-based representations. These developments present new opportunities for reusing these maps for localization.&nbsp; However, there remains a lack of a unified approach that can operate seamlessly across different map representations. This paper presents and evaluates a global visual localization system capable of localizing a single camera image across various 3D map representations built using both visual and lidar sensing. Our system generates a database by synthesizing novel views of the scene, creating RGB and depth image pairs. Leveraging the precise 3D geometric map, our method automatically defines rendering poses, reducing the number of database images while preserving retrieval performance. To bridge the domain gap between real query camera images and synthetic database images, our approach utilizes learning-based descriptors and feature detectors. We evaluate the system's performance through extensive real-world experiments conducted in both indoor and outdoor settings, assessing the effectiveness of each map representation and demonstrating its advantages over traditional structure-from-motion (SfM) localization approaches. The results show that all three map representations can achieve consistent localization success rates of 55% and higher across various environments. NeRF synthesized images show superior performance, localizing query images at an average success rate of 72%. Furthermore, we demonstrate an advantage over SfM-based approaches that our synthesized database enables localization in the reverse travel direction which is unseen during the mapping process. Our system, operating in real-time on a mobile laptop equipped with a GPU, achieves a processing rate of 1Hz.


---
# Improving Athletic Training Through the Integration of Convolutional Neural Networks and Feature Extraction Techniques

## 通过整合卷积神经网络和特征提取技术改善运动训练

Link: https://www.researchsquare.com/article/rs-5306543/latest

This paper presents an innovative approach to improving athlete performance using advanced technology. It introduces a convolutional neural network (CNN) designed to classify training videos of athletes. The CNN architecture includes layers for processing data, such as convolutional, pooling, fully connected, and activation function layers. These layers help identify different types of training, like sprinting, strength exercises, and agility drills. Critical features like motion patterns, body posture, speed, and repetition rate are analyzed to boost performance. The model uses a structured data preprocessing and fusion strategy to enhance accuracy. Tested on the UCF101 dataset, the model demonstrated excellent accuracy, precision, recall, and F1-score results through holdout and K-fold validation methods. A comparison with traditional classifiers shows the proposed method&rsquo;s superior performance. This research offers significant advancements in personalized sports training and real-world action recognition.


---
# TaIncBC: Topic-aware In-context Prompt with Bias Calibration for Event Causality Identification

## TaIncBC: 带有偏差校准的主题感知上下文提示，用于事件因果关系识别

Link: https://www.researchsquare.com/article/rs-5308042/latest

Event Causality Identification (ECI) is to determine whether there exists a causal relation between two event mentions. Recently, the prompt learning paradigm has been applied in the ECI task to leverage a large-scale pre-trained language model through carefully designed prompts, yet their contexts do not describe causal relations. In this paper, we propose to include some topic-aware demonstration samples with their ground-truth labels into the query prompt to form an in-context input prompt, so as to facilitate PLM&rsquo;s understanding and comprehending of universal causal relations. Although including demo samples into prompts may enrich in-context causality information, care must be taken for potential bias that could also be introduced into the event prediction model by such demo samples. To address this challenge, we further design a nearest neighbour-based bias calibration to help alleviating demonstration deviations for our topic-aware in-context prompt learning. Our model, called TaIncBC, is experimented on the widely used EventStoryLine and Causal-TimeBank corpus and results validate our design objective in terms of significantly performance improvements over the state-of-the-art algorithms.


---
# SEGMTM: A Spectrum Prediction Method Based on Enhanced Graph Convolution and Multi-scale Time Decomposition

## SEGMTM: 一种基于增强图卷积和多尺度时间分解的频谱预测方法

Link: https://www.researchsquare.com/article/rs-5297237/latest

The development of wireless communication technology has led to increasing pressure on spectrum resources, making the rational allocation and utilization of these resources a significant challenge both now and in the future. Although spectrum data is a complex nonlinear time series, it exhibits a high degree of temporal and spatial correlation, providing new directions for addressing the issue of spectrum resource scarcity. In response to this situation, this study constructs a multi-scale spatio-temporal spectrum prediction method based on deep learning. First, we analyze the correlations present in different channels of spectrum data and utilize singular spectrum analysis (SSA) to decompose the complex spectrum data into a series of frequency components with underlying structures and patterns. Subsequently, we propose a spectrum prediction model (SEGMTM) that includes an attention-based enhanced graph convolutional network module (A-EGCN) and a multi-scale temporal module (MTM) to model the spatial and temporal correlations of the spectrum data, respectively. Furthermore, to reduce model complexity, we design a D-Regression module for auxiliary predictions. We validate the effectiveness of the proposed method through spectrum quality prediction and spectrum state prediction on two real measured spectrum datasets. Experimental results demonstrate that the proposed method achieves outstanding performance in both prediction tasks, with particularly notable advantages in long-term prediction tasks. In the spectrum quality prediction task, evaluation metrics show an improvement of 1.72% to 21.19%, while in the spectrum state prediction task, the accuracy improves by 1.28% to 3.51%.


---
# Throughput enhancement of High-Bandwidth Wireless Network using Deep Double Q-Network Algorithm

## 基于深度双Q网络算法的高带宽无线网络吞吐量提升

Link: https://www.researchsquare.com/article/rs-5307621/latest

In high-bandwidth network environments, multiple users and devices frequently share similar high-frequency bands, but signal propagation limitations lead to unstable network links. These can affect the throughput of high-bandwidth wireless networks, reducing the continuity and efficiency of data transmission. Therefore, this paper constructs a high-bandwidth wireless network throughput performance enhancement model based on the Double Deep Q-Network algorithm (Double DQN). This method designs a mathematical model for high-bandwidth wireless networks, visually presents node connections using undirected graphs, and constructs a throughput performance enhancement model based on channel allocation and link scheduling by combining interference model analysis. In addition, this method introduces the Double DQN algorithm, integrates the reinforcement learning framework, and realizes dynamic adjustment of optimal channel allocation and link scheduling strategies through continuous interaction and learning between the agent and the environment. Experimental results confirm that this model significantly improves the throughput of high-bandwidth wireless networks to above 2500kb/s and reduces the call drop rate of voice and video network services to 0.01&amp;ndash;0.02%, meeting the demand for high data continuous transmission.


---
# Voice-Assisted Multimodal Fusion Network for Difficult Airway Assessment

## 用于困难气道评估的语音辅助多模态融合网络

Link: https://www.researchsquare.com/article/rs-5304495/latest

Difficult airway management poses significant risks in anesthesia and emergency medicine, including hypoxemia and airway injury. While image-based methods have improved airway assessment, they often fail to capture functional information like airway patency and vocal cord movement. To address this, we propose VAMF-Net (Voice-Assisted Multimodal Fusion Network), which integrates three-view airway images with voice data to improve difficult airway evaluation accuracy. VAMF-Net employs an early fusion strategy of multi-view image features with contrastive learning pretraining, enabling early interaction between views to capture complementary information. Furthermore, We introduce a voice-assisted cross-attention (VCA) module, which prioritizes image data as the primary source while using voice data as supplementary input. A dataset of 1,106 samples (89 difficult and 1017 easy cases) was constructed, with each sample including three airway images (frontal open mouth, frontal tongue extended, and side head tilted back) and voice data. VAMF-Net achieved an AUC of 0.917, sensitivity of 0.931, and specificity of 0.815, demonstrating superior performance compared to existing methods.


---
# Towards Efficient, Fair and Interpretable Neural Dynamic Data Valuation

## 走向高效、公平和可解释的神经动态数据估值

Link: https://www.researchsquare.com/article/rs-5307676/latest

In the modern data economy, data has emerged as a valuable form of property, driving the growth of data marketplaces and elevating the importance of data valuation. While existing methods have made progress in this field, they often struggle to simultaneously achieve efficiency, fairness, and interpretability. To address these challenges, we introduce a novel approach called Neural Dynamic Data Valuation (NDDV), which leverages the principles of optimal control theory. NDDV offers a comprehensive framework that accounts for the dynamic nature of data value and the intricate interactions between data points. By reformulating classical valuation criteria through the lens of stochastic optimal control, our method provides a fresh perspective on quantifying data worth. At its core, NDDV employs trajectory learning to accurately identify data value, supported by robust theoretical interpretations. We enhance the method's fairness through a data re-weighting strategy that captures unique features of individual data points, facilitating interactions between individual data states and the weighted mean-field state. Our results demonstrate NDDV's ability to unveil the dynamic process of data valuation while extending to an interpretable model. Importantly, NDDV achieves significant computational efficiency by requiring only a single training session to estimate the value of all data points. This advancement represents a substantial improvement over existing methods, potentially revolutionizing how we approach data valuation in complex, real-world scenarios.


---
# Estimation of Daylily Leaf Area Index by Synergy Multispectral and Radar Remote-Sensing Data based on&nbsp;Machine-Learning Algorithm

## 基于机器学习算法的协同多光谱与雷达遥感数据估算黄花菜叶面积指数

Link: https://www.researchsquare.com/article/rs-5302684/latest

Rapid and accurate leaf area index (LAI) determination is important to monitoring daylily growth, yield estimation, and field management. Because of low estimation accuracy of empirical models based on single-source data, we proposed a machine-learning algorithm combining optical and microwave remote-sensing data, and the random forest regression (RFR) importance score to select features. A high-precision LAI estimation model for daylilies was constructed by optimizing feature combinations. The RFR importance score screened the top five important features, including vegetation indices land surface water index (LSWI), generalized difference vegetation index (GDVI), normalized difference yellowness index (NDYI) and backscatter coefficients VV and VH. Vegetation index features characterized canopy moisture and color of daylilies, and the backscatter coefficient reflected dielectric properties and geometric structure. Selected features were sensitive to daylily LAI. The RFR algorithm had good anti-noise performance and strong fitting ability; thus, its accuracy was better than the partial least squares regression and artificial neural network models. Synergistic optical and microwave data more comprehensively reflected the physical and chemical properties of daylilies, making the RFR-VI-BC05 model after feature selection better than the others. This study expanded methods for estimating daylily LAI by combining optical and radar data, providing technical support for daylily management.


---
# A Bibliometric Study of Blended Learning in Higher Education (2001- 2024)

## 高等教育混合学习的文献计量研究 (2001- 2024)

Link: https://www.researchsquare.com/article/rs-5302006/latest

This study presents a comprehensive bibliometric analysis of blended learning in higher education (BLHE) research from 2001 to 2024. Using CiteSpace, we analyzed 2,125 publications from the Web of Science Core Collection to map the intellectual structure and evolution of the field. Our findings reveal a significant increase in BLHE research from 2013 onwards, with peak productivity in 2018 and 2019. Conference proceedings emerged as dominant publication venues, reflecting the field's dynamic nature. Document co-citation analysis identified influential works, with Garrison and Kanuka's (2004) Community of Inquiry framework emerging as particularly impactful. Cluster analysis revealed 11 distinct research areas, including blended learning foundations, self-regulated learning, game-based learning, and work-integrated learning. These clusters highlight the multifaceted nature of BLHE research and its integration with various pedagogical approaches and technologies. Our analysis also uncovered several research gaps, including a need for more diverse cultural perspectives, longitudinal studies examining long-term impacts, and research on innovative assessment strategies in blended environments. While the field has made significant progress in understanding BLHE implementation, challenges remain in addressing cultural diversity and long-term effectiveness. This study provides researchers, educators, and policymakers with insights into the field's intellectual structure, emerging trends, and future directions. As blended learning continues to shape higher education, addressing identified research gaps will be crucial for developing more effective, inclusive, and transformative learning experiences.


---
# A Secure data-driven algorithm against malicious intrusion signals in mobile communication networks

## 移动通信网络中针对恶意入侵信号的安全数据驱动算法

Link: https://www.researchsquare.com/article/rs-5310069/latest

Intrusion signals in mobile communication networks are often disguised as normal communication signals to attack, which is highly covert. This makes it difficult to be accurately recognized and increases the danger of data leakage. For this reason, this paper proposes a full link security defense algorithm against malicious intrusion signals in mobile communication networks based on data-driven technique. This algorithm uses the support vector machine technology to construct an identification model against the malicious intrusion signal of the full link and introduces the firefly algorithm to optimize the support vector parameters of the model to ensure the accuracy of the model in identifying the malicious intrusion signal. In addition, this algorithm uses a network full link security defense model based on dynamic camouflage technology to dynamically simulate any element of the full link in the mobile communication network, and at the same time constructs heterogeneous executives to distribute the results of the malicious intrusion signal to each selected heterogeneous executor. Experimental results show that the proposed algorithm can accurately identify different types of malicious intrusion type signal samples, so that the interception rate of the intrusion defense system against malicious intrusion signals is greater than 99%, and the important data loss rate is less than 1%.


---
# JND-Based Illumination Compensationand DoG-Mask RCNN Optimization forAccurate Radish Image&nbsp; Segmentation

## 基于JND的光照补偿和DoG-Mask RCNN优化的萝卜图像精确分割

Link: https://www.researchsquare.com/article/rs-5285927/latest

The widespread application of deep learning in the agricultural field has advanced radish segmentation and detection technologies. However, the issue of high dynamic range in backlit images captured by smartphones affects the monitoring of radish growth. Deep learning-based methods tend to perform poorly in complex lighting conditions, struggling with background interference, overexposure, and information loss. In this paper, we propose a new DoG-Mask RCNN network based on JND (Just Noticeable Difference) visual contrast compensation preprocessing. The network incorporates data preprocessing techniques for challenging environments as input, where the DoG layer is used to suppress overexposure in special conditions and filter out irrelevant background information. This layer retains spot details through its filtering capabilities, while the increment layer ensures the integrity of the feature information. We conducted experiments on radish mixed with traditional crops in different challenging environments to demonstrate the effectiveness of our method in detecting radish parts under various conditions. Compared to the latest monitoring methods, our approach shows better detection stability.


---
# A Reconstructed Priority Assignment Method for Computationally Intensive Task Offloading in Mobile Communication Networks

## 移动通信网络中用于计算密集型任务卸载的重构优先级分配方法

Link: https://www.researchsquare.com/article/rs-5308180/latest

Computationally intensive tasks often require substantial energy support, and mobile devices may experience slow task execution, response delays, and device overheating due to insufficient processing capabilities. By offloading computationally intensive tasks, the energy consumption of mobile devices can be reduced, and the resource utilization and network balance of mobile communication networks can be improved. Therefore, this paper designs a refactored priority division method for offloading computationally intensive tasks in mobile communication networks. This method first calculates the execution delay and energy consumption of mobile communication network system devices, mobile edge computing servers, and cloud servers, and uses these as factors for the refactored priority division of computationally intensive tasks. Then, it employs the Analytic Hierarchy Process (AHP) to refactor the priority division of computationally intensive tasks in mobile communication networks. In addition, deep reinforcement learning is used to comprehensively consider multiple factors such as delay and energy consumption to find the optimal offloading decision. Experimental results show that this method can effectively offload computationally intensive tasks from mobile devices and mobile edge computing servers and improve the balance of mobile communication networks.


---
# Material discovery of secondary and natural cementitious precursors

## 二次和天然胶凝前体的材料发现

Link: https://www.researchsquare.com/article/rs-5342559/latest

Cement production contributes to over 6% of global greenhouse gas (GHG) emissions, driven by clinker&rsquo;s energy-intensive production and limestone calcination. Substituting clinker with cementitious substitutes is an effective strategy for decarbonization. However, typical clinker substitutes---coal fly ash and ground granulated blast furnace slag---face current and future supply constraints. Here we systematically map reactivity variations and expand the repertoire of secondary and natural cementitious precursors. Large language models extract chemical compositions and material types of 14,000 materials from 88,000 academic papers. A multi-headed neural network predicts the degree of cementitious reactivity and pozzolanicity. Subject to performance constraints, current supply allows for substituting half of global cement production with construction and demolition wastes and municipal solid waste incineration ash, reducing the global GHG emissions by 3%---equating to removing 260 million vehicles from the roads in United States. Discovered natural cementitious precursors, including rhyolite, dacite, and gabbro, are distributed globally and show significant potential as raw substitutes for clinker.


---
# Wideband ratiometric measurement of tonic and phasic dopamine release in the striatum

## 纹状体中强直性和阶段性多巴胺释放的宽带比率测量

Link: https://www.researchsquare.com/article/rs-5296053/latest

Reward learning, cognition, and motivation are supported by changes in neurotransmitter levels across multiple timescales. Current measurement technologies for various neuromodulators (such as dopamine and serotonin) do not bridge timescales of fluctuations, limiting the ability to define the behavioral significance, regulation, and relationship between fast (phasic) and slow (tonic) dynamics. To help resolve longstanding debates about the behavioral significance of dopamine across timescales, we developed a novel quantification strategy, augmenting extensively used carbon-fiber Fast Scan Cyclic Voltammetry (FSCV). We iteratively engineered the FSCV scan sequence to rapidly modify electrode sensitivity within a sampling window and applied ratiometric analysis for wideband dopamine measurement. This allowed us to selectively eliminate artifacts unrelated to electrochemical detection (i.e., baseline drift), overcoming previous limitations that precluded wideband dopamine detection from milliseconds to hours. After extensive characterization and validation in vitro and in vivo with simultaneous microdialysis, pharmacological, reward, and optogenetic manipulations, we demonstrate the utility of ratiometric FSCV to resolve key questions about how phasic DA transients contribute to setting striatal DA tone. We identify specific DA frequency bands that correlate with canonical microdialysis-defined &ldquo;tonic&rdquo; DA levels while also uncovering a paradoxical constraint on the accumulation of phasic DA into tonic levels. Our approach can extend to additional analytes, including serotonin, empowering the emperical testing of contrasting predictions from theories about neuromodulator circuit and computaional mechanisms that support behavioral flexibility.


---
# Synthetic Data for Accessible Learning in Healthcare: Improving Mortality Prediction with Longitudinal Data

## 医疗保健中无障碍学习的合成数据: 通过纵向数据改善死亡率预测

Link: https://www.researchsquare.com/article/rs-5363467/latest

Accurate prediction of medium-term survival after admission is necessary for identifying end-of-life patients who may benefit from earlier goals of care (GOC) discussions. While previous studies have leveraged admission data from electronic health records (EHRs) to predict the hospital one-year mortality risk (HOMR) score, they focused on single admissions, without considering longitudinal patient history and its impact on prognostication. &amp;nbsp;To address this gap, we developed the Ensemble Long Short-Term Memory (ELSTM) neural network, which learns from multiple visits of the same patient to improve the accuracy of the HOMR score. Furthermore, in this work, we generated a synthetic dataset and made it publicly available to encourage further research in this area while safeguarding patient privacy.


---
# Advanced Neural Analysis for Ransomware Detection Through Dynamic Network Signature Mapping

## 通过动态网络签名映射进行勒索软件检测的高级神经分析

Link: https://www.researchsquare.com/article/rs-5369384/latest

Dynamic Network Signature Mapping (DNSM) is introduced as a novel and advanced approach for detecting ransomware threats through adaptive, real-time analysis of network traffic patterns. Utilizing an integrated framework of convolutional and recurrent neural networks, DNSM captures spatial and temporal dependencies within network data, enabling precise classification of ransomware activities even under encrypted or high-volume conditions. Unlike traditional, signature-based methods, DNSM constructs a dynamic and evolving threat profile that reduces the need for manual updates, thereby improving adaptability to emerging ransomware techniques. Empirical results from the study validate DNSM&rsquo;s ability to maintain high detection accuracy and low false positive rates across a spectrum of network environments, while demonstrating efficient real-time performance critical for high-stakes operational contexts. The modularity of DNSM, coupled with its automated threat scoring and pattern recognition capabilities, establishes it as a resilient solution that addresses the demands of modern ransomware detection, offering a scalable, resource-effective alternative for proactive network security.


---
# Analysis of GLCM-feature-based dimensionality reduction and feature extraction methods for classifying fabric design patterns by using video data

## 利用视频数据分析基于GLCM特征的织物设计图案降维与特征提取方法

Link: https://www.researchsquare.com/article/rs-5370165/latest

Manufacturing industries now leverage high-dimensional streaming video data from diverse sensors, represented as tensors (multidimensional arrays of channels &amp;times; signals &amp;times; time), for real-time monitoring, inspection, and quality control; however, this data often contains redundancy and captures only a subset of the complete dataset. Selecting effective dimensionality reduction and feature extraction methods for high-dimensional data structures remains challenging. To address these challenges, this paper presents a comparative framework for effective dimensionality reduction and feature extraction, utilizing supervised methods&amp;mdash;Principal Component Analysis (PCA) and Independent Component Analysis (ICA)&amp;mdash;alongside the unsupervised Multilinear-PCA (MPCA), which can more effectively handle multidimensional tensor structures compared to the 1-D or 2-D limitations of PCA and ICA. We evaluate this comparative framework for classifying fabric design patterns using high-dimensional video data captured from various fabric surface weave patterns. The videos are converted into sequential RGB frames and analyzed using the Gray-Level Co-occurrence Matrix (GLCM) for feature extraction, after which the dimensionality of the GLCM features is reduced with PCA, ICA, and MPCA, and the features are classified using supervised machine learning techniques for fabric design pattern recognition. MPCA achieves a 0.022% dimensionality reduction by extracting uniformly distributed features that effectively capture correlated fabric design patterns, unlike the less organized distributions from PCA and ICA. The fabric pattern classification accuracy achieved with MPCA, PCA, and ICA was 99.02%, 95.21%, and 92.68%, respectively. These results suggest that the proposed framework effectively facilitates dimensionality reduction and feature extraction in both supervised and unsupervised methods for high-dimensional video data.

