# Advanced terahertz neural network offers compact solution for AI challenges

## 先进的太赫兹神经网络为AI挑战提供了紧凑的解决方案

Link: https://phys.org/news/2024-11-advanced-terahertz-neural-network-compact.html

An innovative planar spoof plasmonic neural network (SPNN) platform capable of directly detecting and processing terahertz (THz) electromagnetic signals has been unveiled by researchers at City University of Hong Kong (CityUHK) and Southeast University in Nanjing.


---
# Foundation models in healthcare require rethinking reliability

## 医疗保健的基础模型需要重新考虑可靠性

Link: https://www.nature.com/articles/s42256-024-00924-5

<p>Nature Machine Intelligence, Published online: 11 November 2024; <a href="https://www.nature.com/articles/s42256-024-00924-5">doi:10.1038/s42256-024-00924-5</a></p>A new class of AI models, called foundation models, has entered healthcare. Foundation models violate several basic principles of the standard machine learning paradigm for assessing reliability, making it necessary to rethink what guarantees are required to establish warranted trust in them.


---
# Artificial boundaries

## 人工边界

Link: https://www.nature.com/articles/s41567-024-02717-4

<p>Nature Physics, Published online: 11 November 2024; <a href="https://www.nature.com/articles/s41567-024-02717-4">doi:10.1038/s41567-024-02717-4</a></p>The 2024 Nobel prize for Physics was awarded for foundational contributions to the development of artificial neural networks. The award reflects a shift in how we understand boundaries between scientific fields — or whether such boundaries are still useful at all.


---
# Author Correction: Avalanches and edge-of-chaos learning in neuromorphic nanowire networks

## 作者更正: 神经形态纳米线网络中的雪崩和混沌边缘学习

Link: https://www.nature.com/articles/s41467-024-54027-1

<p>Nature Communications, Published online: 11 November 2024; <a href="https://www.nature.com/articles/s41467-024-54027-1">doi:10.1038/s41467-024-54027-1</a></p>Author Correction: Avalanches and edge-of-chaos learning in neuromorphic nanowire networks


---
# Spectroscopy-guided discovery of three-dimensional structures of disordered materials with diffusion models

## 光谱引导的具有扩散模型的无序材料三维结构的发现

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad8c10

Spectroscopy techniques such as x-ray absorption near edge structure (XANES) provide valuable insights into the atomic structures of materials, yet the inverse prediction of precise structures from spectroscopic data remains a formidable challenge. In this study, we introduce a framework that combines generative artificial intelligence models with XANES spectroscopy to predict three-dimensional atomic structures of disordered systems, using amorphous carbon (a-C) as a model system. In this work, we introduce a new framework based on the diffusion model, a recent generative machine learning method, to predict 3D structures of disordered materials from a target property. For demonstration, we apply the model to identify the atomic structures of a-C as a representative material system from the target XANES spectra. We show that conditional generation guided by XANES spectra reproduces key features of the target structures. Furthermore, we show that our model can steer the generative process to tailor atomic arrangements for a specific XANES spectrum. Finally, our generative model exhibits a remarkable scale-agnostic property, thereby enabling generation of realistic, large-scale structures through learning from a small-scale dataset (i.e. with small unit cells). Our work represents a significant stride in bridging the gap between materials characterization and atomic structure determination; in addition, it can be leveraged for materials discovery in exploring various material properties as targeted.


---
# Learning the rules of peptide self-assembly through data mining with large language models

## 通过大语言模型的数据挖掘学习肽自组装的规则

Link: https://arxiv.org/abs/2411.05421

arXiv:2411.05421v1 Announce Type: new 
Abstract: Peptides are ubiquitous and important biologically derived molecules, that have been found to self-assemble to form a wide array of structures. Extensive research has explored the impacts of both internal chemical composition and external environmental stimuli on the self-assembly behaviour of these systems. However, there is yet to be a systematic study that gathers this rich literature data and collectively examines these experimental factors to provide a global picture of the fundamental rules that govern protein self-assembly behavior. In this work, we curate a peptide assembly database through a combination of manual processing by human experts and literature mining facilitated by a large language model. As a result, we collect more than 1,000 experimental data entries with information about peptide sequence, experimental conditions and corresponding self-assembly phases. Utilizing the collected data, ML models are trained and evaluated, demonstrating excellent accuracy (>80\%) and efficiency in peptide assembly phase classification. Moreover, we fine-tune our GPT model for peptide literature mining with the developed dataset, which exhibits markedly superior performance in extracting information from academic publications relative to the pre-trained model. We find that this workflow can substantially improve efficiency when exploring potential self-assembling peptide candidates, through guiding experimental work, while also deepening our understanding of the mechanisms governing peptide self-assembly. In doing so, novel structures can be accessed for a range of applications including sensing, catalysis and biomaterials.


---
# Smart navigation through a rotating barrier: Deep reinforcement learning with application to size-based separation of active microagents

## 通过旋转屏障的智能导航: 深度强化学习应用于基于尺寸的活性微试剂分离

Link: https://arxiv.org/abs/2411.05587

arXiv:2411.05587v1 Announce Type: new 
Abstract: We employ deep reinforcement learning methods to investigate shortest-time navigation strategies for smart active Brownian particles (agents) that self-propel through a rotating, localized potential barrier in an otherwise static and viscous fluid background. The particle motion is prescribed to begin from a specified start point and terminate at a specified destination point. The potential barrier is modeled as a repulsive Gaussian potential with a finite range that rotates with given angular velocities around a fixed center within the plane of motion. We use an advantage actor-critic approach to train the agents and demonstrate that, by leveraging this approach, the rotating potential can be utilized for size-based sorting and separation of the agents. In other words, agents of different (hydrodynamic) radii reach the end-point at sufficiently well-separated times, enabling their separation. The efficiency of particle separation in this context is discussed using specific criteria. We also study the effect of rotational Brownian noise on the quality of the proposed size-based sorting mechanism. Additionally, we demonstrate how the use of noise-induced training can enhance this mechanism in a noisy background within the range of parameters explored in our work. Reinforcement learning in the context of active particles thus offers promising avenues to unravel optimal navigation strategies within complex environments, with potential applications that can be utilized in microfluidic settings.


---
# Biased Degenerate Ground-State Sampling of Small Ising Models with Converged QAOA

## 具有收敛QAOA的小Ising模型的偏置简并基态采样

Link: https://arxiv.org/abs/2411.05294

arXiv:2411.05294v1 Announce Type: cross 
Abstract: The Quantum Alternating Operator Ansatz, a generalization of the Quantum Approximate Optimization Algorithm (QAOA), is a quantum algorithm used for approximately solving combinatorial optimization problems. QAOA typically uses the Transverse field mixer as the driving Hamiltonian. One of the interesting properties of the Transverse-field driving Hamiltonian is that it results in non-uniform sampling of degenerate ground states of optimization problems. In this study we numerically examine the fair sampling properties transverse field mixer QAOA, and Grover Mixer QAOA (GM-QAOA) which provides theoretical guarantees of fair sampling of degenerate optimal solutions, up to large enough p such that the mean expectation value converges to an optimal approximation ratio of 1. This comparison is performed with high quality heuristically computed, but not necessarily optimal, QAOA angles which give strictly monotonically improving solution quality as p increases. These angles are computed using the Julia based numerical simulation software JuliQAOA. Fair sampling of degenerate ground-states is quantified using Shannon entropy of the ground-state amplitudes distribution. The fair sampling properties are reported on several quantum signature Hamiltonians from previous quantum annealing fair sampling studies. Small random fully connected spin glasses are shown which exhibit exponential suppression of some degenerate ground-states with transverse field mixer QAOA. The transverse field mixer QAOA simulations show that some problem instances clearly saturate the Shannon entropy of 0 with a maximally biased distribution that occurs when the learning converges to an approximation ratio of 1 while other problem instances never deviate from a maximum Shannon entropy (uniform distribution) at any p step.


---
# Synaptic-Like Plasticity in 2D Nanofluidic Memristor from Competitive Bicationic Transport

## 竞争性双离子传输在2D纳米流体忆阻器中的突触样可塑性

Link: https://arxiv.org/abs/2406.10510

arXiv:2406.10510v2 Announce Type: replace 
Abstract: Synaptic plasticity, the dynamic tuning of signal transmission strength between neurons, serves as a fundamental basis for memory and learning in biological organisms. This adaptive nature of synapses is considered one of the key features contributing to the superior energy efficiency of the brain. In this study, we utilize molecular dynamics simulations to demonstrate synaptic-like plasticity in a subnanoporous 2D membrane. We show that a train of voltage spikes dynamically modifies the membrane's ionic permeability in a process involving competitive bicationic transport. This process is shown to be repeatable after a given resting period. Due to a combination of sub-nm pore size and the atomic thinness of the membrane, this system exhibits energy dissipation of 0.1--100 aJ per voltage spike, which is several orders of magnitude lower than 0.1--10 fJ per spike in the human synapse. We reveal the underlying physical mechanisms at molecular detail and investigate the local energetics underlying this apparent synaptic-like behavior.


---
# High-Tc superconductor candidates proposed by machine learning

## 机器学习提出的高Tc超导体候选

Link: https://arxiv.org/abs/2406.14524

arXiv:2406.14524v2 Announce Type: replace 
Abstract: We cast the relation between the chemical composition of a solid-state material and its superconducting critical temperature (Tc) as a statistical learning problem with reduced complexity. Training of query-aware similarity-based ridge regression models on experimental SuperCon data achieve average Tc prediction errors of ~5 K for unseen out-of-sample materials. Two models were trained with one excluding high pressure data in training ("ambient" model) and a second also including high pressure data ("implicit" model). Subsequent utilization of the approach to scan ~153k materials in the Materials Project enables the ranking of candidates by Tc while accounting for thermodynamic stability and small band gap. The ambient model is used to predict stable top three high-Tc candidate materials that include those with large band gaps of LiCuF4 (316 K), Ag2H12S(NO)4 (316 K), and Na2H6PtO6 (315 K). Filtering these candidates for those with small band gaps correspondingly yields LiCuF4 (316 K), Cu2P2O7 (311 K), and Cu3P2H2O9 (307 K).


---
# Cascade of phase transitions in the training of Energy-based models

## 基于能量的模型训练中的相变级联

Link: https://arxiv.org/abs/2405.14689

arXiv:2405.14689v3 Announce Type: replace-cross 
Abstract: In this paper, we investigate the feature encoding process in a prototypical energy-based generative model, the Restricted Boltzmann Machine (RBM). We start with an analytical investigation using simplified architectures and data structures, and end with numerical analysis of real trainings on real datasets. Our study tracks the evolution of the model's weight matrix through its singular value decomposition, revealing a series of phase transitions associated to a progressive learning of the principal modes of the empirical probability distribution. The model first learns the center of mass of the modes and then progressively resolve all modes through a cascade of phase transitions. We first describe this process analytically in a controlled setup that allows us to study analytically the training dynamics. We then validate our theoretical results by training the Bernoulli-Bernoulli RBM on real data sets. By using data sets of increasing dimension, we show that learning indeed leads to sharp phase transitions in the high-dimensional limit. Moreover, we propose and test a mean-field finite-size scaling hypothesis. This shows that the first phase transition is in the same universality class of the one we studied analytically, and which is reminiscent of the mean-field paramagnetic-to-ferromagnetic phase transition.


---
# Fast training and sampling of Restricted Boltzmann Machines

## 受限玻尔兹曼机的快速训练和采样

Link: https://arxiv.org/abs/2405.15376

arXiv:2405.15376v2 Announce Type: replace-cross 
Abstract: Restricted Boltzmann Machines (RBMs) are effective tools for modeling complex systems and deriving insights from data. However, training these models with highly structured data presents significant challenges due to the slow mixing characteristics of Markov Chain Monte Carlo processes. In this study, we build upon recent theoretical advancements in RBM training, to significantly reduce the computational cost of training (in very clustered datasets), evaluating and sampling in RBMs in general. The learning process is analogous to thermodynamic continuous phase transitions observed in ferromagnetic models, where new modes in the probability measure emerge in a continuous manner. Such continuous transitions are associated with the critical slowdown effect, which adversely affects the accuracy of gradient estimates, particularly during the initial stages of training with clustered data. To mitigate this issue, we propose a pre-training phase that encodes the principal components into a low-rank RBM through a convex optimization process. This approach enables efficient static Monte Carlo sampling and accurate computation of the partition function. We exploit the continuous and smooth nature of the parameter annealing trajectory to achieve reliable and computationally efficient log-likelihood estimations, enabling online assessment during the training, and propose a novel sampling strategy named parallel trajectory tempering (PTT) which outperforms previously optimized MCMC methods. Our results show that this training strategy enables RBMs to effectively address highly structured datasets that conventional methods struggle with. We also provide evidence that our log-likelihood estimation is more accurate than traditional, more computationally intensive approaches in controlled scenarios. The PTT algorithm significantly accelerates MCMC processes compared to existing and conventional methods.


---
# Bayesian RG Flow in Neural Network Field Theories

## 神经网络场论中的贝叶斯RG流

Link: https://arxiv.org/abs/2405.17538

arXiv:2405.17538v2 Announce Type: replace-cross 
Abstract: The Neural Network Field Theory correspondence (NNFT) is a mapping from neural network (NN) architectures into the space of statistical field theories (SFTs). The Bayesian renormalization group (BRG) is an information-theoretic coarse graining scheme that generalizes the principles of the exact renormalization group (ERG) to arbitrarily parameterized probability distributions, including those of NNs. In BRG, coarse graining is performed in parameter space with respect to an information-theoretic distinguishability scale set by the Fisher information metric. In this paper, we unify NNFT and BRG to form a powerful new framework for exploring the space of NNs and SFTs, which we coin BRG-NNFT. With BRG-NNFT, NN training dynamics can be interpreted as inducing a flow in the space of SFTs from the information-theoretic `IR' $\rightarrow$ `UV'. Conversely, applying an information-shell coarse graining to the trained network's parameters induces a flow in the space of SFTs from the information-theoretic `UV' $\rightarrow$ `IR'. When the information-theoretic cutoff scale coincides with a standard momentum scale, BRG is equivalent to ERG. We demonstrate the BRG-NNFT correspondence on two analytically tractable examples. First, we construct BRG flows for trained, infinite-width NNs, of arbitrary depth, with generic activation functions. As a special case, we then restrict to architectures with a single infinitely-wide layer, scalar outputs, and generalized cos-net activations. In this case, we show that BRG coarse-graining corresponds exactly to the momentum-shell ERG flow of a free scalar SFT. Our analytic results are corroborated by a numerical experiment in which an ensemble of asymptotically wide NNs are trained and subsequently renormalized using an information-shell BRG scheme.


---
# Biquaternion Signal Processing for Nonlinear Ultrasonics

## 非线性超声的双四元数信号处理

Link: https://arxiv.org/abs/2411.05018

arXiv:2411.05018v1 Announce Type: new 
Abstract: Localization and classification of scattered nonlinear ultrasonic signatures in 2 dimensional complex damaged media using Time Reversal based Nonlinear Elastic Wave Spectroscopy (TR-NEWS) approach is extended to 3 dimensional complex damaged media. In (2+1)D, i.e. space 2 dimensional time 1 dimensional spacetime, we used quaternion bases for analyses, while in (3+1)D, we use biquaternion bases.
  The optimal weight function of the path of ultrasonic wave in (3+1)D lattice is obtained by using the Echo State Network (ESN) which is a Machine Learning technique. The hysteresis effect is incorporated by using the Preisach-Mayergoyz model.


---
# Enhancing Accuracy and Feature Insights in Hydration Free Energy Predictions for Small Molecules with Machine Learning

## 通过机器学习提高小分子水合自由能预测的准确性和特征洞察力

Link: https://arxiv.org/abs/2411.05019

arXiv:2411.05019v1 Announce Type: new 
Abstract: The accurate prediction of solvation free energy is of significant importance as it governs the behavior of solutes in solution. In this work, we apply a variety of machine learning techniques to predict and analyze the alchemical free energy of small molecules. Our methodology incorporates an ensemble of machine learning models with feature processing using the K-nearest neighbors algorithm. Two training strategies are explored: one based on experimental data, and the other based on the offset between molecular dynamics (MD) simulations and experimental measurements. The latter approach yields a substantial improvement in predictive accuracy, achieving a mean unsigned error (MUE) of 0.64 kcal/mol. Feature analysis identifies molecular geometry and topology as the most critical factors in predicting alchemical free energy, supporting the established theory that surface tension is a key determinant. Furthermore, the feature analysis of offset results highlights the relevance of charge distribution within the system, which correlates with the inaccuracies in force fields employed in MD simulations and may provide guidance for improving force field designs. These results suggest that machine learning approaches can effectively capture the complex features governing solvation free energy, offering novel pathways for enhancing predictive accuracy.


---
# Intra-operative Optimal Flow Diverter Selection for Intracranial aneurysm treatment using Angiographic parametric imaging: Feasibility study

## 使用血管造影参数成像技术选择颅内动脉瘤的术中最佳流量分流器: 可行性研究

Link: https://arxiv.org/abs/2411.05284

arXiv:2411.05284v1 Announce Type: new 
Abstract: During intracranial aneurysm (IA) treatment with Diverters (FDs), the device/parent artery diameters ratio may influence the ability of the device to induce aneurysm healing response. Oversized FDs are safer to deploy but may not induce enough hemodynamic resistance to ensure aneurysm occlusion. Methods based on Computational Fluid Dynamics (CFD) could allow optimal device selection but are time-consuming and inadequate for intra-operative guidance. To address this limitation, we propose to investigate a method for optimal FD selection using Angiographic Parametric Imaging (API) and machine learning (ML). We selected 128 pre-treatment angiographic sequences of IAs which demonstrated full occlusion at six months follow-up. For each IA, we extracted five API parameters from the aneurysm dome and normalized them to the feeding artery corresponding parameters. We dichotomized the dataset based on the FD/ proximal artery diameter ratio as undersized, if the ratio<1 or if multiple FDs were used and oversized otherwise. Single API parameter and ML analysis were used to determine whether API parameters could be used to determine the need for FD under-sizing (i.e., increased flow resistance). Classification accuracy was assessed using area under the receiver operator characteristic (AUROC). In total we identified 51 and 77 cases for the undersized and oversized cohorts respectively. Single API parameter analysis yielded an inadequate AUROC ~0.5 while machine learning using all five API parameters yielded and AUROC of 0.72.


---
# Combining Bayesian Optimization, SVD and Machine Learning for Advanced Optical Design

## 结合贝叶斯优化，SVD和机器学习进行高级光学设计

Link: https://arxiv.org/abs/2411.05496

arXiv:2411.05496v1 Announce Type: new 
Abstract: The design and optimization of optical components, such as Bragg gratings, are critical for applications in telecommunications, sensing, and photonic circuits. To overcome the limitations of traditional design methods that rely heavily on computationally intensive simulations and large datasets, we propose an integrated methodology that significantly reduces these burdens while maintaining high accuracy in predicting optical response. First, we employ a Bayesian optimization technique to strategically select a limited yet informative number of simulation points from the design space, ensuring that each contributes maximally to the model's performance. Second, we utilize singular value decomposition to effectively parametrize the entire reflectance spectra into a reduced set of coefficients, allowing us to capture all significant spectral features without losing crucial information. Finally, we apply XGBoost, a robust machine learning algorithm, to predict the entire reflectance spectra from the reduced dataset. The combination of Bayesian optimization for data selection, SVD for full-spectrum fitting, and XGBoost for predictive modeling provides a powerful, generalizable framework for the design of optical components.


---
# Prediction of Mode Structure Using A Novel Physics-Embedded Neural ODE Method

## 使用新颖的物理嵌入式神经ODE方法预测模式结构

Link: https://arxiv.org/abs/2411.05528

arXiv:2411.05528v1 Announce Type: new 
Abstract: We designed a new artificial neural network by modifying the neural ordinary differential equation (NODE) framework to successfully predict the time evolution of the 2D mode profile in both the linear growth and nonlinear saturated stages. Starting from the magnetohydrodynamic (MHD) equations, simplifying assumptions were applied based on physical properties and symmetry considerations of the energetic-particle-driven geodesic acoustic mode (EGAM) to reduce complexity. Our approach embeds physical laws directly into the neural network architecture by exposing latent differential states, enabling the model to capture complex features in the nonlinear saturated stage that are difficult to describe analytically, and thus, the new artificial neural network is named as ExpNODE (Exposed latent state Neural ODE). ExpNODE was evaluated using a data set generated from first-principles simulations of the EGAM instability, focusing on the pre-saturated stage and the nonlinear saturated stage where the mode properties are most complex. Compared to state-of-the-art models such as ConvLSTM, ExpNODE with physical information not only achieved lower test loss but also converged faster during training. Specifically, it outperformed ConvLSTM method in both the 20-step and 40-step prediction horizons, demonstrating superior accuracy and efficiency. Additionally, the model exhibited strong generalization capabilities, accurately predicting mode profiles outside the training data set. Visual comparisons between model predictions and ground truth data showed that ExpNODE with physical information closely captured detailed features and asymmetries inherent in the EGAM dynamics that were not adequately captured by other models. These results suggest that integrating physical knowledge into neural ODE frameworks enhances their performance, and provides a powerful tool for modeling complex plasma phenomena.


---
# Physics-constrained coupled neural differential equations for one dimensional blood flow modeling

## 一维血流建模的物理约束耦合神经微分方程

Link: https://arxiv.org/abs/2411.05631

arXiv:2411.05631v1 Announce Type: new 
Abstract: Computational cardiovascular flow modeling plays a crucial role in understanding blood flow dynamics. While 3D models provide acute details, they are computationally expensive, especially with fluid-structure interaction (FSI) simulations. 1D models offer a computationally efficient alternative, by simplifying the 3D Navier-Stokes equations through axisymmetric flow assumption and cross-sectional averaging. However, traditional 1D models based on finite element methods (FEM) often lack accuracy compared to 3D averaged solutions. This study introduces a novel physics-constrained machine learning technique that enhances the accuracy of 1D blood flow models while maintaining computational efficiency. Our approach, utilizing a physics-constrained coupled neural differential equation (PCNDE) framework, demonstrates superior performance compared to conventional FEM-based 1D models across a wide range of inlet boundary condition waveforms and stenosis blockage ratios. A key innovation lies in the spatial formulation of the momentum conservation equation, departing from the traditional temporal approach and capitalizing on the inherent temporal periodicity of blood flow. This spatial neural differential equation formulation switches space and time and overcomes issues related to coupling stability and smoothness, while simplifying boundary condition implementation. The model accurately captures flow rate, area, and pressure variations for unseen waveforms and geometries. We evaluate the model's robustness to input noise and explore the loss landscapes associated with the inclusion of different physics terms. This advanced 1D modeling technique offers promising potential for rapid cardiovascular simulations, achieving computational efficiency and accuracy. By combining the strengths of physics-based and data-driven modeling, this approach enables fast and accurate cardiovascular simulations.


---
# On-chip rewritable phase-change metasurface for programmable diffractive deep neural networks

## 用于可编程衍射深度神经网络的片上可重写相变超表面

Link: https://arxiv.org/abs/2411.05723

arXiv:2411.05723v1 Announce Type: new 
Abstract: Photonic neural networks capable of rapid programming are indispensable to realize many functionalities. Phase change technology can provide nonvolatile programmability in photonic neural networks. Integrating direct laser writing technique with phase change material (PCM) can potentially enable programming and in-memory computing for on-chip photonic neural networks. Sb2Se3 is a newly introduced ultralow-loss phase change material with a large refractive index contrast over the telecommunication transmission band. Compact, low-loss, rewritable, and nonvolatile on-chip phase-change metasurfaces can be created by using direct laser writing on a Sb2Se3 thin film. Here, by cascading multiple layers of on-chip phase-change metasurfaces, an ultra-compact on-chip programmable diffractive deep neural network is demonstrated at the wavelength of 1.55um and benchmarked on two machine learning tasks of pattern recognition and MNIST (Modified National Institute of Standards and Technology) handwritten digits classification and accuracies comparable to the state of the art are achieved. The proposed on-chip programmable diffractive deep neural network is also advantageous in terms of power consumption because of the ultralow-loss of the Sb2Se3 and its nonvolatility which requires no constant power supply to maintain its programmed state.


---
# Accurate Unsupervised Photon Counting from Transition Edge Sensor Signals

## 来自过渡边缘传感器信号的精确无监督光子计数

Link: https://arxiv.org/abs/2411.05737

arXiv:2411.05737v1 Announce Type: new 
Abstract: We compare methods for signal classification applied to voltage traces from transition edge sensors (TES) which are photon-number resolving detectors fundamental for accessing quantum advantages in information processing, communication and metrology. We quantify the impact of numerical analysis on the distinction of such signals. Furthermore, we explore dimensionality reduction techniques to create interpretable and precise photon number embeddings. We demonstrate that the preservation of local data structures of some nonlinear methods is an accurate way to achieve unsupervised classification of TES traces. We do so by considering a confidence metric that quantifies the overlap of the photon number clusters inside a latent space. Furthermore, we demonstrate that for our dataset previous methods such as the signal's area and principal component analysis can resolve up to 16 photons with confidence above $90\%$ while nonlinear techniques can resolve up to 21 with the same confidence threshold. Also, we showcase implementations of neural networks to leverage information within local structures, aiming to increase confidence in assigning photon numbers. Finally, we demonstrate the advantage of some nonlinear methods to detect and remove outlier signals.


---
# Multi-Dimensional Reconfigurable, Physically Composable Hybrid Diffractive Optical Neural Network

## 多维可重构，物理可组合的混合衍射光学神经网络

Link: https://arxiv.org/abs/2411.05748

arXiv:2411.05748v1 Announce Type: new 
Abstract: Diffractive optical neural networks (DONNs), leveraging free-space light wave propagation for ultra-parallel, high-efficiency computing, have emerged as promising artificial intelligence (AI) accelerators. However, their inherent lack of reconfigurability due to fixed optical structures post-fabrication hinders practical deployment in the face of dynamic AI workloads and evolving applications. To overcome this challenge, we introduce, for the first time, a multi-dimensional reconfigurable hybrid diffractive ONN system (MDR-HDONN), a physically composable architecture that unlocks a new degree of freedom and unprecedented versatility in DONNs. By leveraging full-system learnability, MDR-HDONN repurposes fixed fabricated optical hardware, achieving exponentially expanded functionality and superior task adaptability through the differentiable learning of system variables. Furthermore, MDR-HDONN adopts a hybrid optical/photonic design, combining the reconfigurability of integrated photonics with the ultra-parallelism of free-space diffractive systems. Extensive evaluations demonstrate that MDR-HDONN has digital-comparable accuracy on various task adaptations with 74x faster speed and 194x lower energy. Compared to prior DONNs, MDR-HDONN shows exponentially larger functional space with 5x faster training speed, paving the way for a new paradigm of versatile, composable, hybrid optical/photonic AI computing. We will open-source our codes.


---
# Adaptive Whole-Body PET Image Denoising Using 3D Diffusion Models with ControlNet

## 基于ControlNet的三维扩散模型自适应全身PET图像去噪

Link: https://arxiv.org/abs/2411.05302

arXiv:2411.05302v1 Announce Type: cross 
Abstract: Positron Emission Tomography (PET) is a vital imaging modality widely used in clinical diagnosis and preclinical research but faces limitations in image resolution and signal-to-noise ratio due to inherent physical degradation factors. Current deep learning-based denoising methods face challenges in adapting to the variability of clinical settings, influenced by factors such as scanner types, tracer choices, dose levels, and acquisition times. In this work, we proposed a novel 3D ControlNet-based denoising method for whole-body PET imaging. We first pre-trained a 3D Denoising Diffusion Probabilistic Model (DDPM) using a large dataset of high-quality normal-dose PET images. Following this, we fine-tuned the model on a smaller set of paired low- and normal-dose PET images, integrating low-dose inputs through a 3D ControlNet architecture, thereby making the model adaptable to denoising tasks in diverse clinical settings. Experimental results based on clinical PET datasets show that the proposed framework outperformed other state-of-the-art PET image denoising methods both in visual quality and quantitative metrics. This plug-and-play approach allows large diffusion models to be fine-tuned and adapted to PET images from diverse acquisition protocols.


---
# WeatherGFM: Learning A Weather Generalist Foundation Model via In-context Learning

## WeatherGFM: 通过上下文学习学习天气多面手基础模型

Link: https://arxiv.org/abs/2411.05420

arXiv:2411.05420v1 Announce Type: cross 
Abstract: The Earth's weather system encompasses intricate weather data modalities and diverse weather understanding tasks, which hold significant value to human life. Existing data-driven models focus on single weather understanding tasks (e.g., weather forecasting). Although these models have achieved promising results, they fail to tackle various complex tasks within a single and unified model. Moreover, the paradigm that relies on limited real observations for a single scenario hinders the model's performance upper bound. In response to these limitations, we draw inspiration from the in-context learning paradigm employed in state-of-the-art visual foundation models and large language models. In this paper, we introduce the first generalist weather foundation model (WeatherGFM), designed to address a wide spectrum of weather understanding tasks in a unified manner. More specifically, we initially unify the representation and definition of the diverse weather understanding tasks. Subsequently, we devised weather prompt formats to manage different weather data modalities, namely single, multiple, and temporal modalities. Finally, we adopt a visual prompting question-answering paradigm for the training of unified weather understanding tasks. Extensive experiments indicate that our WeatherGFM can effectively handle up to ten weather understanding tasks, including weather forecasting, super-resolution, weather image translation, and post-processing. Our method also showcases generalization ability on unseen tasks.


---
# Towards Active Flow Control Strategies Through Deep Reinforcement Learning

## 通过深度强化学习实现主动流量控制策略

Link: https://arxiv.org/abs/2411.05536

arXiv:2411.05536v1 Announce Type: cross 
Abstract: This paper presents a deep reinforcement learning (DRL) framework for active flow control (AFC) to reduce drag in aerodynamic bodies. Tested on a 3D cylinder at Re = 100, the DRL approach achieved a 9.32% drag reduction and a 78.4% decrease in lift oscillations by learning advanced actuation strategies. The methodology integrates a CFD solver with a DRL model using an in-memory database for efficient communication between


---
# Smart navigation through a rotating barrier: Deep reinforcement learning with application to size-based separation of active microagents

## 通过旋转屏障的智能导航: 深度强化学习应用于基于尺寸的活性微试剂分离

Link: https://arxiv.org/abs/2411.05587

arXiv:2411.05587v1 Announce Type: cross 
Abstract: We employ deep reinforcement learning methods to investigate shortest-time navigation strategies for smart active Brownian particles (agents) that self-propel through a rotating, localized potential barrier in an otherwise static and viscous fluid background. The particle motion is prescribed to begin from a specified start point and terminate at a specified destination point. The potential barrier is modeled as a repulsive Gaussian potential with a finite range that rotates with given angular velocities around a fixed center within the plane of motion. We use an advantage actor-critic approach to train the agents and demonstrate that, by leveraging this approach, the rotating potential can be utilized for size-based sorting and separation of the agents. In other words, agents of different (hydrodynamic) radii reach the end-point at sufficiently well-separated times, enabling their separation. The efficiency of particle separation in this context is discussed using specific criteria. We also study the effect of rotational Brownian noise on the quality of the proposed size-based sorting mechanism. Additionally, we demonstrate how the use of noise-induced training can enhance this mechanism in a noisy background within the range of parameters explored in our work. Reinforcement learning in the context of active particles thus offers promising avenues to unravel optimal navigation strategies within complex environments, with potential applications that can be utilized in microfluidic settings.


---
# SK-PINN: Accelerated physics-informed deep learning by smoothing kernel gradients

## Sk-pinn: 通过平滑核梯度加速物理通知深度学习

Link: https://arxiv.org/abs/2411.02411

arXiv:2411.02411v2 Announce Type: replace 
Abstract: The automatic differentiation (AD) in the vanilla physics-informed neural networks (PINNs) is the computational bottleneck for the high-efficiency analysis. The concept of derivative discretization in smoothed particle hydrodynamics (SPH) can provide an accelerated training method for PINNs. In this paper, smoothing kernel physics-informed neural networks (SK-PINNs) are established, which solve differential equations using smoothing kernel discretization. It is a robust framework capable of solving problems in the computational mechanics of complex domains. When the number of collocation points gradually increases, the training speed of SK-PINNs significantly surpasses that of vanilla PINNs. In cases involving large collocation point sets or higher-order problems, SK-PINN training can be up to tens of times faster than vanilla PINN. Additionally, analysis using neural tangent kernel (NTK) theory shows that the convergence rates of SK-PINNs are consistent with those of vanilla PINNs. The superior performance of SK-PINNs is demonstrated through various examples, including regular and complex domains, as well as forward and inverse problems in fluid dynamics and solid mechanics.


---
# Lagrangian Drifter Path Identification and Prediction: SINDy vs Neural ODE

## 拉格朗日漂流路径识别和预测: 辛迪vs神经ODE

Link: https://arxiv.org/abs/2411.04350

arXiv:2411.04350v2 Announce Type: replace 
Abstract: In this study, we investigate the performance of the sparse identification of nonlinear dynamics (SINDy) algorithm and the neural ordinary differential equations (ODEs) in identification of the underlying mechanisms of open ocean Lagrangian drifter hydrodynamics with possible applications in coastal and port hydrodynamic processes. With this motivation we employ two different Lagrangian drifter datasets acquired by National Oceanic and Atmospheric Administration (NOAA)'s surface buoys with proper World Meteorological Organization (WMO) numbers. In the SINDy approach, the primary goal is to identify the drifter paths of buoys using ordinary differential equation sets with a minimal number of sparse coefficients. In the neural ODE approach, the goal is to identify the derivative of the hidden state of a neural network (NN). Using the acquired data, we examine the applicability of the SINDy and the neural ODE algorithms in identification of the drifter trajectories comparatively. We propose that while both of the algorithms may give acceptable results for open ocean, the SINDy-based algorithmic approach can predict the Lagrangian drifter paths more accurately and consistently at least for the datasets investigated and parameters selected. A discussion of our findings with potential applications in search and rescue missions in the open ocean, their limitations and applicability are also presented.


---
# Discretize first, filter next: learning divergence-consistent closure models for large-eddy simulation

## 先离散化，后过滤: 学习散度一致的大涡模拟闭合模型

Link: https://arxiv.org/abs/2403.18088

arXiv:2403.18088v2 Announce Type: replace-cross 
Abstract: We propose a new neural network based large eddy simulation framework for the incompressible Navier-Stokes equations based on the paradigm "discretize first, filter and close next". This leads to full model-data consistency and allows for employing neural closure models in the same environment as where they have been trained. Since the LES discretization error is included in the learning process, the closure models can learn to account for the discretization. Furthermore, we employ a divergence-consistent discrete filter defined through face-averaging and provide novel theoretical and numerical filter analysis. This filter preserves the discrete divergence-free constraint by construction, unlike general discrete filters such as volume-averaging filters. We show that using a divergence-consistent LES formulation coupled with a convolutional neural closure model produces stable and accurate results for both a-priori and a-posteriori training, while a general (divergence-inconsistent) LES model requires a-posteriori training or other stability-enforcing measures.


---
# Lattice physics approaches for neural networks

## 神经网络的晶格物理方法

Link: https://arxiv.org/abs/2405.12022

arXiv:2405.12022v4 Announce Type: replace-cross 
Abstract: Modern neuroscience has evolved into a frontier field that draws on numerous disciplines, resulting in the flourishing of novel conceptual frames primarily inspired by physics and complex systems science. Contributing in this direction, we recently introduced a mathematical framework to describe the spatiotemporal interactions of systems of neurons using lattice field theory, the reference paradigm for theoretical particle physics. In this note, we provide a concise summary of the basics of the theory, aiming to be intuitive to the interdisciplinary neuroscience community. We contextualize our methods, illustrating how to readily connect the parameters of our formulation to experimental variables using well-known renormalization procedures. This synopsis yields the key concepts needed to describe neural networks using lattice physics. Such classes of methods are attention-worthy in an era of blistering improvements in numerical computations, as they can facilitate relating the observation of neural activity to generative models underpinned by physical principles.


---
# Taming Uncertainty in a Complex World: The Rise of Uncertainty Quantification -- A Tutorial for Beginners

## 驯服复杂世界中的不确定性: 不确定性量化的兴起 -- 初学者教程

Link: https://arxiv.org/abs/2408.01823

arXiv:2408.01823v2 Announce Type: replace-cross 
Abstract: This paper provides a tutorial about uncertainty quantification (UQ) for those who have no background but are interested in learning more in this area. It exploits many very simple examples, which are understandable to undergraduates, to present the ideas of UQ. Topics include characterizing uncertainties using information theory, UQ in linear and nonlinear dynamical systems, UQ via data assimilation, the role of uncertainty in diagnostics, and UQ in advancing efficient modeling. The surprisingly simple examples in each topic explain why and how UQ is essential. Both MATLAB and Python codes are made available for these simple examples.


---
# Deep Learning the Forecast of Galactic Cosmic-Rays Spectra

## 深入学习银河宇宙射线光谱的预测

Link: https://arxiv.org/abs/2410.21046

arXiv:2410.21046v2 Announce Type: replace-cross 
Abstract: We introduce a novel deep learning framework based on Long Short-Term Memory (LSTM) networks to predict galactic cosmic-ray spectra on a one-day-ahead basis by leveraging historical solar activity data, overcoming limitations inherent in traditional transport models. By flexibly incorporating multiple solar parameters such as the heliospheric magnetic field, solar wind speed, and sunspot numbers, our model achieves accurate short-term and long-term predictions of cosmic-ray flux. The addition of historical cosmic-ray flux data significantly enhances prediction accuracy, allowing the model to capture complex dependencies between past and future flux variations. Additionally, the model reliably predicts full cosmic-ray spectra for different particle species, enhancing its utility for comprehensive space weather forecasting. Our approach offers a scalable, data-driven alternative to traditional physics-based methods, ensuring robust daily and long-term forecasts. This work opens avenues for advanced models that can integrate broader observational data, with significant implications for space weather monitoring and mission planning.


---
# ChIMES Carbon 2.0: A Transferable Machine-Learned Interatomic Model Harnessing Multifidelity Training Data

## ChIMES碳2.0: 利用多保真度训练数据的可转移机器学习的原子间模型

Link: https://dx.doi.org/10.26434/chemrxiv-2024-s1fs5-v3?rft_dat=source%3Ddrss

We present a new parameterization of the ChIMES physics informed machine- learned interatomic model for simulating carbon under conditions ranging from 300 K and 0 GPa to 10,000 K and 100 GPa, along with a new multi-fidelity active learning strategy. The resulting model shows significant improvement in accuracy and temperature/pressure transferability relative to the original ChIMES carbon model developed in 2017, and can serve as a foundation for future transfer-learned ChIMES parameter sets. Model applications to carbon melting point prediction, shockwave-driven con- version of graphite to diamond, and thermal conversion of nanodiamond to graphitic nanoonion are provided. Ultimately, we find our new model to be robust, accurate, and well-suited for modeling evolution in carbon systems under extreme conditions.


---
# Data Efficiency of Classification Strategies for Chemical and Materials Design

## 化学和材料设计分类策略的数据效率

Link: https://dx.doi.org/10.26434/chemrxiv-2024-1sspf-v3?rft_dat=source%3Ddrss

Active learning and design-build-test-learn strategies are increasingly employed to accelerate materials discovery and characterization. Many data-driven materials design campaigns target solutions within constrained domains such as synthesizability, stability, solubility, recyclability, and toxicity. Lack of knowledge about these constraints can hinder design efficiency by producing samples that fail to meet required thresholds. Acquiring this knowledge during the design campaign is inefficient, and effective classification of common materials constraints transcends specific design objectives. However, there is no consensus on the most data-efficient algorithm for classifying whether a material satisfies a constraint. To address this gap, we comprehensively compare the performance of 100 strategies designed to classify chemical and materials behavior. Performance is assessed across 31 classification tasks sourced from the literature in chemical and materials science. From these results, we recommend best practices for building data-efficient classifiers, showing the neural network- and random forest-based active learning algorithms are most efficient across tasks. We also show that classification task complexity can be quantified based on task metafeatures, most notably the noise-to-signal ratio. Overall, this work provides a comprehensive survey of data-efficient classification strategies, identifies attributes of top-performing strategies, and suggests avenues for further study.


---
# Leveraging High-throughput Molecular Simulations and Machine Learning for Formulation Design

## 利用高通量分子模拟和机器学习进行配方设计

Link: https://dx.doi.org/10.26434/chemrxiv-2024-4lff6-v3?rft_dat=source%3Ddrss

Formulations, or mixtures of chemical ingredients, are ubiquitous in materials science, but optimizing their properties remains challenging due to the vast design space. Computational approaches offer a promising solution to traverse this space while minimizing trial-and-error experimentation. Using high-throughput classical molecular dynamics simulations, we generated a comprehensive dataset of over 30,000 solvent mixtures to evaluate three machine learning approaches that connect molecular structure and composition to property: formulation descriptor aggregation (FDA), formulation graph (FG), and Set2Set-based method (FDS2S). Our results demonstrate that our new FDS2S approach outperforms other approaches in predicting simulation-derived properties. Formulation-property relationships can reveal important substructures and identify promising formulations at least two to three times faster than random guessing. The models show robust transferability to experimental datasets, accurately predicting properties across energy, pharmaceutical, and petroleum applications. Our research demonstrates the utility of high-throughput simulations and machine learning tools to design formulations with promising properties.


---
# Machine Learning Approaches for Determining Molecular Packing of Organic Semiconductors: Toward Accurate Crystal Structure Prediction

## 确定有机半导体分子堆积的机器学习方法: 实现准确的晶体结构预测

Link: https://dx.doi.org/10.26434/chemrxiv-2024-pvk9d-v2?rft_dat=source%3Ddrss

Organic semiconductors (OSCs) with π-electron skeletons (π-cores) have garnered significant attention. The development of innovative molecules with high carrier mobility necessitates strategic molecular design.
One critical property affecting the carrier mobility of π-conjugated OSCs is the molecular arrangement, particularly the two-dimensional (2D) molecular packing of the π-cores, such as π-stacking, herringbone (HB) packing, and brickwork (BW) packing.
These molecular packing structures, which are similar 2D packings, have not been theoretically predicted, leading chemists to design new OSC molecules based on empirical knowledge. Therefore, computational science and informatics are crucial for the strategic design of OSC molecules with unprecedented properties and functions.
In this study, we introduce a machine learning method to determine with high accuracy whether an OSC forms the HB packing, a 2D molecular packing known to enhance carrier mobility. We also present a computational method to predict the crystal structure of an OSC from its chemical structure using molecular mechanics (MM) calculations and molecular dynamics (MD) simulations, coupled with our proposed machine learning model to classify the type of 2D molecular packing.


---
# Active learning FEP using 3D-QSAR for prioritizing bioisosteres in medicinal chemistry

## 使用3D-QSAR主动学习FEP在药物化学中优先考虑生物电子等排物

Link: https://dx.doi.org/10.26434/chemrxiv-2024-d9fwk?rft_dat=source%3Ddrss

Bioisostere replacement is a powerful and popular tool used to optimize the potency and selectivity of candidate molecules in drug discovery. Selecting the right bioisosteres to invest resources in for synthesis and subsequent optimization is key to an efficient drug discovery project. Here we demonstrate how 3D-quantitative structure activity relationship (3D-QSAR), and relative binding free energy calculations can be combined into an active learning workflow to prioritize molecules from a pool of hundreds of bioisosteres. We demonstrate on a human aldose reductase test case that the use of this workflow can rapidly locate the strongest-binding bioisosteric replacements with a relatively modest computational cost.


---
# Study on the Mechanical Properties Equivalence of High-Temperature Red Sandstone and Neural Network Prediction

## 高温红砂岩力学性能等效性研究及神经网络预测

Link: https://www.researchsquare.com/article/rs-5300674/latest

Background Post-disaster assessment is an important problem in engineering field, and cooling methods after high temperature are important factors to be considered.Purpose In order to explore the damage characteristics of red sandstone after heat impact, and realize the damage assessment and quantization.Methods Red sandstone specimens were heated respectively at temperature ranging from 200℃ to 700℃, and were cooled by air or water. In addition, a improved Nishihara model was used to construct a constitutive model of heat impact damage and validated using a neural network model.Results The test results indicate that: the peak strength of the red sandstone is bounded by 400℃, which is first increased and then decreases. And the strength of the water-cooled samples are less than that of the air-cooled samples. Both the improved Nishihara model and neural network model have high correlation coefficients and can achieve the damage assessment under different temperature and cooling rates.Conclusions There is a temperature threshold, so that the peak strength first increases and then decreases. The cooling rate will enhance the heat impact damage and aggravate the deterioration of the physical and mechanical properties. The improved Nishihara model and neural network model can achieve damage prediction.


---
# Establishing a Preoperative Predictive Model for Gallbladder Adenoma and Cholesterol Polyps Based on Machine Learning: A Multicentre Retrospective Study

## 基于机器学习建立胆囊腺瘤和胆固醇息肉术前预测模型的多中心回顾性研究

Link: https://www.researchsquare.com/article/rs-5298790/latest

Background With the rising diagnostic rate of gallbladder polypoid lesions (GPLs), differentiating benign cholesterol polyps from gallbladder adenomas with a higher preoperative malignancy risk is crucial. This study aimed to establish a preoperative prediction model capable of accurately distinguishing between gallbladder adenomas and cholesterol polyps using machine learning algorithms.Materials and Methods We retrospectively analysed the patients' clinical baseline data, serological indicators, and ultrasound imaging data. Using 12 machine learning algorithms, 110 combination predictive models were constructed. The models were evaluated using internal and external cohort validation, receiver operating characteristic curves, area under the curve (AUC) values, calibration curves, and clinical decision curves to determine the best predictive model.Results Among the 110 combination predictive models, the Support Vector Machine&amp;thinsp;+&amp;thinsp;Random Forest (SVM&amp;thinsp;+&amp;thinsp;RF) model demonstrated the highest AUC values of 0.972 and 0.922 in the training and internal validation sets, respectively, indicating an optimal predictive performance. The model-selected features included gallbladder wall thickness, polyp size, polyp echo, and pedicle. Evaluation through external cohort validation, calibration curves, and clinical decision curves further confirmed its excellent predictive ability for distinguishing gallbladder adenomas from cholesterol polyps. Additionally, this study identified age, adenosine deaminase level, and metabolic syndrome as potential predictive factors for gallbladder adenomas.Conclusion This study employed the latest machine learning combination algorithms and preoperative ultrasound imaging data to construct an SVM&amp;thinsp;+&amp;thinsp;RF predictive model, enabling effective preoperative differentiation of gallbladder adenomas and cholesterol polyps. These findings will assist clinicians in accurately assessing the risk of GPLs and providing personalised treatment strategies.


---
# Predicting the Molecular Subtypes of 2021 WHO Grade 4 Glioma by a Multiparametric MRI-Based Machine Learning Model

## 通过基于MRI的多参数机器学习模型预测WHO 4级胶质瘤2021年分子亚型

Link: https://www.researchsquare.com/article/rs-5288001/latest

Purpose: To develop and validate a machine learning (ML) model using multiparametric MRI for the preoperative differentiation of 2021 World Health Organization (WHO) grade 4 astrocytoma and glioblastoma (GBM) (Task 1), and to stratify grade 4 astrocytoma to distinguish isocitrate dehydrogenase-mutant (IDH-mut) from IDH-wild-type (IDH-wt) (Task 2). Additionally, to evaluate the model&rsquo;s prognostic value.
Materials and methods: We retrospectively analyzed 320 glioma patients from three hospitals. Cases were randomly divided into training and validation sets with a 7:3 ratio. Features were extracted from tumor and edema on contrast-enhanced T1-weighted imaging (CE-T1WI) and T2 fluid-attenuated inversion recovery (T2-FLAIR). Extreme gradient boosting (XGBoost) was utilized for constructing ML, clinical, and combined models. Model performance was evaluated with receiver operating characteristic (ROC) curves, decision curves, and calibration curves. Stability was evaluated using six additional classifiers. Kaplan-Meier (KM) survival analysis and the log-rank test assessed the model&rsquo;s prognostic value.
Results: In Task 1 (grade 4 vs GBM) and Task 2 (IDH-mut grade 4 vs IDH-wt grade 4), the combined model (AUC = 0.911 and 0.854, 0.902 and 0.909) and the optimal ML model (AUC = 0.902 and 0.855, 0.904 and 0.895) significantly outperformed the clinical model (AUC = 0.671 and 0.656, 0.619 and 0.605) in both the training and validation sets. Survival analysis showed the combined model performed similarly to molecular subtype in both tasks (P = 0.966 and P = 0.793).
Conclusion: The multiparametric MRI ML model effectively distinguished grade 4 astrocytoma from GBM and differentiated IDH-mut from IDH-wt grade 4 astrocytoma. Additionally, the model provides reliable survival stratification for glioma patients with various molecular subtypes.


---
# Leveraging Machine Learning models to predict contraceptive nonuse among women of reproductive age in Rwanda: A machine learning approach

## 利用机器学习模型预测卢旺达育龄妇女不使用避孕药具: 机器学习方法

Link: https://www.researchsquare.com/article/rs-5300030/latest

Background: Despite efforts and commitments put in place by the Rwandan Government and collaborating great health organizations, contraceptive prevalence rate (CPR) remains low in Rwanda (64% in 2019 for married women using any method and 58.% for only modern methods. CPR has however been increasing from 45% in 2010 and 48% in 2015. Consequently, unmet need for family planning dropped from 34% to 14% between 2010 and 2020. &amp;nbsp;This study aims to leverage Machine Learning to predict contraceptive nonuse among women of reproductive age in Rwanda.
Methods: A cross-sectional analysis of secondary data was conducted on 2020 Rwanda Demographic and Health Survey. We used six Machine Learning algorithms on the sample of 14,634 women of reproductive age, which were trained and evaluated using various metrics to know the best model. Moreover, multivariable binary logistic regression was used to determine key factors of contraceptive nonuse through Python software and to identify women at higher risk of not using contraceptives, providing valuable insights for targeted interventions and policy enhancements to improve access to reproductive health and family planning services for underserved populations in Rwanda.
Results: Findings revealed that woman age, residence region, education, wealth status, marital status, urban-rural residence, total children ever born, working status, partner's occupation, and the desire for more children are key determinants of not using contraceptives. Younger women, particularly those aged 15-24, urban residents, wealthier women, and those desiring more children are at a higher risk of not using contraceptives. Furthermore, Support Vector Machine model performed better than other five classifiers in predicting nonuse of contraceptives status with an accuracy of 75%, giving a ROC-AUC score of 83%, and making it the best model to predict contraceptive behavior in Rwanda.
Conclusion The results from this study suggest the use of Machine Learning to predict contraceptive outcomes accurately. Additionally, by tailoring focused interventions for identified women at higher risk of not using contraceptive could contribute to contraceptive use uptake in Rwanda.


---
# Detecting Sarcasm in User-Generated Content Integrating Transformers and Gated Graph Neural Networks

## 在集成了转换器和门控图神经网络的用户生成内容中检测讽刺

Link: https://www.researchsquare.com/article/rs-5270483/latest

The widespread use of the Internet and social media has posed significant challenges to automated sentiment analysis, particularly in relation to detecting sarcasm in user-generated content. Sarcasm often expresses negative emotions through seemingly positive or exaggerated language, making its detection a complex task in natural language processing. To address this issue, the present study proposes a novel sarcasm detection model that combines Bidirectional Encoder Representations from Transformers (BERT) with Gated Graph Neural Networks (GGNN), further enhanced by a self-attention mechanism to more effectively capture ironic cues. BERT is utilized to extract deep contextual information from the text, while GGNN is employed to learn global semantic structures by incorporating dependency and emotion graphs. Experiments were conducted on two benchmark sarcasm detection datasets, namely Headlines and Riloff. The experimental results demonstrate that the proposed BERT-GGNN model achieves an accuracy of 92.00% and an F1 score of 91.51% on the Headlines dataset, as well as an accuracy of 86.49% and an F1 score of 86.59% on the Riloff dataset, significantly outperforming the conventional BERT-GCN models. The results of ablation studies further corroborate the efficacy of integrating GGNN, particularly for handling complex ironic expressions frequently encountered in social media contexts.


---
# Malware Detection Method Based on Feature Fusion

## 基于特征融合的恶意软件检测方法

Link: https://www.researchsquare.com/article/rs-5346977/latest

In recent years, as cyberattacks continue to escalate, malware has become increasingly diverse and complex, posing significant security threats to enterprises, government agencies, and individual users. Malware developers often employ techniques such as feature obfuscation and behavior hiding, rendering traditional detection methods less effective. To address this challenge, this study proposes a malware detection method based on feature fusion and a multi-feature detection framework. The method extracts frequency features and semantic information from opcodes and readable characters, and byte transition probabilities from byte sequences, thereby constructing a comprehensive feature vector. A two-layer detection framework that combines deep learning with traditional machine learning is designed, effectively integrating different feature types and overcoming the limitations of single-feature approaches. Experimental results demonstrate that the proposed method significantly outperforms traditional algorithms in terms of detection accuracy and generalization capability, greatly enhancing the detection of complex malware families. Notably, it excels in handling packed code, obfuscation techniques, and imbalanced data, offering an efficient solution for malware detection.


---
# Slotting blasting model experiment and PCA-PNN evaluation model of influencing factors of slitting effect

## 开槽爆破模型试验及分切效果影响因素的pca-pnn评价模型

Link: https://www.researchsquare.com/article/rs-5272250/latest

Numerous parameters influence the slotting performance of slotted cartridge; however, the extent of influence of each parameter is not well understood. To facilitate rapid, efficient, and accurate predictions of the slotting performance, several evaluation indicators generally need to be considered. Nevertheless, these indicators frequently exhibit correlations, resulting in overlapping information. A statistical analysis of blasting experiments conducted on PMMA with six different slotted cartridge parameters yielded 12 indicators for assessing the slitting performance. Subsequently, a principal component analysis (PCA) method was introduced to reduce the dimensionality of the data associated with these indicators, and three new comprehensive indicators were extracted for a comprehensive assessment of the slotting performance. The PCA scores ranked the influence of the six slotted cartridge parameters on slotting performance as follows: decoupling coefficient, slotting width, slotting angle, slotting tube thickness, slotting tube material, and charge amount. This ranking serves as a guideline for selecting suitable slotted cartridge parameters. On the basis of the PCA, a probabilistic neural network (PNN) model was developed to assess slotting performance levels. The predictive results demonstrated that the PCA-PNN model performed well across eight different training and testing sample configurations, achieving correct prediction rates of 100%, 100%, 96.43%, 89.29%, 89.29%, 89.29%, 78.57%, and 78.57%, respectively. This corresponded to an average accuracy improvement of 11.61% compared to data that was not subjected to PCA dimensionality reduction. Moreover, the PCA-PNN model was validated as a robust and feasible approach for evaluating the slotting performance of slotted cartridge.


---
# Phenotyping to predict 12-month health outcomes of older general medicine patients

## 预测老年普通医学患者12个月健康结果的表型

Link: https://www.researchsquare.com/article/rs-5314625/latest

Background: A variety of unsupervised learning algorithms have been used to phenotype older patients, enabling directed care and personalised treatment plans. However, the ability of the clusters to accurately discriminate for the risk of older patients, may vary depending on the methods employed.&amp;nbsp;
Aims: To compare seven clustering algorithms in their ability to develop patient phenotypes that accurately predict health outcomes.&amp;nbsp;
Methods: Data was collected for N=737 older medical inpatients for five different types of medical data (ICD-10 codes, ATC drug codes, laboratory, clinic and frailty data). We trialled five unsupervised learning algorithms (K-means, K-modes, hierarchical clustering, latent class analysis (LCA), and DBSCAN) and two graph-based approaches to create separate clusters for each method and datatype. These were used as input for a random forest classifier to predict eleven health outcomes: mortality at one, three, six and 12 months, in-hospital falls and delirium, length-of-stay, outpatient visits, and readmissions at one, three and six months.&amp;nbsp;
Results: The overall area-under-the-curve (AUC) across the eleven outcomes for the seven methods were (from highest to lowest) 0.758 (hierarchical), 0.739 (K-means), 0.722 (KG-Louvain), 0.718 (KNN-Louvain), 0.698 (LCA), 0.694 (DBSCAN) and 0.656 (K-modes). Overall, frailty data was most important data type for predicting mortality, ICD-10 disease codes for predicting readmissions, and laboratory data the most important for predicting falls.&amp;nbsp;
Conclusions: Clusters created using hierarchical, K-means and Louvain community detection algorithms identified well-separated patient phenotypes that were consistently associated with age-related adverse health outcomes. Frailty data was the most valuable data type for predicting most health outcomes.


---
# Amide proton transfer-weighted imaging and apparent diffusion coefficient imaging with histogram analysis to predict tumor budding in rectal cancer: a preliminary study

## 酰胺质子转移加权成像和表观扩散系数成像直方图分析预测直肠癌肿瘤出芽的初步研究

Link: https://www.researchsquare.com/article/rs-5310482/latest

Objectives To investigate the value of histogram features based on amide proton transfer-weighted(APTw) imaging and apparent diffusion coefficient(ADC) images combined with clinical data and conventional magnetic resonance imaging(MRI) features in the preoperative prediction of tumor budding(TB) grade in rectal cancer (RC).
Methods We included a total of 71 TB patients who underwent surgical resection and pathological confirmation of RC between June 2023 and June 2024. The patients were classified into the low-intermediate grade group(n=44) and the high grade group (n=27) based on pathological findings. Histogram features are extracted by delineating a four-layer contour of the largest level of the tumor on APTw and ADC images. Following feature screening, the optimal histogram model is selected using machine learning, and the histogram feature score (Histogram-score) is calculated. Measurement of APTw signal intensity (SI) and ADC values was performed by subjectively delineating the region of interest (ROI) in the largest section of the tumor. Univariate logistic regression analysis was implemented to identify independent risk factors, including both clinical Characteristics, conventional MR features and Histogram-score. Subsequently, models for conventional MRI and combined model were constructed using multivariable binary logistic regression analysis for the purpose of predicting TB grade. Then, we plotted combined model into a nomograh for personalized prediction. Evaluation of model performance and clinical practicality was conducted using area under curve (AUC), calibration curve, and decision curve.
Results APTw SI was significantly higher in the high group compared with the low-intermediate grade group (P &amp;lt; 0.05). The value of ADC was significantly lower in the high group compared with the low-intermediate group (P &amp;lt; 0.05). The AUC of the conventional MRI model constructed on the basis of MRI-T stage, APT SI and ADC value was 0.891 (95% CI: 0.795, 0.953). A histogram model was composed of 5 histogram features filtered from the optimal SVM machine learning algorithm with AUC of 0.939 (95% CI: 0.856, 0.982). The AUC of the combined model constructed using ADC value and Histogram-score was 0.960 (95% CI: 0.885, 0.992). The combined model had higher diagnostic efficacy than the histogram model (P = 0.14) and the conventional MRI model (P = 0.04).&amp;nbsp;
Conclusions The combined model constructed on the basis of histogram features of APTw and ADC images and conventional MRI features can effectively predict the TB grade of RC patients preoperatively, providing a preoperative noninvasive assessment method for the selection of treatment options and prognostic evaluation of RC patients.


---
# A new method for estimating reference crop evapotranspiration based on solar-induced chlorophyll fluorescence: arid and semi-arid regions of northern China as an example

## 基于太阳诱导叶绿素荧光的参考作物蒸散量估算新方法 -- 以中国北方干旱半干旱地区为例

Link: https://www.researchsquare.com/article/rs-5305042/latest

Accurately estimating reference crop evapotranspiration (ET0) is crucial for evaluating crop water needs, guiding irrigation practices, and effectively managing water resources at the regional level. However, conventional ET0 estimation models heavily depend on numerous meteorological parameters, which can pose limitations when such data is scarce or incomplete. The integration of Solar-Induced Chlorophyll Fluorescence (SIF) with the ET0 model offers a novel approach for ET0 estimation, but this model encounters significant uncertainties in capturing the seasonal variations of ET0. Consequently, there remain challenges in accurately monitoring the spatial and temporal patterns of large-scale ET0 changes using the SIF-based methodology. In order to address this limitation, we incorporate the basal crop coefficient (Kcb) into the original SIF_ET0 model to provide constraints, resulting in the development of the improved SIF_ET0 model (RET0_SIF). The research findings indicate that: (1) In comparison to the ET0_SIF model, the RET0_SIF model, combined with three machine learning algorithms, exhibits superior performance. It can more accurately capture the seasonal variations of ET0 across 22 monitoring stations;(2) Comparing with the five traditional empirical models, RET0_SIFo exhibits superior estimation accuracy. Its multi-year average deviation from ET0PM across 22 stations is merely 0.59 mm/8days. In contrast, the multi-year average deviations of the five traditional empirical models from ET0PM are 2.29 mm/8days, 16.87 mm/8days, 8.42 mm/8days, -11.82 mm/8days, and &amp;minus;&amp;thinsp;11.44 mm/8days, respectively;(3) From 2000 to 2019, RET0_SIFd exhibits a spatial pattern of gradual decrease from west to east in the study area and shows an increasing trend over the time series. The linear trend of increase is 2.56. This study seeks to provide a scientific reference for accurately estimating ET0 in arid and semi-arid regions, as well as for the rational allocation of water resources.


---
# Construction and Analysis of China's Carbon Emission Model Based on Machine Learning

## 基于机器学习的中国碳排放模型构建与分析

Link: https://www.researchsquare.com/article/rs-5276635/latest

In response to the formidable challenge of China's substantial carbon emissions, this study introduces a comprehensive research paradigm that integrates "modeling + SHAP analysis + scenario forecasting" from the perspective of machine learning. Utilizing carbon emission data spanning from 1997 to 2021, we have constructed a machine learning model and conducted an in-depth analysis of the key factors influencing carbon emissions. Based on current national policies, predictions for carbon emissions have been made. Firstly, factors affecting carbon emissions were selected in accordance with the principle of data availability. Secondly, by calculating the Spearman correlation coefficients, nine explanatory variables including the share of coal in total energy consumption and urbanization rate, had correlation coefficients of 0.6 or higher and significantly correlated with China's carbon emissions. Subsequently, the contribution of each explanatory variable in the optimal model was quantified using the SHAP method, revealing that energy intensity and urbanization rate are the key factors affecting China's carbon emissions, exerting negative and positive impacts, respectively. Finally, through policy scenario simulation, the trend of China's carbon emissions from 2022 to 2030 was predicted. The study indicates that China's carbon emissions plateau from 2022 to 2028 and peak in 2028, with an estimated carbon emission volume of approximately 9,720 million tons in 2030.


---
# Mission-capable satellite prediction method for ultra large remote-sensing satellite constellation based on BP neural network

## 基于BP神经网络的超大型遥感卫星星座任务卫星预报方法

Link: https://www.researchsquare.com/article/rs-5351953/latest

The number of satellites in the ultra large remote-sensing satellite constellation will be more than 10,000, and the amount of data under control will be huge. The ultra large remote-sensing satellite constellation is often used to deal with sudden, complex and time-sensitive tasks with time-sensitive missions. To accommodate time-sensitive mission requirements, a fast and relatively accurate method of predicting mission satellites is needed. The traditional method performs predicting mission satellites by traversing the satellites of constellation and forecasting satellite orbits. This method is accurate but time-consuming and does not guarantee the timeliness of decisions on the ultra large remote-sensing satellite constellation. In this paper, we propose a new method for predicting mission satellites that does not rely on forecasting satellite orbits. Direct fitting of relationships from satellite orbital parameters, mission initiation time and target position to the performance of an observation mission using a Back-Propagation (BP) neural network. Since there are only 1192 remote-sensing satellites in orbit, this paper generates a set of LEO satellite constellations with 28,800 satellites based on the characteristics of the existing LEO remote-sensing satellites, which are used to generate network training and testing samples. Considering that BP neural networks have residual errors even after optimising all parameters, a fault-tolerant mechanism and a one-vote veto mechanism is used to guarantee the credibility of mission-capable satellite prediction. The results show that for the prediction of mission-capable satellite and the prediction of optimal mission-metric satellite&amp;nbsp;(optimal response time and optimal observation duration), the actual executable&amp;nbsp;probability of the mission-capable satellite as well as the prediction error of the&amp;nbsp;mission-metrics satisfy the requirements to some extent. In addition, since no&amp;nbsp;satellite orbits forecasting is involved, the BP network has a high computational&amp;nbsp;efficiency in the mission-capable satellite prediction, showing good application&amp;nbsp;prospects.


---
# A Guide for Active Learning in Synergistic Drug Discovery

## 协同药物发现中的主动学习指南

Link: https://www.researchsquare.com/article/rs-5088190/latest

Synergistic drug combination screening is a promising strategy in drug discovery, but it involves navigating a costly and complex search space. While AI, particularly deep learning, has advanced synergy predictions, its effectiveness is limited by the low occurrence of synergistic drug pairs. Active learning, which integrates experimental testing into the learning process, has been proposed to address this challenge. In this work, we explore the key components of active learning to provide recommendations for its implementation. We find that molecular encoding has a limited impact on performance, while the cellular environment features significantly enhance predictions. Additionally, active learning can discover 60% of synergistic drug pairs with only exploring 10% of combinatorial space. The synergy yield ratio is observed to be even higher with smaller batch sizes, where dynamic tuning of the exploration-exploitation strategy can further enhance performance.


---
# Barriers to AI Course Assistant Adoption: Understanding Student Non-Utilization at LAPU

## AI课程助理采用的障碍: 了解LAPU的学生未使用情况

Link: https://www.researchsquare.com/article/rs-5378875/latest

This study explores the factors contributing to the non-utilization of the AI course assistant Spark among some students at Los Angeles Pacific University (LAPU). Despite the demonstrated benefits of AI in enhancing academic performance, motivation, and learning efficiency, a proportion of students choose not to engage with this technology. Using a mixed-methods exploratory approach, this research identifies key barriers to adoption, including perceptions of unnecessity, lack of interest, and unfamiliarity with AI tools. The study further examines external factors such as technical challenges and a preference for traditional learning methods. By combining sentiment analysis with thematic analysis of student survey responses, this research provides a comprehensive understanding of the underlying reasons for non-use. The findings suggest that targeted strategies, such as improving communication about the benefits of AI tools, offering training to increase familiarity, and integrating AI more seamlessly into coursework could enhance the adoption and effectiveness of AI course assistants. This study contributes to the growing body of literature on AI in education and offers practical recommendations for educators and institutions aiming to maximize the impact of AI technologies on student learning outcomes.

