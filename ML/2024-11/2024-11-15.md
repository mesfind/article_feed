# Machine learning potential for the Cu-W system

## Cu-w系统的机器学习潜力

Link: http://link.aps.org/doi/10.1103/PhysRevMaterials.8.113804

Author(s): Manura Liyanage, Vladyslav Turlo, and W. A. Curtin<br /><p>Combining the excellent thermal and electrical properties of Cu with the high abrasion resistance and thermal stability of W, Cu-W nanoparticle-reinforced metal matrix composites and nano-multilayers are finding applications as brazing fillers and shielding material for plasma and radiation. Due to …</p><br />[Phys. Rev. Materials 8, 113804] Published Fri Nov 15, 2024


---
# Accelerating graph-based tracking tasks with symbolic regression

## 使用符号回归加速基于图的跟踪任务

Link: http://iopscience.iop.org/article/10.1088/2632-2153/ad8f12

The reconstruction of particle tracks from hits in tracking detectors is a computationally intensive task due to the large combinatorics of detector signals. Recent efforts have proven that ML techniques can be successfully applied to the tracking problem, extending and improving the conventional methods based on feature engineering. However, complex models can be challenging to implement on heterogeneous trigger systems, integrating architectures such as field programmable gate arrays (FPGAs). Deploying the network on an FPGA is feasible but challenging and limited by its resources. An efficient alternative can employ symbolic regression (SR). We propose a novel approach that uses SR to replace a graph-based neural network. Substituting each network block with a symbolic function preserves the graph structure of the data and enables message passing. The technique is perfectly suitable for heterogeneous hardware, as it can be implemented more easily on FPGAs and grants faster execution times on CPU with respect to conventional methods. While the tracking problem is the target for this work, it also provides a proof-of-principle for the method that can be applied to many use cases.


---
# Universal Ensemble‐Embedding Graph Neural Network for Direct Prediction of Optical Spectra from Crystal Structures

## 用于从晶体结构直接预测光谱的通用嵌入图神经网络

Link: https://onlinelibrary.wiley.com/doi/10.1002/adma.202409175?af=R

Advanced Materials, Volume 36, Issue 46, November 14, 2024.


---
# Universal Ensemble‐Embedding Graph Neural Network for Direct Prediction of Optical Spectra from Crystal Structures (Adv. Mater. 46/2024)

## 用于从晶体结构直接预测光谱的通用嵌入图神经网络 (Adv. Mater. 46/2024)

Link: https://onlinelibrary.wiley.com/doi/10.1002/adma.202470369?af=R

Advanced Materials, Volume 36, Issue 46, November 14, 2024.


---
# Tailoring interactions between active nematic defects with reinforcement learning

## 通过强化学习定制活动向列缺陷之间的相互作用

Link: https://arxiv.org/abs/2411.09588

arXiv:2411.09588v1 Announce Type: new 
Abstract: Active nematics, formed from a liquid crystalline suspension of active force dipoles, are a paradigmatic active matter system whose study provides insights into how chemical driving produces the cellular mechanical forces essential for life. Recent advances in optogenetic control over molecular motors and cell-signaling pathways now allow experimenters to mimic the spatiotemporal regulation of activity necessary to drive biologically relevant active nematic flows in vivo. However, engineering effective activity protocols remains challenging due to the system's complex dynamics. Here, we explore a model-free approach for controlling active nematic fields using reinforcement learning. Specifically, we demonstrate how local activity fields can induce interactions between pairs of nematic defects, enabling them to follow designer dynamical laws such as those of overdamped springs with varying stiffnesses. Reinforcement learning bypasses the need for accurate parameterization and model representation of the nematic system, and could thus transfer straightforwardly to experimental implementation. Moreover, the sufficiency of our low-dimensional system observables and actions suggests that coarse projections of the active nematic field can be used for precise feedback control, making the biological implementation of such feedback loops plausible.


---
# A Message Passing Neural Network Surrogate Model for Bond-Associated Peridynamic Material Correspondence Formulation

## 用于键相关的近场动力材料对应公式的消息传递神经网络代理模型

Link: https://arxiv.org/abs/2411.08911

arXiv:2411.08911v1 Announce Type: cross 
Abstract: Peridynamics is a non-local continuum mechanics theory that offers unique advantages for modeling problems involving discontinuities and complex deformations. Within the peridynamic framework, various formulations exist, among which the material correspondence formulation stands out for its ability to directly incorporate traditional continuum material models, making it highly applicable to a range of engineering challenges. A notable advancement in this area is the bond-associated correspondence model, which not only resolves issues of material instability but also achieves high computational accuracy. However, the bond-associated model typically requires higher computational costs than FEA, which can limit its practical application. To address this computational challenge, we propose a novel surrogate model based on a message-passing neural network (MPNN) specifically designed for the bond-associated peridynamic material correspondence formulation. Leveraging the similarities between graph structure and the neighborhood connectivity inherent to peridynamics, we construct an MPNN that can transfers domain knowledge from peridynamics into a computational graph and shorten the computation time via GPU acceleration. Unlike conventional graph neural networks that focus on node features, our model emphasizes edge-based features, capturing the essential material point interactions in the formulation. A key advantage of this neural network approach is its flexibility: it does not require fixed neighborhood connectivity, making it adaptable across diverse configurations and scalable for complex systems. Furthermore, the model inherently possesses translational and rotational invariance, enabling it to maintain physical objectivity: a critical requirement for accurate mechanical modeling.


---
# Image to Properties: Extracting Atomic Structure Information from Band Dispersion Images of Semiconductor Heterostructures Using Machine Learning

## 图像到属性: 使用机器学习从半导体异质结构的能带色散图像中提取原子结构信息

Link: https://arxiv.org/abs/2302.00261

arXiv:2302.00261v3 Announce Type: replace 
Abstract: The atomic environments of semiconductor heterostructures can be highly varied as various structural imperfections, lattice mismatch and non-uniform strain environments are generally present. The computational costs of first-principles modeling techniques make it challenging to fully explore how atomic environments tune the electronic bands of heterostructures. We present a machine learning (ML)-assisted first-principles modeling framework that establishes a direct relationship between the atomic environments and the electronic bands of semiconductor heterostructures. The framework combines a forward and a reverse model: The forward model predicts how the atomic environments tune electronic bands; The reverse learning model extracts information about the atomic environments that is associated with an input band structure image, such as the ones obtained with angle-resolved photoemission spectroscopy. We demonstrate the framework using silicon/germanium-based superlattices and heterostructures. Our framework offers a physics-informed approach to designing heterostructures for new phenomena and device possibilities for diverse technologies, going beyond trial-and-error approaches.


---
# Human-machine collaboration: ordering mechanism of rank-2 spin liquid on breathing pyrochlore lattice

## 人机协作: 呼吸烧绿石晶格上rank-2自旋液体的排序机制

Link: https://arxiv.org/abs/2402.10658

arXiv:2402.10658v2 Announce Type: replace 
Abstract: Machine learning algorithms thrive on large data sets of good quality. Here we show that they can also excel in a typical research setting with little data of limited quality, through an interplay of insights coming from machine, and human researchers. The question we address is the unsolved problem of ordering out of a spin-liquid phase described by an emergent rank-2 $U(1)$ gauge theory, as described by [H. Yan it et al., Phys. Rev. Lett. 124, 127203 (2020)]. Published Monte Carlo simulations for this problem are consistent with a strong first-order phase transition, out of the R2-U1 spin liquid, but were too noisy for the form of low-temperature order to be identified. Using a highly-interpretable machine learning approach based on a support vector machine with a tensorial kernel (TKSVM), we re-analyze this Monte Carlo data, gaining new information about the form of order that could in turn be interpreted by traditionally-trained physicists. We find that the low-temperature ordered phase is a form of hybrid nematic order with emergent $Z_2$ symmetry, which allows for a sub-extensive set of domain walls at zero energy. This complex form of order arises due to a subtle thermal order-by-disorder mechanism, that can be understood from the fluctuations of the tensor electric field of the parent rank-2 gauge theory. These results were obtained by a back-and-forth process which closely resembles a collaboration between human researchers and machines. We argue that this "collaborative" approach may provide a blueprint for solving other problems that have not yielded to human insights alone.


---
# Magnetocaloric effect for a $Q$-clock type system

## $ Q $-clock型系统的磁热效应

Link: https://arxiv.org/abs/2405.14000

arXiv:2405.14000v2 Announce Type: replace 
Abstract: In this work, we study the magnetocaloric effect (MCE) in a working substance corresponding to a square lattice of spins with $Q$ possible orientations, known as the ``$Q$-state clock model". When the $Q$-state clock model has $Q\geq 5$ possible configurations, it presents the famous Berezinskii Kosterlitz Thouless (BKT) phase associated with vortices states. We calculate thermodynamic quantities using Monte Carlo simulations for even $Q$ numbers, ranging from $Q=2$ to $Q=8$ spin orientations per site in a lattice. We use lattices of different sizes with $L\times L = 8^{2}, 16^{2}, 32^{2}, 64^{2}, \text{and}\ 128^{2}$ sites, considering free boundary conditions and an external magnetic field varying between $B = 0$ and $B=1$ in natural units of the system. By obtaining the entropy, it is possible to quantify the MCE through an isothermal process in which the external magnetic field on the spin system is varied. In particular, we find the values of $Q$ that maximize the MCE depending on the lattice size and the magnetic phase transitions linked with the process. Given the broader relevance of the $Q$-state clock model in areas such as percolation theory, neural networks, and biological systems, where multi-state interactions are essential, our study provides a robust framework in applied quantum mechanics, statistical mechanics and related fields.


---
# Predicting electronic screening for fast Koopmans spectral functional calculations

## 用于快速Koopmans光谱功能计算的预测电子筛选

Link: https://arxiv.org/abs/2406.15205

arXiv:2406.15205v2 Announce Type: replace 
Abstract: Koopmans spectral functionals are a powerful extension of Kohn-Sham density-functional theory (DFT) that enable the prediction of spectral properties with state-of-the-art accuracy. The success of these functionals relies on capturing the effects of electronic screening through scalar, orbital-dependent parameters. These parameters have to be computed for every calculation, making Koopmans spectral functionals more expensive than their DFT counterparts. In this work, we present a machine-learning model that -- with minimal training -- can predict these screening parameters directly from orbital densities calculated at the DFT level. We show on two prototypical use cases that using the screening parameters predicted by this model, instead of those calculated from linear response, leads to orbital energies that differ by less than 20 meV on average. Since this approach dramatically reduces run-times with minimal loss of accuracy, it will enable the application of Koopmans spectral functionals to classes of problems that previously would have been prohibitively expensive, such as the prediction of temperature-dependent spectral properties. More broadly, this work demonstrates that measuring violations of piecewise linearity (i.e. curvature in total energies with respect to occupancies) can be done efficiently by combining frozen-orbital approximations and machine learning.


---
# Liquid Hopfield model: retrieval and localization in heterogeneous liquid mixtures

## 液体Hopfield模型: 非均质液体混合物中的检索和定位

Link: https://arxiv.org/abs/2310.18853

arXiv:2310.18853v4 Announce Type: replace-cross 
Abstract: Biological mixtures, such as the cellular cytoplasm, are composed of a large number of different components. From this heterogeneity, ordered mesoscopic structures emerge, such as liquid phases with controlled composition. These structures compete with each other for the same components. This raises several questions, such as what types of interactions allow the retrieval of multiple ordered mesoscopic structures, and what are the physical limitations for the retrieval of said structures. In this work, we develop an analytically tractable model for liquids capable of retrieving states with target compositions. We name this model the liquid Hopfield model in reference to corresponding work in the theory of associative neural networks. By solving this model, we show that non-linear repulsive interactions are necessary for retrieval of target structures. We demonstrate that this is because liquid mixtures at low temperatures tend to transition to phases with few components, a phenomenon that we term localization. Taken together, our results demonstrate a trade-off between retrieval and localization phenomena in liquid mixtures.


---
# Predicting quantum learnability from landscape fluctuation

## 从景观波动预测量子学习能力

Link: https://arxiv.org/abs/2406.11805

arXiv:2406.11805v2 Announce Type: replace-cross 
Abstract: The conflict between trainability and expressibility is a key challenge in variational quantum computing and quantum machine learning. Resolving this conflict necessitates designing specific quantum neural networks (QNN) tailored for specific problems, which urgently needs a general and efficient method to predict the learnability of QNNs without costly training. In this work, we demonstrate a simple and efficient metric for learnability by comparing the fluctuations of the given training landscape with standard learnable landscapes. This metric shows surprising effectiveness in predicting learnability as it unifies the effects of insufficient expressibility, barren plateaus, bad local minima, and overparametrization. Importantly, it can be estimated efficiently on classical computers via Clifford sampling without actual training on quantum devices. We conduct extensive numerical experiments to validate its effectiveness regarding physical and random Hamiltonians. We also prove a compact lower bound for the metric in locally scrambled circuits as analytical guidance. Our findings enable efficient predictions of learnability, allowing fast selection of suitable QNN architectures for a given problem without training, which can greatly improve the efficiency especially when access to quantum devices is limited.


---
# Turkey's Earthquakes: Damage Prediction and Feature Significance Using A Multivariate Analysis

## 土耳其的地震: 使用多变量分析的破坏预测和特征意义

Link: https://arxiv.org/abs/2411.08903

arXiv:2411.08903v1 Announce Type: new 
Abstract: Accurate damage prediction is crucial for disaster preparedness and response strategies, particularly given the frequent earthquakes in Turkey. Utilizing datasets on earthquake data, infrastructural quality metrics, and contemporary socioeconomic factors, we tested various machine-learning architectures to forecast death tolls and fatalities per affected population. Our findings indicate that the Random Forest model provides the most reliable predictions. The model highlights earthquake magnitude and building stability as the primary determinants of damage. This research contributes to the reduction of fatalities in future seismic events in Turkey.


---
# A Message Passing Neural Network Surrogate Model for Bond-Associated Peridynamic Material Correspondence Formulation

## 用于键相关的近场动力材料对应公式的消息传递神经网络代理模型

Link: https://arxiv.org/abs/2411.08911

arXiv:2411.08911v1 Announce Type: new 
Abstract: Peridynamics is a non-local continuum mechanics theory that offers unique advantages for modeling problems involving discontinuities and complex deformations. Within the peridynamic framework, various formulations exist, among which the material correspondence formulation stands out for its ability to directly incorporate traditional continuum material models, making it highly applicable to a range of engineering challenges. A notable advancement in this area is the bond-associated correspondence model, which not only resolves issues of material instability but also achieves high computational accuracy. However, the bond-associated model typically requires higher computational costs than FEA, which can limit its practical application. To address this computational challenge, we propose a novel surrogate model based on a message-passing neural network (MPNN) specifically designed for the bond-associated peridynamic material correspondence formulation. Leveraging the similarities between graph structure and the neighborhood connectivity inherent to peridynamics, we construct an MPNN that can transfers domain knowledge from peridynamics into a computational graph and shorten the computation time via GPU acceleration. Unlike conventional graph neural networks that focus on node features, our model emphasizes edge-based features, capturing the essential material point interactions in the formulation. A key advantage of this neural network approach is its flexibility: it does not require fixed neighborhood connectivity, making it adaptable across diverse configurations and scalable for complex systems. Furthermore, the model inherently possesses translational and rotational invariance, enabling it to maintain physical objectivity: a critical requirement for accurate mechanical modeling.


---
# A machine learning enhanced discontinuous Galerkin method for simulating transonic airfoil flow-fields

## 跨音速翼型流场模拟的机器学习增强间断Galerkin方法

Link: https://arxiv.org/abs/2411.09351

arXiv:2411.09351v1 Announce Type: new 
Abstract: Accurate and rapid prediction of flow-fields is crucial for aerodynamic design. This work proposes a discontinuous Galerkin method (DGM) whose performance enhances with increasing data, for rapid simulation of transonic flow around airfoils under various flow conditions. A lightweight and continuously updated data-driven model is built offline to predict the roughly correct flow-field, and the DGM is then utilized to refine the detailed flow structures and provide the corrected data. During the construction of the data-driven model, a zonal proper orthogonal decomposition (POD) method is designed to reduce the dimensionality of flow-field while preserving more near-wall flow features, and a weighted-distance radial basis function (RBF) is constructed to enhance the generalization capability of flow-field prediction. Numerical results demonstrate that the lightweight data-driven model can predict the flow-field around a wide range of airfoils at Mach numbers ranging from 0.7 to 0.95 and angles of attack from -5 to 5 degrees by learning from sparse data, and maintains high accuracy of the location and essential features of flow structures (such as shock waves). In addition, the machine learning (ML) enhanced DGM is able to significantly improve the computational efficiency and simulation robustness as compared to normal DGMs in simulating transonic inviscid/viscous airfoil flow-fields on arbitrary grids, and further enables rapid aerodynamic evaluation of numerous sample points during the surrogate-based aerodynamic optimization.


---
# Goal-oriented Feature Extraction: a novel approach for enhancing data-driven surrogate model

## 面向目标的特征提取: 一种增强数据驱动代理模型的新方法

Link: https://arxiv.org/abs/2411.09367

arXiv:2411.09367v1 Announce Type: new 
Abstract: Surrogate model can replace the parametric full-order model (FOM) by an approximation model, which can significantly improve the efficiency of optimization design and reduce the complexity of engineering systems. However, due to limitations in efficiency and accuracy, the applications of high-dimensional surrogate models are still challenging. In the present study, we propose a method for extracting hidden features to simplify high-dimensional problems, thereby improving the accuracy and robustness of surrogate models. We establish a goal-oriented feature extraction (GFE) neural network through indirect supervised learning. We constrained the distance between hidden features based on the differences in the target output. This means that in the hidden feature space, cases that are closer in distance output approximately the same, and vice versa. The proposed hidden feature learning method can significantly reduce the dimensionality and nonlinearity of the surrogate model, thereby improving modeling accuracy and generalization capability. To demonstrate the efficiency of our proposed ideas, We conducted numerical experiments on three popular surrogate models. The modeling results of typical high-dimensional mathematical cases and aerodynamic performance cases of ONERA M6 wings show that goal-oriented feature extraction significantly improves the modeling accuracy. Goal-oriented feature extraction can effectively reduce the error distribution of predicting cases and reduce the convergence and robustness differences caused by various data-driven surrogate models.


---
# Localization of nanoscale objects with light singularities

## 具有光奇异性的纳米级物体的定位

Link: https://arxiv.org/abs/2411.09415

arXiv:2411.09415v1 Announce Type: new 
Abstract: Unprecedented atomic-scale measurement resolution has recently been demonstrated in single-shot optical localization metrology based on deep-learning analyses of diffraction patterns of topologically structured light scattered from objects. Here we show that variations in the diffraction patterns caused by positional changes of an object depend upon the spatial derivatives of the magnitude and phase of the incident field, with the latter strongly enhanced at phase singularities. Despite lower intensity near the singularity, an orders-of-magnitude increase in Fisher information contained in the diffraction patterns can be achieved when a nano-object is illuminated by light containing phase singularities, rather than a plane wave. Our work provides a fundamental explanation and motivation for singularity-based metrology with deeply subwavelength precision.


---
# Graph Neural Networks and Differential Equations: A hybrid approach for data assimilation of fluid flows

## 图神经网络和微分方程: 用于流体流数据同化的混合方法

Link: https://arxiv.org/abs/2411.09476

arXiv:2411.09476v1 Announce Type: new 
Abstract: This study presents a novel hybrid approach that combines Graph Neural Networks (GNNs) with Reynolds-Averaged Navier Stokes (RANS) equations to enhance the accuracy of mean flow reconstruction across a range of fluid dynamics applications. Traditional purely data-driven Neural Networks (NNs) models, often struggle maintaining physical consistency. Moreover, they typically require large datasets to achieve reliable performances. The GNN framework, which naturally handles unstructured data such as complex geometries in Computational Fluid Dynamics (CFD), is here integrated with RANS equations as a physical baseline model. The methodology leverages the adjoint method, enabling the use of RANS-derived gradients as optimization terms in the GNN training process. This ensures that the learned model adheres to the governing physics, maintaining physical consistency while improving the prediction accuracy. We test our approach on multiple CFD scenarios, including cases involving generalization with respect to the Reynolds number, sparse measurements, denoising and inpainting of missing portions of the mean flow. The results demonstrate significant improvements in the accuracy of the reconstructed mean flow compared to purely data-driven models, using limited amounts of data in the training dataset. The key strengths of this study are the integration of physical laws into the training process of the GNN, and the ability to achieve high-accuracy predictions with a limited amount of data, making this approach particularly valuable for applications in fluid dynamics where data is often scarce.


---
# MICCAI-CDMRI 2023 QuantConn Challenge Findings on Achieving Robust Quantitative Connectivity through Harmonized Preprocessing of Diffusion MRI

## Miccai-cdmri 2023 QuantConn挑战赛通过扩散MRI的协调预处理实现强大的定量连接的发现

Link: https://arxiv.org/abs/2411.09618

arXiv:2411.09618v1 Announce Type: new 
Abstract: White matter alterations are increasingly implicated in neurological diseases and their progression. International-scale studies use diffusion-weighted magnetic resonance imaging (DW-MRI) to qualitatively identify changes in white matter microstructure and connectivity. Yet, quantitative analysis of DW-MRI data is hindered by inconsistencies stemming from varying acquisition protocols. There is a pressing need to harmonize the preprocessing of DW-MRI datasets to ensure the derivation of robust quantitative diffusion metrics across acquisitions. In the MICCAI-CDMRI 2023 QuantConn challenge, participants were provided raw data from the same individuals collected on the same scanner but with two different acquisitions and tasked with preprocessing the DW-MRI to minimize acquisition differences while retaining biological variation. Submissions are evaluated on the reproducibility and comparability of cross-acquisition bundle-wise microstructure measures, bundle shape features, and connectomics. The key innovations of the QuantConn challenge are that (1) we assess bundles and tractography in the context of harmonization for the first time, (2) we assess connectomics in the context of harmonization for the first time, and (3) we have 10x additional subjects over prior harmonization challenge, MUSHAC and 100x over SuperMUDI. We find that bundle surface area, fractional anisotropy, connectome assortativity, betweenness centrality, edge count, modularity, nodal strength, and participation coefficient measures are most biased by acquisition and that machine learning voxel-wise correction, RISH mapping, and NeSH methods effectively reduce these biases. In addition, microstructure measures AD, MD, RD, bundle length, connectome density, efficiency, and path length are least biased by these acquisition differences.


---
# Exploring the capabilities of CNNs for 3D angiographic reconstructions from limited projection data using rotational angiography

## 使用旋转血管造影从有限的投影数据中探索cnn用于3D血管造影重建的功能

Link: https://arxiv.org/abs/2411.09632

arXiv:2411.09632v1 Announce Type: new 
Abstract: This study leverages convolutional neural networks to enhance the temporal resolution of 3D angiography in intracranial aneurysms focusing on the reconstruction of volumetric contrast data from sparse and limited projections. Three patient-specific IA geometries were segmented and converted into stereolithography files to facilitate computational fluid dynamics simulations. These simulations first modeled blood flow under steady conditions with varying inlet velocities: 0.25 m/s, 0.35 m/s, and 0.45 m/s. Subsequently, 3D angiograms were simulated by labeling inlet particles to represent contrast bolus injections over durations of 0.5s, 1.0s, 1.5s, and 2.0s. The angiographic simulations were then used within a simulated cone beam C arm CT system to generate in-silico rotational DSAs, capturing projections every 10 ms over a 220-degree arc at 27 frames per second. From these simulations, both fully sampled (108 projections) and truncated projection datasets were generated the latter using a maximum of 49 projections. High fidelity volumetric images were reconstructed using a Parker weighted Feldkamp Davis Kress algorithm. A modified U Net CNN was subsequently trained on these datasets to reconstruct 3D angiographic volumes from the truncated projections. The network incorporated multiple convolutional layers with ReLU activations and Max pooling, complemented by upsampling and concatenation to preserve spatial detail. Model performance was evaluated using mean squared error (MSE). Evaluating our U net model across the test set yielded a MSE of 0.0001, indicating good agreement with ground truth reconstructions and demonstrating acceptable capabilities in capturing relevant transient angiographic features. This study confirms the feasibility of using CNNs for reconstructing 3D angiographic images from truncated projections.


---
# Differentiable Land Model Reveals Global Environmental Controls on Ecological Parameters

## 可区分土地模型揭示了生态参数的全球环境控制

Link: https://arxiv.org/abs/2411.09654

arXiv:2411.09654v1 Announce Type: new 
Abstract: Accurate modeling of terrestrial carbon and water exchange requires robust ecological parameters that capture vegetation responses and adaptations to the local environment. The current generation of land models use Plant Functional Types (PFTs) to discretize vegetation functional diversity, but these coarse categorizations often overlook fine-scale variations shaped by local climate, soil, and forest age factors. The lack of governing equations for plant adaptation demands a paradigm shift in how we integrate diverse Earth observations to uncover ecological functional dependence on changing environments. To address this challenge, we developed DifferLand, a differentiable, hybrid physics and machine learning model that infers the spatial distributions of ecological parameters and their relationships with environmental factors constrained by satellite and in-situ observations. Our model unifies top-down and bottom-up observational constraints with process-based knowledge to generate a global analysis of ecological functions and their adaptation to environmental gradients. We found PFTs account for less than half of the explainable spatial parameter variations controlling carbon fluxes and vegetation states. The remaining parameter variability is largely driven by local climate and forest demography factors, and the learned environment-parameter relationships lead to enhanced spatial generalization at unseen locations. DifferLand identified growing season length, leaf economics, and agricultural intensity as the three orthogonal spatial gradients underlying parameter variations. Our novel framework can lead to new insights on global carbon cycling by learning directly from data and expanding our understanding of local responses of ecosystems to environmental drivers.


---
# Computed tomography using meta-optics

## 使用超光学的计算机断层扫描

Link: https://arxiv.org/abs/2411.08995

arXiv:2411.08995v1 Announce Type: cross 
Abstract: Computer vision tasks require processing large amounts of data to perform image classification, segmentation, and feature extraction. Optical preprocessors can potentially reduce the number of floating point operations required by computer vision tasks, enabling low-power and low-latency operation. However, existing optical preprocessors are mostly learned and hence strongly depend on the training data, and thus lack universal applicability. In this paper, we present a metaoptic imager, which implements the Radon transform obviating the need for training the optics. High quality image reconstruction with a large compression ratio of 0.6% is presented through the use of the Simultaneous Algebraic Reconstruction Technique. Image classification with 90% accuracy is presented on an experimentally measured Radon dataset through neural network trained on digitally transformed images.


---
# RibCageImp: A Deep Learning Framework for 3D Ribcage Implant Generation

## RibCageImp: 用于3D胸腔植入物生成的深度学习框架

Link: https://arxiv.org/abs/2411.09204

arXiv:2411.09204v1 Announce Type: cross 
Abstract: The recovery of damaged or resected ribcage structures requires precise, custom-designed implants to restore the integrity and functionality of the thoracic cavity. Traditional implant design methods rely mainly on manual processes, making them time-consuming and susceptible to variability. In this work, we explore the feasibility of automated ribcage implant generation using deep learning. We present a framework based on 3D U-Net architecture that processes CT scans to generate patient-specific implant designs. To the best of our knowledge, this is the first investigation into automated thoracic implant generation using deep learning approaches. Our preliminary results, while moderate, highlight both the potential and the significant challenges in this complex domain. These findings establish a foundation for future research in automated ribcage reconstruction and identify key technical challenges that need to be addressed for practical implementation.


---
# Harnessing Machine Learning for Single-Shot Measurement of Free Electron Laser Pulse Power

## 利用机器学习进行自由电子激光脉冲功率的单次测量

Link: https://arxiv.org/abs/2411.09468

arXiv:2411.09468v1 Announce Type: cross 
Abstract: Electron beam accelerators are essential in many scientific and technological fields. Their operation relies heavily on the stability and precision of the electron beam. Traditional diagnostic techniques encounter difficulties in addressing the complex and dynamic nature of electron beams. Particularly in the context of free-electron lasers (FELs), it is fundamentally impossible to measure the lasing-on and lasingoff electron power profiles for a single electron bunch. This is a crucial hurdle in the exact reconstruction of the photon pulse profile. To overcome this hurdle, we developed a machine learning model that predicts the temporal power profile of the electron bunch in the lasing-off regime using machine parameters that can be obtained when lasing is on. The model was statistically validated and showed superior predictions compared to the state-of-the-art batch calibrations. The work we present here is a critical element for a virtual pulse reconstruction diagnostic (VPRD) tool designed to reconstruct the power profile of individual photon pulses without requiring repeated measurements in the lasing-off regime. This promises to significantly enhance the diagnostic capabilities in FELs at large.


---
# Likelihood and Deep Learning Analysis of the electron neutrino event sample at Intermediate Water Cherenkov Detector (IWCD) of the Hyper-Kamiokande experiment

## Hyper-kamiokande实验的中间水Cherenkov检测器 (IWCD) 中电子中微子事件样本的可能性和深度学习分析

Link: https://arxiv.org/abs/2411.09562

arXiv:2411.09562v1 Announce Type: cross 
Abstract: Hyper-Kamiokande (Hyper-K) is a next-generation long baseline neutrino experiment. One of its primary physics goals is to measure neutrino oscillation parameters precisely, including the Dirac CP violating phase. As conventional $\nu_{\mu}$ beam generates from the J-PARC neutrino baseline contains only 1.5$\%$ of $\nu_{e}$ interaction of total, it is challenging to measure $\nu_{e}/\bar{\nu}_{e}$ scattering cross-section on nuclei. To reduce these systematic uncertainties, IWCD will be built to study neutrino interaction rates with higher precision. Simulated data comprise $\nu_{e}CC0\pi$ as the main signal with NC$\pi^{0}$ and $\nu_{\mu}CC$ are major background events. To reduce the backgrounds initially, a log-likelihood-based reconstruction algorithm to select candidate events was used. However, this method sometimes struggles to distinguish $\pi^{0}$ events properly from electron-like events. Thus, a Machine Learning-based framework has been developed and implemented to enhance the purity and efficiency of $\nu_{e}$ events.


---
# Liquid Hopfield model: retrieval and localization in heterogeneous liquid mixtures

## 液体Hopfield模型: 非均质液体混合物中的检索和定位

Link: https://arxiv.org/abs/2310.18853

arXiv:2310.18853v4 Announce Type: replace 
Abstract: Biological mixtures, such as the cellular cytoplasm, are composed of a large number of different components. From this heterogeneity, ordered mesoscopic structures emerge, such as liquid phases with controlled composition. These structures compete with each other for the same components. This raises several questions, such as what types of interactions allow the retrieval of multiple ordered mesoscopic structures, and what are the physical limitations for the retrieval of said structures. In this work, we develop an analytically tractable model for liquids capable of retrieving states with target compositions. We name this model the liquid Hopfield model in reference to corresponding work in the theory of associative neural networks. By solving this model, we show that non-linear repulsive interactions are necessary for retrieval of target structures. We demonstrate that this is because liquid mixtures at low temperatures tend to transition to phases with few components, a phenomenon that we term localization. Taken together, our results demonstrate a trade-off between retrieval and localization phenomena in liquid mixtures.


---
# Development of a Generalizable Data-driven Turbulence Model: Conditioned Field Inversion and Symbolic Regression

## 开发可推广的数据驱动湍流模型: 条件场反演和符号回归

Link: https://arxiv.org/abs/2402.16355

arXiv:2402.16355v4 Announce Type: replace 
Abstract: This paper addresses the issue of predicting separated flows with Reynolds-averaged Navier-Stokes (RANS) turbulence models, which are essential for many engineering tasks. Traditional RANS models usually struggle with this task, so recent efforts have focused on data-driven methods such as field inversion and machine learning (FIML) to correct this issue by adjusting the baseline equations. However, these FIML methods often reduce accuracy in attached boundary layers. To address this issue, we developed a "conditioned field inversion" technique. This method adjusts the corrective factor \b{eta} (used by FIML) in the shear-stress transport (SST) model. It multiplies \b{eta} with a shield function f_d that is off in the boundary layer and on elsewhere. This maintains the accuracy of the baseline model for the attached flows. We applied both conditioned and classic field inversion to the NASA hump and a curved backward-facing step (CBFS), creating two datasets. These datasets were used to train two models: SR-CND (from our new method) and SR-CLS (from the traditional method). The SR-CND model matches the SR-CLS model in predicting separated flows in various scenarios, such as periodic hills, the NLR7301 airfoil, the 3D SAE car model, and the 3D Ahmed body, and outperforms the baseline SST model in the cases presented in the paper. Importantly, the SR-CND model maintains accuracy in the attached boundary layers, whereas the SR-CLS model does not. Therefore, the proposed method improves separated flow predictions while maintaining the accuracy of the original model for attached flows, offering a better way to create data-driven turbulence models.


---
# Exploring active learning in physics with ISLE-based modules in high school

## 基于ISLE模块的高中物理主动学习探索

Link: https://arxiv.org/abs/2403.11583

arXiv:2403.11583v2 Announce Type: replace 
Abstract: This study presents a case study of active learning within the Investigative Science Learning Environment (ISLE), using the iOLab digital devices. We designed a pilot lab format to enhance student engagement and understanding through direct experimentation, taking advantage of the multifunctional capabilities of the iOLab devices. This paper evaluates the pedagogical effectiveness of integrating ISLE with digital tools for data collection and analysis in physics experiments. The initial findings provide insights into the pedagogical benefits and logistical considerations of using such technologies in a laboratory setting. Although no direct comparison with traditional teaching methods has been made, the observed student engagement and feedback suggest a positive impact on learning outcomes, even within the constraints of the short duration of the interventions.


---
# Event-enhanced Passive Non-line-of-sight imaging for moving objects with Physical embedding

## 具有物理嵌入的移动物体的事件增强无源非视线成像

Link: https://arxiv.org/abs/2404.05977

arXiv:2404.05977v4 Announce Type: replace 
Abstract: Non-line-of-sight (NLOS) imaging with intelligent sensors emerges as a novel technique in imaging and sensing occluded objects around corners. With the innovation of bio-inspired neuromorphic sensors, the applications of novel sensors in unconventional imaging tasks like NLOS imaging have shown promising prospects in intelligent perception, encompassing autonomous driving, medical endoscopy and other sensing scenarios. However, the most challenging point of sensors application in computational imaging is the inverse problem established between sensors acquisition and reconstructions. Traditional physical retrieval methods with certain sensors applications usually result in poor reconstruction due to the highly ill-posedness, particularly in moving object imaging. Thanks to the development of neural networks, data-driven methods have greatly improved its accuracy, however, heavy reliance on data volume has put great pressure on data collection and dataset fabrication. To the best of our knowledge, we firstly propose a sensor-dominated restoration prototype termed "event enhanced passive NLOS imaging prototype for moving objects with physical embedding" (EPNP), which illustrated the application of dynamic vision sensors in NLOS imaging. EPNP induces an event camera for feature extraction of dynamic diffusion spot and leverages simulation dataset to pre-train the physical embedded model before fine-tuning with limited real-shot data. The proposed EPNP prototype is verified by simulation and real-world experiments, while the comparisons of data paradigms also validate the superiority of event-based sensor applications in passive NLOS imaging for moving objects and perspectives in advanced imaging techniques.


---
# Efficient modeling of sub-kilometer surface wind with Gaussian processes and neural networks

## 基于高斯过程和神经网络的亚公里面风高效建模

Link: https://arxiv.org/abs/2405.12614

arXiv:2405.12614v2 Announce Type: replace 
Abstract: Accurately representing surface weather at the sub-kilometer scale is crucial for optimal decision-making in a wide range of applications. This motivates the use of statistical techniques to provide accurate and calibrated probabilistic predictions at a lower cost compared to numerical simulations. Wind represents a particularly challenging variable to model due to its high spatial and temporal variability. This paper presents a novel approach that integrates Gaussian processes and neural networks to model surface wind gusts at sub-kilometer resolution, leveraging multiple data sources, including numerical weather prediction models, topographical descriptors, and in-situ measurements. Results demonstrate the added value of modeling the multivariate covariance structure of the variable of interest, as opposed to only applying a univariate probabilistic regression approach. Modeling the covariance enables the optimal integration of observed measurements from ground stations, which is shown to reduce the continuous ranked probability score compared to the baseline. Moreover, it allows the generation of realistic fields that are also marginally calibrated, aided by scalable techniques such as random Fourier features and pathwise conditioning. We discuss the effect of different modeling choices, as well as different degrees of approximation, and present our results for a case study.


---
# Information-driven design of imaging systems

## 信息驱动的成像系统设计

Link: https://arxiv.org/abs/2405.20559

arXiv:2405.20559v2 Announce Type: replace 
Abstract: Most modern imaging systems process the data they capture algorithmically before-or instead of-human viewing. As a result, performance depends not on how interpretable the measurements appear, but how effectively they encode details for algorithmic processing. Information theory provides mathematical tools to analyze this, but developing methods that can handle the complexity of real-world measurements yet remain practical enough for widespread use has proven challenging. We introduce a data-driven approach for estimating the information content of imaging system measurements. Our framework requires only experimental measurements and noise characterization, with no need for ground truth data. We demonstrate that these information estimates reliably predict system performance across diverse imaging modalities, including color photography, radio astronomy, lensless imaging, and label-free microscopy. To automate the process of designing imaging systems that maximize information capture we introduce an optimization technique called Information-Driven Encoder Analysis Learning (IDEAL). The tools we develop in this work unlock information theory as a powerful, practical tool for analyzing and designing imaging systems across a broad range of applications.
  A video summarizing this work can be found at https://waller-lab.github.io/EncodingInformationWebsite/


---
# Machine Learning Global Simulation of Nonlocal Gravity Wave Propagation

## 非局部重力波传播的机器学习全局模拟

Link: https://arxiv.org/abs/2406.14775

arXiv:2406.14775v2 Announce Type: replace 
Abstract: Global climate models typically operate at a grid resolution of hundreds of kilometers and fail to resolve atmospheric mesoscale processes, e.g., clouds, precipitation, and gravity waves (GWs). Model representation of these processes and their sources is essential to the global circulation and planetary energy budget, but subgrid scale contributions from these processes are often only approximately represented in models using parameterizations. These parameterizations are subject to approximations and idealizations, which limit their capability and accuracy. The most drastic of these approximations is the "single-column approximation" which completely neglects the horizontal evolution of these processes, resulting in key biases in current climate models. With a focus on atmospheric GWs, we present the first-ever global simulation of atmospheric GW fluxes using machine learning (ML) models trained on the WINDSET dataset to emulate global GW emulation in the atmosphere, as an alternative to traditional single-column parameterizations. Using an Attention U-Net-based architecture trained on globally resolved GW momentum fluxes, we illustrate the importance and effectiveness of global nonlocality, when simulating GWs using data-driven schemes.


---
# Predicting electronic screening for fast Koopmans spectral functional calculations

## 用于快速Koopmans光谱功能计算的预测电子筛选

Link: https://arxiv.org/abs/2406.15205

arXiv:2406.15205v2 Announce Type: replace-cross 
Abstract: Koopmans spectral functionals are a powerful extension of Kohn-Sham density-functional theory (DFT) that enable the prediction of spectral properties with state-of-the-art accuracy. The success of these functionals relies on capturing the effects of electronic screening through scalar, orbital-dependent parameters. These parameters have to be computed for every calculation, making Koopmans spectral functionals more expensive than their DFT counterparts. In this work, we present a machine-learning model that -- with minimal training -- can predict these screening parameters directly from orbital densities calculated at the DFT level. We show on two prototypical use cases that using the screening parameters predicted by this model, instead of those calculated from linear response, leads to orbital energies that differ by less than 20 meV on average. Since this approach dramatically reduces run-times with minimal loss of accuracy, it will enable the application of Koopmans spectral functionals to classes of problems that previously would have been prohibitively expensive, such as the prediction of temperature-dependent spectral properties. More broadly, this work demonstrates that measuring violations of piecewise linearity (i.e. curvature in total energies with respect to occupancies) can be done efficiently by combining frozen-orbital approximations and machine learning.


---
# Toward AI/ML-assisted Discovery of Transition Metal Complexes

## 过渡金属配合物的AI/ML辅助发现

Link: https://dx.doi.org/10.26434/chemrxiv-2024-1k3l5?rft_dat=source%3Ddrss

Traditional computational methods for molecule design are based on first principles calculation, which places a high demand on computing power. The increasingly powerful machine learning (ML) models have fundamentally transformed this landscape. Statistically, by learning the joint probability distribution between molecular or material structure and targeted properties, generative models can autonomously design numerous novel structures with satisfactory properties. This inverse design strategy clearly outperforms the traditional physics-based methods which requires human expertise and intuition, along with serendipity. To validate the generated molecules or materials for specific properties, classical discriminative models allow for fast large-scale screening of the quantitative structure-activity relationships. Generally, the completely ML-based workflow from generation to validation for the exploration of chemical space is accessible and provides outstanding benefits which traditional computational approaches struggle to achieve. In this review, we summarize recent advances in ML-assisted discovery for transition metal complexes and conclude with several existing challenges which impede the widespread practical applications of this technology to the class of problems.


---
# Electric Vehicle Pattern-based Battery Cycling Dataset and Its Application in Predicting Rapid Degradation

## 基于电动汽车模式的电池循环数据集及其在快速退化预测中的应用

Link: https://dx.doi.org/10.26434/chemrxiv-2024-db29k-v2?rft_dat=source%3Ddrss

Previous studies aimed at predicting the lifetime of lithium-ion batteries often rely on cycling data characterized by charge and discharge rates that do not reflect the typical usage conditions of electric vehicles (EVs), or they focus on batteries that degrade slowly, limiting their applicability to scenarios where batteries degrade more rapidly. This study introduces a new cycling experiment dataset that mirrors realistic EV charge and discharge profiles and includes conditions that simulate rapid pressure increases due to various side reactions or mechanical impacts.We establish a criterion for identifying cells that experience abrupt capacity fades. Utilizing a two-dimensional convolutional neural network, we accurately classify cells prone to rapid degradation using only the voltage, current and temperature data from the first 3 cycles, achieving over 99% accuracy. Furthermore, we predict the state of health (SOH) of each classified cell at 270 cycles with a root mean square error (RMSE) of less than 2%.


---
# A consistent set of thermophysical properties of methane curated with machine learning

## 用机器学习策划的甲烷热物理性质的一致集合

Link: https://dx.doi.org/10.26434/chemrxiv-2024-gthhs?rft_dat=source%3Ddrss

Accurately predicting thermophysical properties across different states of matter is essential for industrial and scientific applications. However, experimental data often suffer from variability and noise, among other problems, thus necessitating robust modeling approaches to create consistent sets. In this work, we employ machine learning (ML) models to predict multiple thermophysical properties of methane in liquid, vapor, and supercritical phases, including isobaric and isochoric heat capacities, density, volume, Joule-Thomson coefficients, enthalpies, sound speed, and viscosities. We explored different ML algorithms including Adaptive Boosting, Bagging, Decision Trees, Extra Trees, Gradient Boosting, Histogram-based Gradient Boosting Regression Tree, K-Nearest Neighbors, Light Gradient Boosting Machine, Nu-Support Vector Regression, Random Forest, Extreme Gradient Boosting, and Artificial Neural Networks across regions of the phase diagram. Combining ML techniques with previously available raw experimental data shows that ML models provide predictions closer to the statistically treated National Institute of Standards and Technology (NIST) data when compared to the original experimental datasets. Therefore, our approach shows the ML’s potential to identify and generalize complex patterns, smooth inherent data noise, and manage variability. The results indicate that ML models, particularly the Extra Trees and Gradient Boosting models, are a scalable alternative for thermophysical property predictions, offering consistency and efficiency over traditional methods in data processing and curation.


---
# Robust Protein-Ligand Interaction Modeling Integrating Physical Laws and Geometric Knowledge for Absolute Binding Free Energy Calculation

## 强大的蛋白质-配体相互作用模型集成了物理定律和几何知识，用于绝对结合自由能计算

Link: https://dx.doi.org/10.26434/chemrxiv-2024-9k6z7?rft_dat=source%3Ddrss

Accurate estimation of protein-ligand (PL) binding free energies is a crucial task in medicinal chemistry and a critical measure of PL interaction modeling effectiveness. However, traditional computational methods are often computationally expensive and prone to errors. Recently, deep learning (DL)-based approaches for predicting PL interactions have gained enormous attention, but their accuracy and generalizability are hindered by data scarcity. In this study, we propose LumiNet, a versatile PL interaction modeling framework that bridges the gap between physics-based models and black-box algorithms. LumiNet utilizes subgraph transformer to extract multiscale information from molecular graphs and employs geometric neural networks to integrate PL information, mapping atomic pair structures into key physical parameters of non-bonded interactions in classical force fields, thereby enhancing accurate absolute binding free energy (ABFE) calculations.  LumiNet is designed to be highly interpretable, offering detailed insights into atomic interactions within protein-ligand complexes, pinpointing relatively important atom pairs or groups. Our semi-supervised learning strategy enables LumiNet to adapt to new targets with fewer data points than other data-driven methods, making it more relevant for real-world drug discovery. Benchmarks show that LumiNet outperforms the current state-of-the-art model by 18.5% on the PDE10A dataset, and rivals the FEP+ method in some tests with a speed improvement of several orders of magnitude. We applied LumiNet in the scaffold hopping process, which accurately guided the discovery of the optimal ligands. furthermore, we provide a web service for the research community to test LumiNet. The visualization of predicted inter-molecular energy contributions is expected to provide practical values in drug discovery projects.


---
# Instruction set and language for chemical nomenclature

## 化学命名的指令集和语言

Link: https://dx.doi.org/10.26434/chemrxiv-2024-5b4dn?rft_dat=source%3Ddrss

Processing of chemical information by computational intelligence methods faces the challenge of the structural complexity of molecular graphs. These graphs are not amenable to being represented in a suitable way for such methods. The most popular representation is the SMILES notation standard. However, it comes with some limitations such as the abundance of non-valid strings and the fact that similar strings often represent very different molecules.
In this work, a completely different approach to chemical nomenclature is presented. A reduced instruction set is defined, and the language of all strings that are sequences of such instructions is considered. All strings of this language are valid, i.e., each string represents a molecule. Moreover, slight changes in a string usually correspond to small modifications in the represented molecule. Therefore, this approach is appropriate for its use if state-of-the-art computational intelligence systems for chemical information processing, including deep learning models.


---
# Revealing the Role of Local Octahedral Distortions in Hybrid Halide Perovskites Through Physical-Informed Data-Driven Machine Learning

## 通过物理信息数据驱动的机器学习揭示混合卤化物钙钛矿中局部八面体畸变的作用

Link: https://dx.doi.org/10.26434/chemrxiv-2024-klnhr?rft_dat=source%3Ddrss

Data-driven materials design often encounters challenges from small and imbalanced datasets. The complex structural and physicochemical properties of hybrid halide perovskites, coupled with these limitations, create obstacles for performing feature engineering and extracting key fingerprints. Herein, we employed a physical-informed data-driven modeling approach to identify lattice geometric fingerprints, such as the distortion index (DI) and effective coordination number (ECoN), and to establish a robust structure-properties relationship mapping the electronic bandgap, resulting in improved model performance. Lattice compression simulations across multiple phases of MAPbI3 further confirmed a strong correlation between DI and ECoN with electronic bandgap, validating the robustness of the selected octahedra geometrical fingerprints. By adjusting the s-p antibonding coupling, the pressure-driven reduction in local octahedral distortion, induced by the anisotropic hydrogen bonding between the inorganic framework and organic cation, narrows the electronic bandgap and facilitates the p-p transitions, thereby boosting the transition dipole moment and band-edge absorption. Combining data mining with physical analysis, we have successfully clarified the significant impact of lattice geometry on the electronic properties and identified key octahedral geometric fingerprints for effectively describing the electronic bandgap, while also revealed the microphysical mechanisms of local octahedral distortion on the optoelectronic properties of hybrid halide perovskites.


---
# Enhancing Molecular Structure Elucidation: MultiModalTransformer for both simulated and experimental spectra

## 增强分子结构的阐明: 模拟和实验光谱的多模变压器

Link: https://dx.doi.org/10.26434/chemrxiv-2024-zmmnw?rft_dat=source%3Ddrss

We present MultiModalTransformer (MMT), a novel deep learning architecture that directly predicts molecular structures from diverse spectroscopic data (1H-NMR, 13C-NMR, HSQC, COSY, IR, and mass spectrometry (MS). Utilizing a modified Transformer model with attention mechanisms, the MMT simultaneously processes multiple data modalities to focus on the most relevant spectral features. Our approach demonstrates significant advancements in automated structure determination, achieving up to 94% correct identifications for real experimental samples despite being trained solely on simulated spectra. To address the challenges of vast chemical space and limited experimental data we introduce an innovative improvement cycle that allows MMT to adapt to new chemical spaces. The model's robustness is evidenced by its ability to maintain substantial predictive power even when starting with slightly incorrect molecular structures, identifying 56% of experimental molecules correctly from modified initial guesses. MMT provides explainable predictions through token-based analysis, offering insights into its decision-making process. We also present a user-friendly GUI that integrates the full improvement cycle workflow, facilitating practical application in chemistry laboratories. By leveraging diverse spectral inputs and adaptive learning techniques, MMT represents a significant step towards fully automated structure elucidation, potentially accelerating drug discovery and natural product research while demonstrating that comprehensive chemical space coverage in training data is more critical than precise spectral accuracy.


---
# Anomeric Selectivity of Glycosylations Through a Machine Learning Lens

## 通过机器学习镜头对糖基化的异头选择性

Link: https://dx.doi.org/10.26434/chemrxiv-2024-jw9dx?rft_dat=source%3Ddrss

Predicting the stereoselectivity of glycosylations is a major challenge in carbohydrate chemistry. Herein we show that it is possible to build machine learning models that can predict the major anomer of a glycosylation, whether the other anomer is observed as the minor product, and the anomeric ratio of the two anomers. The three models are integrated into a publicly available tool, GlycoPredictor. From a statistical analysis of literature data, we analyze glycosylation trends and compare them to known trends in the field of carbohydrate chemistry, making it possible to elucidate a hierarchy of rules governing the stereoselectivity of glycosylations and discover promising new trends that complement expert intuition.


---
# Dependency-aware Task Collaborative Offloading and Resource Allocation in UAV Enabled Edge Computing

## 无人机边缘计算中依赖感知的任务协同卸载和资源分配

Link: https://www.researchsquare.com/article/rs-4689562/latest

Edge computing, a new wireless communications technology, can provide abundant resources for computing and storage. Recently, it is a challenging problem to jointly consider the offloading and resource allocation of generally dependent tasks in multi Unmanned Aerial Vehicles (UAVs) multi Terminal Devices (TDs) edge computing system. In this paper, the joint problem of offloading decisions, collaborative decisions and resource allocation of general dependent tasks is investigated, considering and highlighting the cooperation between TDs. The corresponding optimization problem, which is a Mixed Integer Nonlinear Programming problem, is formulated. To make this problem solved, an iterative method based on Deep Reinforcement Learning (DRL) and Convex optimization is proposed to decompose the original problem into two subproblems. Given the resource allocation scheme, the Deep Q network (DQN) algorithm is employed to solve the offloading and collaborative decisions of all tasks. Then, given the offloading decision and cooperation decision of all tasks, the convex optimization algorithm is used to solve the optimal resource allocation scheme in the UAV enabled edge computing system. Two subproblems iterative alternately. The simulation results demonstrated that our proposed method can significantly reduce the system energy consumption compared to other schemes.


---
# Leveraging Machine Learning Algorithms for Early Detection and Prognosis of Pediatric Autoimmune Diseases A Comprehensive Data-Driven Approach

## 利用机器学习算法对儿科自身免疫性疾病的早期检测和预后进行全面的数据驱动方法

Link: https://www.researchsquare.com/article/rs-5287349/latest

The early detection and prognosis of pediatric autoimmune diseases are crucial for improving clinical outcomes and patient quality of life. Traditional diagnostic methods often fall short due to the complexity and variability of autoimmune responses in children. This study explores the application of machine learning algorithms in the early detection and prognosis of pediatric autoimmune diseases, leveraging a comprehensive data-driven approach. By integrating various machine learning techniques, including Support Vector Machines (SVM), Random Forests, and Neural Networks, we aim to develop models that can accurately identify early signs of autoimmune diseases and predict their progression. Data for this study were collected from multiple healthcare databases, encompassing a wide range of clinical parameters, patient histories, and biomarker profiles. Preprocessing steps involved data cleaning, normalization, and handling missing values to ensure the robustness of the models. The performance of the machine learning models was evaluated using metrics such as accuracy, precision, recall, and F1-score, with cross-validation techniques employed to validate the results. Our findings demonstrate that machine learning algorithms significantly outperform traditional diagnostic methods in both sensitivity and specificity. The Random Forest algorithm, in particular, showed the highest accuracy in detecting early signs of pediatric autoimmune diseases. Additionally, the models developed provide valuable prognostic insights, aiding healthcare providers in making informed decisions about patient management and treatment plans. The study highlights the potential of machine learning to revolutionize the diagnosis and management of pediatric autoimmune diseases, offering a promising tool for clinicians to enhance early detection and improve patient outcomes. Future research should focus on refining these models and integrating them into clinical practice to fully realize their benefits.


---
# Anomaly Detection in weekly SIRGAS GNSS Time Series: A TimesNet assessment in real data

## 每周SIRGAS GNSS时间序列中的异常检测: 真实数据中的时间网评估

Link: https://www.researchsquare.com/article/rs-4460921/latest

Time series anomaly detection is essential in a range of fields because it allows for the identification of atypical patterns that differ from the expected behavior. Time series data of GNSS coordinates of SIRGAS stations are valuable for research purposes, including the determination of tectonic drift (velocity) and strain rate deformation. Changes in the patterns of a GNSS time series at a station due to abnormal events such as earthquakes, equipment changes, or malfunctions can significantly impact the accuracy of velocity estimation. In this work, we assess the efficacy of a neural network called TimesNet for detecting anomalies in real GNSS time series data from 95 SIRGAS stations in Brazil and Ecuador. As TimesNet achieved state-of-the-art efficiency on many benchmark datasets, it was chosen as the primary model for this research. Hyperparameter optimization was employed for TimesNet using two stations: BRAZ, in a low seismic activity area in Brazil, and CHEC in a high seismic activity area in Ecuador. The results with both hyperparameters sets were compared against three established anomaly detection filters (Gaussian process, Kalman and Moving Average) and a LSTM neural network that were paired with three anomaly scorer methods (norm, K-means and difference). We tested two methods to predict labels from the anomaly scores: 1) Using a fixed percentile (Top 1%) threshold, and 2) Using the Top S scores, where S is the number of anomalies of each station. The TimesNet with hyperparameters optimized in the CHEC station obtained better results than BRAZ, both in Brazil and Ecuador stations, showing that the choice of hyperparameters may present an impact in the anomaly detection results. The best F1Top S and MSE in Brazil were obtained with the Kalman filter (F1Top S=57.60 | MSE&amp;thinsp;=&amp;thinsp;0.0094), closely followed by TimesNet (F1Top S=55.67 | MSE&amp;thinsp;=&amp;thinsp;0.0095). In Ecuador, the best F1Top S and MSE were obtained by TimesNet (F1Top S=63.64 | MSE&amp;thinsp;=&amp;thinsp;0.0145), followed by the Kalman filter (F1Top S=59.09 | MSE&amp;thinsp;=&amp;thinsp;0.0344). Therefore, the anomaly scores produced by TimesNet were less noisy than those produced by the other methods on Ecuador. To foster further research, the source code for this analysis is publicly available at https://github.com/mauriciodev/deep_anomaly_gnss.


---
# Improving Intrusion Detection Systems' Resilience to Adversarial Attacks through Feature Engineering and Hybrid Metaheuristic Algorithms

## 通过特征工程和混合元启发式算法提高入侵检测系统对敌对攻击的适应能力

Link: https://www.researchsquare.com/article/rs-5350806/latest

Intrusion Detection Systems (IDS) are essential for securing computer networks against malicious activities. However, the rise of adversarial attacks seriously threatens the robustness and efficacy of IDS models. With the increasing prevalence of adversarial attacks on intrusion detection systems (IDS), it has become crucial to develop robust defence mechanisms to make sure the integrity and reliability of these systems. This paper presents a novel approach that combines Particle Swarm Optimization (PSO), Gradient Boosting Machines (GBM), genetic operators, and deep neural networks (DNN) with defence mechanisms to improve the resilience of IDS in order to stop adversarial attacks. The proposed approach starts with a feature engineering stage, where PSO and GBM are utilised to select and optimise the most informative features from the input dataset. Genetic operators are then employed to refine the feature selection process further, ensuring the creation of robust and discriminative feature subsets. In the subsequent stage, a deep neural network model is constructed with defence mechanisms, including adversarial training, input perturbation, and ensemble learning. These defence mechanisms work synergistically to monitor and improve the IDS's capacity to find and classify normal and adversarial network traffic accurately. The well-known NSL-KDD dataset is utilised to assess how successful the suggested method is. Experimental findings show that the integrated framework outperforms current techniques. Additionally, the system shows increased resistance to various adversarial techniques, such as evasion, poisoning, and adversarial samples. Overall, this study bridges the gap between adversarial attacks and intrusion detection, offering a powerful defence framework that can be integrated into existing IDS architectures to extenuate the consequence of adversarial threats and ensure the integrity and reliability of network security systems.


---
# Structural Constraint Integration in Generative Model for Discovery of Quantum Material Candidates

## 用于发现量子候选材料的生成模型中的结构约束集成

Link: https://www.researchsquare.com/article/rs-4765336/latest

Billions of organic molecules are known, but only a tiny fraction of the functional inorganic materials have been discovered, a particularly relevant problem to the community searching for new quantum materials. Recent advancements in machine learning-based generative models, particularly diffusion models, show great promise for generating new, stable materials. However, integrating geometric patterns into materials generation remains a challenge. Here, we introduce Structural Constraint Integration in the GENerative model (SCIGEN). Our approach can modify any trained generative diffusion model by strategic masking of the denoised structure with a diffused constrained structure prior to each diffusion step to steer the generation toward constrained outputs. Furthermore, we mathematically prove that SCIGEN effectively performs conditional sampling from the original distribution, which is crucial for generating stable constrained materials. We generate eight million compounds using Archimedean lattices as prototype constraints, with over 10% surviving a multi-staged stability pre-screening. High-throughput density functional theory (DFT) on 26,000 survived compounds shows that over 50% passed structural optimization at the DFT level. Since the properties of quantum materials are closely related to geometric patterns, our results indicate that SCIGEN provides a general framework for generating quantum materials candidates.


---
# Channel Estimation and Interference Management in Multi-User MIMO Systems Using Integrated Deep Learning and Quantum Computing

## 集成深度学习和量子计算的多用户MIMO系统信道估计和干扰管理

Link: https://www.researchsquare.com/article/rs-5051284/latest

This study presents a novel approach combining deep learning with quantum computing for channel estimation and interference management in multi-user MIMO systems. Addressing the limitations of traditional channel estimation methods in complex wireless communication environments, we introduce quantum computing techniques, including quantum Fourier transforms and quantum state reconstruction algorithms, to enhance the accuracy and efficiency of channel estimation. Building on the results from quantum computing, we further optimize the outcomes using deep learning networks, focusing specifically on interference cancellation and data compression. In the experimental setup, we simulated the channel matrix of a multi-user MIMO system on a quantum computing platform and trained a convolutional neural network (CNN) for deep learning optimization. The findings demonstrate that the integration of quantum computing and deep learning substantially enhances system performance, particularly in managing interference and processing data in complex channel environments. This study not only provides new technical methods for channel estimation and interference management in multi-user communication systems but also paves the way for further research into the combined application of quantum computing and deep learning.


---
# Optimizing Military Target Recognition in Urban Battlefields: An Intelligent Framework Based on Graph Neural Networks and YOLO

## 优化城市战场军事目标识别: 基于图神经网络和YOLO的智能框架

Link: https://www.researchsquare.com/article/rs-5207658/latest

In urban battlefield environments, the rapid movement and frequent occlusion of military targets often result in lower detection accuracy. To address this issue, this study proposes an innovative approach that combines graph neural networks with the YOLO model to overcome the slow detection speed and low accuracy due to blurriness in existing models. We first detect the targets, then enhance model performance by introducing intelligent reasoning and optimization processes at the output stage, allowing the model to reassess object confidence based on spatial relationships between objects. A graph relationship model is constructed from the detection results and input into the adjusted SeHGNN network. The SeHGNN network learns complex relationships between targets and recalculates confidence scores. Experimental results show significant improvements in mAP@0.50, demonstrating the effectiveness of this method. By integrating traditional object detection techniques with the knowledge reasoning capabilities of graph neural networks, this approach substantially enhances the model&amp;rsquo;s performance in detecting military targets in urban battlefield scenarios.


---
# Numerical analysis of a fractional-order giving up smoking model&nbsp;by using artificial neural network scheme

## 基于人工神经网络格式的分数阶戒烟模型的数值分析

Link: https://www.researchsquare.com/article/rs-5232616/latest

The aim of this study is to analyze the numerical performance of the fractional-order giving up smoking model (FO-GUSM) by developing a framework for computation by using stochastic Levenberg-Marquardt backpropagation artificial neural networks (SLMB-ANN). The GUSM is classif ied into four categories, potential smokers P(t), occasional smokers L(t), chain smoker S(t), and quit smoker Q(t). Computations are performed by SLMB-ANN to solve the four numerical variations. Using stochastic structured LMB-ANNs, the results obtained from GUSM were presented with training, validation, and testing processes to reduce the mean squared error (MSE) values compared to the reference (data-driven outcomes). To assess the efficiency, accuracy, capability, and proficiency of the suggested computational framework LMB-ANNs, a comprehensive analysis is conducted by analyzing correlations, mean square error (MSE), state transition data, error histograms, and regression analysis. The importance and value of the LMBANNs method is confirmed by the comparison of the results, achieving an accuracy within 5 to 7 decimal places in solving the GUSM.


---
# Comparison between ChatGPT 3.0 and Google Gemini Regarding Medicine Knowledge

## ChatGPT 3.0与Google Gemini关于医学知识的比较

Link: https://www.researchsquare.com/article/rs-5423066/latest

ChatGPT and Gemini AI are two of the most advanced and enhanced large language models widely used worldwide for various purposes. These models are built to facilitate human civilization with their generative capability to produce solutions and suggestions for different purposes, in a human-like conversation type with predictive texts. This study aimed to identify the potential differences between these two models in the case of possessing medical knowledge. A set of multiple-choice questions (MCQ) was adapted from a medicine textbook, and the correct answers were identified by matching the answers in the textbook and a medical expert. Then both of the models were asked to identify the correct answers from the options given to them. They were scored based on their ability to identify the correct answers. The findings revealed that both AI models possess significantly less knowledge of different disease domains and are not sufficiently reliable for medical assistance, though ChatGPT 3.5 possesses slightly better knowledge than its counterpart Google Gemini. The developers should focus on these models to make them more reliable in medical education so that our medical students and doctors can utilize the full potential of Artificial Intelligence in their medical lives for both learning and application.


---
# Design of a surgical robot servo control system based on RBF neural network adaptive PID

## 基于RBF神经网络自适应PID的手术机器人伺服控制系统设计

Link: https://www.researchsquare.com/article/rs-5232481/latest

This paper presents the design of a servo control system for flexible endoscope surgical robots. For the system with a certain degree of uncertainty, an Radial Basis Function (RBF) neural network adaptive Proportional-Integral-Derivative (PID) control algorithm is proposed. This algorithm fully utilizes the adaptivity, self-learning ability, and excellent nonlinear approximation ability of RBF neural network to achieve real-time online adjustment of PID. We developed a mathematical model and transfer function of the servo and conducted a detailed simulation study with the help of MATLAB platform. The simulation results show that the RBF neural network adaptive PID control algorithm not only significantly outperforms the traditional PID controller in terms of performance, demonstrating stronger adaptability and anti-interference ability, but also greatly improves the control effect for nonlinear time-varying systems. We establish the block diagram of the servo control system on the LABVIEW platform and further confirmed the superiority of the algorithm in practical applications through experimental verification. This is specifically manifested in the effective reduction of system overshooting and the significant improvement of response speed and control accuracy.


---
# Pharmacovigilance analysis of drug-induced hypofibrinogenemia using the FDA Adverse Event Reporting System

## 使用FDA不良事件报告系统对药物性低纤维蛋白原血症的药物警戒分析

Link: https://www.researchsquare.com/article/rs-5326354/latest

Background Drug-induced hypofibrinogenemia (DIHF) has received increasing scrutiny; however, the specific drugs involved remain poorly characterized. Hypofibrinogenemia can have significant clinical implications, including increased bleeding risks.Aim This study aimed to utilize the FDA Adverse Event Reporting System (FAERS) to identify and analyze drugs frequently implicated in drug-induced hypofibrinogenemia.Method A disproportionality analysis was conducted using FAERS data from January 2004 to March 2024. Various statistical tools were used, including the Reporting Odds Ratio (ROR), Proportional Reporting Ratio, Medicines and Healthcare Products Regulatory Agency metrics, and Bayesian confidence propagation neural network.Results The analysis included 17,627,340 cases involving 52,373,206 adverse events, with 1,661 cases identified as hypofibrinogenemia, representing just 0.0032% of the total FAERS reports. The top five drugs associated with DIHF by case number were methotrexate (124 cases), tigecycline (119 cases), tocilizumab (100 cases), pegaspargase (83 cases), and alteplase (57 cases). The drugs ranked by signal strength included eravacycline (ROR 2173.84, 95% CI 1208.80-3909.30), tigecycline (ROR 747.34, 95% CI 619.03-902.24), crotalidae polyvalent immune Fab (ROR 407.67, 95% CI 291.07-570.99), pegaspargase (ROR 216.06, 95% CI 173.15-269.61), and asparaginase (ROR 184.93, 95% CI 132.18-258.72).Conclusion This analysis of FAERS data identified 52 drugs associated with hypofibrinogenemia, many of which do not mention this risk in their prescribing information. These findings demonstrate the need for improved pharmacovigilance and may serve as a reference for the prevention and early intervention of DIHF.


---
# MLKD-CLIP：Multi-layer Feature Knowledge Distillation of CLIP for Open-Vocabulary Action Recognition

## Mlkd-clip: 用于开词汇动作识别的CLIP的多层特征知识提炼

Link: https://www.researchsquare.com/article/rs-5330691/latest

Open-vocabulary action recognition aims to identify unseen action categories during training, which is crucial for enabling models to address diverse action scenarios and enhancing their generalizability and adaptability to dynamic environments. Large-scale vision-language pre-trained models (such as CLIP) excel in zero-shot image tasks due to their strong generalizability. However, their lack of temporal information hampers direct application to video tasks. Many studies have fine-tuned CLIP on video datasets, but video datasets are much smaller than the pre-training datasets, potentially leading to reduced generalizability and challenges in recognizing unseen actions. To this end, we propose MLKD-CLIP, which uses the frozen CLIP as the teacher and the fine-tuned CLIP as the student to perform multi-layer feature knowledge distillation. Firstly, we introduce a feature fusion module that employs self-attention to merge features from different layers and incorporates a temporal convolution module, enabling the model to maintain the learning of temporal capabilities during the distillation process. Next, we perform layer-wise fusion to combine the multi-layer features of both the teacher and student models, allowing the model to balance their significance in the distillation process. Finally, we distill the fused features, enabling the student model to learn the multi-level features of the teacher model while considering both global representations and local details. Additionally, the classification tasks on video datasets enhance the student model to learn video features. We evaluated the open-vocabulary action recognition capability of MLKD-CLIP on the UCF101, HMDB51, and SSv2 datasets, achieving the best top-1 accuracy compared to popular methods.


---
# Contextual learning requires rapid Ser408-409 phosphorylation of the GABAA receptor &beta;3 subunit and GABAergic plasticity at hippocampal CA1 synapses

## 情境学习需要海马CA1突触中GABAA受体 β3亚基的快速Ser408-409磷酸化和gaba能可塑性

Link: https://www.researchsquare.com/article/rs-5228324/latest

Contextual learning requires plasticity at both AMPA receptor-mediated excitatory and GABAA receptor-mediated inhibitory synapses in CA1 neurons, but detailed mechanisms of learning-induced plasticity at GABAA receptor-mediated synapses have been unclear. To further investigate the causal relationship between Ser408&amp;ndash;409 phosphorylation, GABAergic plasticity, and learning, we developed a novel peptide-based phosphorylation inhibitor targeting the Ser408&amp;ndash;409 site using a cell-permeable HIV-tagged peptide (Tat pep &beta;3-SS). In the behavioral analysis, the peptide was microinjected bilaterally into CA1 under freely moving conditions 60 min before IA training. Tat-pep &beta;3-SS but not Tat-pep &beta;3-AA significantly impaired contextual learning performance without altering sensory or motor functions. In Western blot analysis, injection of Tat-pep &beta;3-SS but not Tat-pep &beta;3-AA into CA1 attenuated the rapid phosphorylation of Ser408&amp;ndash;409. In patch clamp analysis, we microinjected Tat-pep &beta;3-SS-FITC into CA1 and successfully prevented the training-induced increase in postsynaptic Cl- current of GABAA receptors in labeled CA1 neurons. For histological analysis, membrane clusters of GABAA receptors were reduced in Tat pep &beta;3-SS-positive neurons compared to Tat pep &beta;3-AA-positive neurons. Our study provides novel evidence that contextual learning requires GABAA receptor-mediated plasticity at inhibitory synapses.


---
# 97 Machine Learning Algorithms in the Prognosis of Cutaneous Melanoma: A Population-Based Study

## 97种机器学习算法在皮肤黑色素瘤预后中的应用: 一项基于人群的研究

Link: https://www.researchsquare.com/article/rs-5335515/latest

Objectives: To establish a predictive model for prognosis of cutaneous melanoma using machine learning algorithms in large sample data
Methods: A retrospective analysis of patients diagnosed with cutaneous melanoma in the SEER database from 2010 to 2015 was performed using 12 different machine learning algorithms, for a total of 97 algorithm combinations, to screen for variables associated with cutaneous melanoma prognosis and to build predictive models.
Results: A total of 24,457 cases were collected in this study, and 8,441 cases were finally included. Among them, 5908 cases in the training set and 2533 cases in the test set. The results of the study show that StepCox[both] + RSF is the best model. The variable features screened by the best model were Sex, Age, Marital, T stage, N stage, Ulcer, Site, Histologic, Surgery, Chemotherapy, Bone metastasis, Liver metastasis and Lung metastasis.
Conclusion: We have developed a predictive model with good accuracy for cutaneous melanoma prognosis using a combination of 97 machine learning algorithms in a large sample database.


---
# An Explainable machine learning model for predicting response to targeted therapy and immunotherapy in advanced hepatocellular carcinoma: a multicentric study

## 一种可解释的机器学习模型，用于预测晚期肝细胞癌对靶向治疗和免疫治疗的反应: 一项多中心研究

Link: https://www.researchsquare.com/article/rs-5304318/latest

Background and aims Combination therapy based on targeted therapy and immunotherapy is a first-line treatment for advanced hepatocellular carcinoma (HCC). However, accurately predicting tumor response to the combination therapy is challenging. We aimed to develop an explainable machine learning model to predict response to the combination therapy in advanced HCC.
Methods Patients with advanced HCC who received targeted therapy combined with immunotherapy at four tertiary hospitals were enrolled between January 2020 and January 2024. The extreme gradient boosting (XGBoost) model was constructed to predict whether patients would respond to the combination therapy. The area under the receiver operating characteristic curve (AUC) and F1 score were used to evaluate the predictive performance of the XGBoost model. The SHapley Additive exPlanations (SHAP) method was deployed to interpret the XGBoost model.
Results A total of 179 patients were enrolled in this study, and seventy-six patients (42.5%) showed a response to the combination therapy. The XGBoost model had an AUC of 0.795 (95% confidence interval: 0.716&ndash;0.873) and a F1 score of 0.704 for predicting the response to the combination therapy for advanced HCC in the training set. The importance of SHAP variables in the XGBoost model ranked from high to low, was: interventional therapy, portal vein tumor thrombus, extrahepatic metastasis, number of tumors, and age.
Conclusion The XGBoost machine learning model shows high performance in predicting response to targeted therapy combined with immunotherapy in advanced HCC. Additionally, the SHAP method facilitates a comprehensive interpretation of the results generated by the machine learning model.


---
# Exploring Machine Learning Algorithms for Predicting Early Antenatal Care Initiation at First Trimester among Reproductive Women in Nigeria

## 探索机器学习算法，以预测尼日利亚育龄妇女在孕早期开始产前护理

Link: https://www.researchsquare.com/article/rs-5321613/latest

Background Early antenatal care (ANC) initiation during the first trimester is crucial for maternal and child health outcomes. However, in Nigeria, early ANC uptake remains low due to socioeconomic and cultural barriers. Traditional statistical models used to predict ANC initiation often fail to capture the complex nonlinear interactions between predictors. This study applies machine learning (ML) algorithms to predict early ANC initiation using data from Nigeria&amp;rsquo;s 2018 Demographic and Health Survey (NDHS).Methods This cross-sectional study utilized NDHS 2018 data and six ML algorithms: Logistic Regression (LR), Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Decision Tree, Random Forest (RF), and XGBoost. The synthetic minority oversampling technique (SMOTE) was used to address data imbalance. The models were evaluated using metrics, such as accuracy, precision, recall, and AUROC values. Feature importance was assessed using the permutation importance and Gini impurity methods.Results The Random Forest model demonstrated the best performance, achieving the highest accuracy (77%), precision (75%), recall (80%), and AUROC value of 0.77. This model effectively identified key predictors of early ANC, including education level, wealth index, and place of delivery, with educated and wealthier women being more likely to seek early care. Feature importance analysis revealed significant sociodemographic and geographic disparities, highlighting the critical role of economic resources and healthcare accessibility in influencing ANC behavior.Conclusion ML models, particularly Random Forest, provide an effective approach for predicting early ANC initiation, offering comprehensive insights beyond traditional methods. These findings underscore the need for targeted interventions focusing on education, economic empowerment, and healthcare access to enhance early ANC uptake among Nigerian women.


---
# Pollen Grain Intensity Identification in the Air&nbsp;using YOLO and RNN: A Review

## 使用YOLO和RNN识别空气中的花粉粒强度: 综述

Link: https://www.researchsquare.com/article/rs-5179016/latest

Pollen allergies, also known as hay fever or allergic rhinitis, impact millions of&amp;nbsp;people worldwide, especially during peak seasons when pollen concentrations in&amp;nbsp;the air are elevated. Traditional methods of monitoring pollen levels, such as&amp;nbsp;manual counting and analysis of pollen traps, often result in delayed reports that&amp;nbsp;do not provide real-time data. This limitation leaves individuals with allergies&amp;nbsp;vulnerable to sudden increases in pollen levels. Furthermore, regional variations&amp;nbsp;in pollen concentrations and the influence of environmental factors such as wind&amp;nbsp;patterns, temperature, and humidity make it challenging to offer accurate, localized pollen forecasts. With the advent of advanced machine learning technologies,&amp;nbsp;there is now an opportunity to transform the way pollen is detected and predicted, providing more immediate and personalized solutions for allergy sufferers.&amp;nbsp;The integration of YOLO and RNN models offers a groundbreaking approach to&amp;nbsp;this problem, leveraging both real-time visual analysis and predictive analytics&amp;nbsp;to deliver timely and accurate pollen data.&amp;nbsp;
The YOLO model, widely recognized for its ability to perform real-time object&amp;nbsp;detection, is particularly suited for detecting and classifying pollen grains in outdoor environments. By deploying cameras in strategic locations&mdash;such as near&amp;nbsp;parks, forests, or urban areas with high vegetation&mdash;this system can capture&amp;nbsp;continuous video feeds or images of the air. YOLO then processes these visual&amp;nbsp;inputs to detect pollen particles in real time, distinguishing them from other&amp;nbsp;airborne particulates like dust or pollution. This visual detection is crucial for&amp;nbsp;1providing immediate updates on pollen presence in the air. The RNN model complements this by offering a predictive component, using historical pollen data,&amp;nbsp;environmental factors, and trends to forecast future pollen levels.
MSC Classification: 30C45 , 30C50


---
# Data Augmentation in Cancer Image&nbsp;Classification Problem with Quantum GAN

## 量子GAN在癌症图像分类问题中的数据增强

Link: https://www.researchsquare.com/article/rs-5191116/latest

&nbsp;In this paper, we propose a novel approach leveraging Quantum Generative&nbsp;Adversarial Networks (QGANs) for data augmentation in cancer image classification tasks. Cancer diagnosis from medical images plays a crucial role in early&nbsp;detection and treatment planning. However, imbalance nature of medical image&nbsp;data pose significant challenges for training accurate classification models. Our&nbsp;proposed methodology utilizes QGANs to generate synthetic medical images that&nbsp;closely mimic the characteristics of real cancer images classes, effectively addressing the data imbalance issue. Our QGAN architecture, which combines quantum&nbsp;circuits for the generator with a classical neural networks for the discriminator,&nbsp;was trained to synthesize medical images for augmentation. The performance of&nbsp;the convolutional neural networks (CNN) classifier was evaluated using accuracy&nbsp;and the area under the receiver operating characteristics curve (AUC-ROC) as&nbsp;metrics. Results show that augmented datasets significantly improve the classif&nbsp;ication performance. For instance, the AUC-ROC for the Basal Cell Carcinoma&nbsp;(BCC) class increased by 0.031, and the Dermatofibroma (DF) class saw a reduction in validation loss by 0.06. Moreover, segmentation-based QGAN training&nbsp;demonstrated considerable advantages in computational efficiency. The training&nbsp;time was reduced to just one hour, and inference times were less than a second&nbsp;per image.


---
# Predicting pragmatic language abilities from brain structural MRI in preschool children with ASD by NBS-Predict

## NBS预测学龄前ASD儿童脑结构MRI的语用语言能力

Link: https://www.researchsquare.com/article/rs-5308722/latest

Pragmatics, as it pertains to spoken language, plays a crucial role in effectively conveying messages across various social communication contexts. This aspect is frequently highlighted in the challenges experienced by children diagnosed with autism spectrum disorder (ASD). Notably, there remains a paucity of research investigating how the structural connectome (SC) predicts pragmatic language abilities within this population. Using diffusion tensor imaging (DTI) and deterministic tractography, we constructed the whole-brain white matter structural network (WMSN) in a cohort comprising 92 children with ASD and 52 typically developing (TD) preschoolers, matched for age and gender. Subsequent graph theoretical analyses were conducted to assess alterations in the global and node-based properties of the WMSN within both cohorts. To further elucidate these findings, we employed NBS-Predict, a novel methodology that integrates machine learning (ML) with network-based statistics (NBS), to identify dysconnected subnetworks associated with ASD. Our application of NBS-Predict allowed us to predict pragmatic language abilities based on the SC derived from the whole-brain WMSN in the ASD group. Initially, NBS-Predict identified a subnetwork characterized by 42 reduced connections across 37 brain regions (p&amp;thinsp;=&amp;thinsp;0.01), achieving a highest classification accuracy of 79.4% (95% CI: 0.791&amp;ndash;0.796). The dysconnected regions were predominantly localized within the brain&amp;rsquo;s frontotemporal and subcortical areas, with the right superior medial frontal gyrus (SFGmed.R) emerging as the region exhibiting the most extensive disconnection. Moreover, NBS-Predict demonstrated that the optimal correlation coefficient between the predicted pragmatic language scores and the actual measured scores was 0.204 (95% CI: 0.181&amp;ndash;0.226). This analysis revealed a significant association between the pragmatic language abilities of the ASD cohort and the white matter connections linking the SFGmed.R with the bilateral anterior cingulate gyrus (ACC). In summary, our findings suggest that the subnetworks displaying the most significant abnormal connections were concentrated in the frontotemporal and subcortical regions among the ASD group. Furthermore, the observed abnormalities in the white matter connection pathways between the SFGmed.R and ACC may underlie the neurobiological basis for pragmatic language deficits in preschool children with ASD.


---
# Comparison of uniportal and three-portal video-assisted thoracoscopic thymectomy for thymoma: a propensity score-matched study.

## 单入口和三入口电视胸腔镜胸腺切除术治疗胸腺瘤的比较: 一项倾向评分匹配研究。

Link: https://www.researchsquare.com/article/rs-5312029/latest

Background: Minimally invasive thymectomy (MIT) is a surgical approach to thymectomy. To investigate the efficacy of the minimally invasive thymectomy, a retrospective comparison for perioperative outcomes of patients was conducted between uniportal and three-portal video-assisted thoracoscopic thymectomy (UP-VATS and TP-VATS).
Methods: A detailed database search identified 135 patients treated withUP-VATS thymectomy technique and 228 patients treated via TP-VATS thymectomy technique between January 2013 and December 2022. Propensity score-matched analysis was used to compare the perioperative outcomes between the two groups.
Results: The first 20 patients were excluded respectively to account for the learning curve effect in both groups. 115 patients in each group were screened after propensity match. There were 14.8% morbidity in the UP-VATS group and 12.2% morbidity in the TP-VATS group, no significant differences were exist between two groups. Furthermore, no significant differences in other perioperative outcomes were exist between two groups. Although the volume of drainage (86.2 vs. 76.1, p = 0.078) were similar between the two groups, the operative time in the UP-VATS group (117.2 vs. 96.7, p &amp;lt; 0.001) was longer than that in the TP-VATS group.
CONCLUSION: Thymectomy treatment of (TP-VATS) is an advisable procedure for patients with thymoma, while these two minimally invasive thymectomy techniques are both appropriate for thymoma treatment.


---
# Deep Learning Frameworks for Histopathological Image Processing in Colorectal Cancer Diagnostics

## 用于结直肠癌诊断的组织病理学图像处理的深度学习框架

Link: https://www.researchsquare.com/article/rs-5247690/latest

Artificial intelligence (AI) in the field of pathology and medical diagnostics has rapidly evolved, with applications focused on analyzing histopathological images. These images, obtained from biopsies or surgical procedures, are crucial for diagnosing diseases, particularly cancer, and provide essential insights into tissue structure. Traditionally, pathologists faced a challenging task in accurately analyzing the cellular features within these images. However, the introduction of deep learning, has significantly improved diagnostic reliability. In this study, two convolutional neural network models were implemented and compared. Both were trained on a multiclass dataset of histological images related to colorectal cancer. Among the two tested models, VGG-19 demonstrated the best performance, achieving a precision rate of 98%. Using a Python-based graphical interface, we employed the "Grad-CAM" technique to gain deeper insight into the model's classification process and identify key regions during training. The application of artificial intelligence to colon histopathological images also has the potential to improve patient outcomes and early cancer diagnosis. By combining AI with intuitive interfaces, we can enhance diagnostic accuracy and accelerate the analysis process.


---
# Toward Indigenous Knowledge Systems: The Role of Project-Based Learning in HigherEducation: Insights into Sculpture Students' Projects on Ghanaian Adinkra Symbols

## 迈向土著知识体系: 基于项目的学习在高等教育中的作用: 对加纳Adinkra符号上的雕塑学生项目的见解

Link: https://www.researchsquare.com/article/rs-5180598/latest

This study explores the integration of Project-Based Learning (PBL) within the higher education context, focusing on sculpture students' projects based on Ghanaian Adinkra symbols and their engagement with Indigenous Knowledge Systems (IKS). The primary aim of this research is to examine how PBL enhances sculpture students' understanding and appreciation of Adinkra symbols while also assessing the broader impact of PBL on their interaction with indigenous knowledge systems. Sculpture students participating in this study were tasked with developing projects that incorporated Adinkra symbols, thereby connecting their creative practice with the rich cultural narratives embodied in these symbols. Through this process, students were not only encouraged to produce art but also to interpret, analyse, and engage with the cultural meanings and historical significance of the Adinkra symbols. A qualitative research methodology was employed, using semi-structured interviews, participant observations, and project evaluations to gather data. Findings from the study suggest that PBL significantly enhances students' appreciation for and understanding of indigenous knowledge systems by providing them with the tools to interpret cultural artefacts within their historical and social contexts. To collaborate with indigenous communities, art educational institutions should build partnerships with local indigenous communities, cultural experts, and artisans to co-create projects and learning experiences for students.


---
# Intrahost dynamics, together with genetic and phenotypic traits predict the success of viral mutations

## 宿主内动态，连同遗传和表型性状预测病毒突变的成功

Link: https://www.researchsquare.com/article/rs-5298116/latest

Predicting the fitness of mutations in the evolution of pathogens is a long-standing and important, yet largely unsolved problem. In this study, we used SARS-CoV-2 as a model system to explore whether the intrahost diversity of viral infections could provide clues on the relative fitness of single amino acid variants (SAVs). To do so, we analysed ~15 million complete genomes and nearly ~8000 sequencing libraries generated from SARS-CoV-2 infections, which were collected at various timepoints during the COVID-19 pandemic. Across timepoints, we found that many successful SAVs were detected in the intrahost diversity of samples collected prior, with a median of 6-40 months between the initial collection dates of samples and the highest frequency seen for these SAVs. Additionally, we found that the co-occurrence of intrahost SAVs significantly captures genetic linkage patterns observed at the interhost level (Pearson&rsquo;s r=0.28-0.45, all p&amp;lt;0.0001). Further, we show that machine learning models can learn highly generalisable intrahost, physiochemical and phenotypic patterns to forecast the future fitness of intrahost SAVs (r2=0.48-0.63). Most of these models performed significantly better when considering genetic linkage (r2=0.53-0.68). Overall, our results document the evolutionary forces shaping the fitness of mutations, which may offer potential to forecast the emergence of future variants and ultimately inform the design of vaccine targets.


---
# Enhancing Streamflow Forecasting in Glacierized Basins: A Hybrid Model Integrating Glacio-Hydrological Outputs, Deep Learning, and Wavelet Transformation

## 增强冰川盆地的水流预测: 集成了冰川水文输出，深度学习和小波变换的混合模型

Link: https://www.researchsquare.com/article/rs-5296614/latest

Understanding snow and ice melt dynamics is vital for flood risk assessment and effective water resource management in highly populated river basins rising in inaccessible high-mountains. This study evaluated AI-enhanced hydrological modelling using a hybrid approach integrating glacio-hydrological model (GSM-SOCONT), with advanced machine learning and deep learning techniques framed as alternative &amp;lsquo;scenarios&amp;rsquo;, leveraging both physical processes and data-driven insights for enhanced predictive capabilities. The standalone deep learning model (CNN-LSTM), relying solely on meteorological data, outperformed both the machine learning and glacio-hydrological model. Additionally, a series of hybrid models (CNN-LSTM1 to CNN-LSTM15) were trained using meteorological data along with three additional feature groups derived from glacio-hydrological model outputs, providing detailed physical insights into hydrological processes for streamflow simulation. The hybrid model (CNN-LSTM14), which relied solely on glacier-derived features, demonstrated the best performance with high NSE (0.86), KGE (0.80), and R (0.93) values during calibration, and the highest NSE (0.83), KGE (0.88), R (0.91), and lowest RMSE (892) and MAE (544) during validation. Furthermore, the proposed hybridization framework involves applying permutation feature importance to identify key features, using wavelet transform to decompose them for multi-scale analysis, and integrating these into the hybrid model (CNN-LSTM19), which significantly enhances predictive accuracy, particularly for high-flow events, as evidenced by improved NSE (from 0.83 to 0.97) and reduced RMSE (from 892 to 442) during validation. The comparative analysis illustrates how AI-enhanced hydrological models improve the accuracy of runoff forecasting and provide more reliable and actionable insights for managing water resources and mitigating flood risks - despite the relative paucity of direct measurements.


---
# Deep Learning-based Classification Model using SMOTE Resampling Technique to Identify Potent Inhibitors of Lethal Factor of Anthrax and Principal Component, Chemical Space Analysis

## 基于深度学习的分类模型利用SMOTE重采样技术识别炭疽致死因子强效抑制剂及主成分、化学空间分析

Link: https://www.researchsquare.com/article/rs-5315945/latest

Anthrax is a highly lethal disease caused by Bacillus anthracis. Lethal factor (LF) with protective antigen directly contributes to anthrax symptoms in humans. This research work identified a small molecule inhibitors of anthrax lethal factor. We developed a consolidated computational strategy that includes a deep learning-based SMOTE&amp;thinsp;+&amp;thinsp;artificial neural network (ANN) hybrid model, principal component analysis, t-SNE, activity cliff, constellation plot, scaffold, and fingerprinting to identify potential drug candidates against Anthrax. The best model showed 0.98 accuracy, 0.99 specificity, 0.99 sensitivity, 0.99 F1-score, 0.99 recall, 0.99 ROC, and 0.99 precision. The trained hybrid model screened out 134 FDA-approved drugs, 338 experimental drugs, 51 phytochemical compounds of the phytochemical database, and eight natural products from NCI divest IV as anthrax inhibitors. We found scaffold of ring system with substitution patterns such as 4-oxopyrrolo[3,2-c]quinolone enhanced the biological activity of Anthrax inhibitors. Fingerprints indicated greater than 80% and are linked to the ring system using the substitution pattern scaffold. These studies conclude that SMOTE&amp;thinsp;+&amp;thinsp;ANN model could be an efficient method for the virtual screening of large database and a new way to screen small molecules against Anthrax.


---
# Malware Detection via Memory Dump Images: Investigating the Role of Uneven Kernel Filters in CNNs with Visual Explainability

## 通过内存转储图像进行恶意软件检测: 研究具有视觉可解释性的cnn中不均匀内核过滤器的作用

Link: https://www.researchsquare.com/article/rs-5376790/latest

With the Internet becoming more accessible, protecting our digital identities has become more crucial than ever. Our devices are always online, sharing data, and exposed to numerous threats. Traditional methods of detecting malware are no longer adequate due to the rapid advancement and complexity of malware. To address these challenges, researchers have started using artificial intelligence, especially machine learning and deep learning techniques, with encouraging outcomes. One emerging approach involves converting malware binaries or memory dumps into images. However, these malware images are not recognizable to the human eye and, therefore, need to be explained in terms of how the CNNs perceive this data type. This paper applies the Grad-CAM technique to malware images collected from memory dumps to understand sufficiently how black-box CNN models make predictions with this data. Based on insights from the Grad-CAM analysis, we propose a novel CNN architecture with uneven kernel sizes that outperforms existing malware detection and classification models. We compare its performance against well-known CNN architectures, all trained and tested on malware image datasets such as Malimg, Dumpware10, MaleVis, and MalBen. Our proposed architecture achieved an impressive accuracy of 99.58\% on the Malimg dataset with fewer training parameters, surpassing previous models, which achieved a maximum accuracy of 99.26\% on the same dataset.


---
# AFF-LightNet: Attentional Feature Fusion Based Lightweight Network for Ship Detection

## Aff-lightnet: 基于注意力特征融合的轻量级舰船检测网络

Link: https://www.researchsquare.com/article/rs-5369748/latest

Efficient mobile detection equipment plays a vital role in ensuring maritime safety, and accurate ship identification is crucial for maritime traffic. Recently, advanced learning-based methods boost the accuracy of ship detection, but face challenges on mobile devices due to size and computation. Thus, we propose a lightweight ship detection network based on feature fusion, called AFF-LightNet. We introduce iterative attentional feature fusion (IAFF) into the proposed neck network, improving the efficiency of feature fusion by introducing a multi-scale channel attention module. Also, Conv is replaced by DCNv2 in the backbone network to further improve the detection accuracy of the proposed network. DCNv2 enhances the spatial sampling position in convolution and Rol pooling by introducing offsets. Moreover, a lightweight convolution GhostConv was introduced into the head network to reduce the number of parameters and computation cost. Last, SIOU was leveraged to improve the convergence speed of the model. We conduct extensive experiments on the publicly available dataset SeaShips and compare it with existing methods. The experimental results show that compared with the standard YOLOv8n, the improved network has an average accuracy of 98.8%, an increase of 0.4%, a reduction of 1.9 G in computational complexity, and a reduction of 0.19 M in parameter count.


---
# TML: A Transformer-Based Meta-Learning Framework for Cross-Project Software Defect Prediction

## TML: 一种基于Transformer的跨项目软件缺陷预测元学习框架

Link: https://www.researchsquare.com/article/rs-5382592/latest

Identifying software defects early is crucial for enhancing software quality and reducing costs. Traditional Within-Project Defect Prediction (WPDP) methods rely on historical project-specific data, limiting their effectiveness when such data is unavailable. Cross-Project Defect Prediction (CPDP) offers a solution by leveraging defect data from different projects, but challenges arise due to the diverse nature of data distributions across projects. This paper presents a novel framework, TML (Transformer-based Meta-Learning), designed to improve CPDP performance by addressing these challenges. TML integrates transformer-based encoder networks for feature extraction, adversarial domain adaptation to align data distributions, and meta-learning to enhance generalization across projects. Additionally, it incorporates ensemble learning and Bayesian optimization to improve model robustness and predictive accuracy. The framework is evaluated on 16 datasets from four major software repositories (AEEM, NASA, Promise, JIRA). Experimental results demonstrate that TML significantly outperforms existing CPDP methods such as ENTL, EGW, and EMKCA in key performance metrics including Precision, Recall, F1-score, G-Mean, and AUC. The results consistently demonstrate the robustness of the TML framework, establishing it as a promising approach for early defect detection in diverse software development environments.


---
# Four-Step Approach to Screening Mental Health in Adolescents with Substance Use: A Study Using NSDUH Data

## 四步法筛查青少年使用物质的心理健康: 一项使用NSDUH数据的研究

Link: https://www.researchsquare.com/article/rs-5057651/latest

This study implements multiple independent models and aggregates them to screen the mental health status of adolescents with substance use problems, aiming to address an observable gap in developing reproducible and replicable Artificial Intelligence (AI) application. We analysed 21,037 adolescents in the year 2021 and 2022 National Survey on Drug Use and Health (NSDUH) data, focusing on multiple target correlates. Data columns with more than 80% missing values, variance below 1%, and correlation above 99% were omitted. Chi-square analysis identified significant associations, while mutual information analysis measured the strength of association. 29 input features related to major depressive episodes, substance use disorders, and mental health treatment history were associated with each of the 16 mental health status target labels, including concentration, depressive symptoms, sleep, energy levels, restlessness, loss of interest and appetite. Analysis of Machine Learning (ML) classifiers, neural networks, and ensemble techniques identified the best-performing models. These model&rsquo;s predictions and their consensus screen and diagnose adolescents&rsquo; status. The resulting AI-based application is deployed at https://huggingface.co/spaces/pantdipendra/AdolescentsMentalHealthPrediction. Finally, the four-step approach, consisting of data extraction, statistical, machine learning analytics, and AI application step, supports reproducible AI application development and makes it accessible to community practices and patient care.


---
# Automated Pipeline for Leaf Spot Severity Scoring in Peanuts Using Segmentation Neural Networks

## 使用分割神经网络对花生中的叶斑严重程度进行自动评分的管道

Link: https://www.researchsquare.com/article/rs-5059528/latest

Background: Late and early leaf spot in peanuts is a foliar disease contributing to a significant amount of lost yield globally. Peanut breeding programs frequently focus on developing disease-resistant peanut genotypes. However, existing phenotyping protocols employ subjective rating scales, performed by human raters, who determine the severity of leaf spot infection. The objective of this study was to develop an objective end-to-end pipeline that can serve to replace an expert human scorer in the field. This was accomplished using image capture protocols and segmentation neural networks that extracted lesion areas from plot-level images to determine an appropriate rating for infection severity.&amp;nbsp;
Results: The pipeline incorporated a neural network that accurately determined the infected leaf surface area and identified dead leaves from plot-level cellphone imagery. Image processing algorithms then convert these labels into quality metrics that can efficiently score these images based on infected versus non-infected area. The pipeline was evaluated using field data from plots with varying leaf spot severity, creating a dataset of thousands of images that spanned conventional visual severity scores ranging from 1-9. These predictions were based on the amount of infected leaf area and the presence of defoliated leaves in the surrounding area. We were able to demonstrate automated scoring, as compared to exprt visual scoring, with a root mean square error of 0.996 visual scores, on individual images (one image per plot), and 0.800 visual scores when three images were captured of each plot.&amp;nbsp;
Conclusion: Results indicated that the model and image processing pipeline can serve as an alternative to human scoring. Eliminating human subjectivity for the scoring protocols will allow non-experts to collect scores and may enable drone-based data collection. This could reduce the time needed to obtain new lines or identify new genes responsible for leaf spot resistance in peanut.


---
# Reusability report: Towards inflow generators for turbulence simulations through diffusion models

## 可重用性报告: 通过扩散模型进行湍流模拟的流入发生器

Link: https://www.researchsquare.com/article/rs-4631799/latest

The use of machine learning for scientific applications (SciML) provides an appealing alternative for solving computationally-intensive tasks in physical simulations. The chaotic and high-dimensional nature of turbulent flows makes the application of these techniques to fluid-dynamics problems challenging. Nonetheless, Li et al. [1] have shown how diffusion models can be successfully trained to generate new Lagrangian trajectories in turbulent flows, correctly reproducing most statistical benchmarks across different scales. In this work, we show how the same neural-network model and training method can be adapted to generate fluctuation velocity fields from a turbulent open-channel simulation. The resulting fields are qualitatively and statistically accurate, hinting at the possibility to use this method to accelerate direct numerical simulations, for instance through inflow generators


---
# Machine Learning for Early Detection and Severity Classification in People with Parkinson's Disease

## 机器学习用于帕金森病患者的早期检测和严重程度分类

Link: https://www.researchsquare.com/article/rs-5195774/latest

Early detection of Parkinson's disease (PD) and accurate assessment of disease progression are critical for optimizing treatment and rehabilitation. However, there is no consensus on how to effectively detect early-stage PD and classify motor symptom severity using gait analysis. This study evaluated the accuracy of machine learning (ML) models in classifying early and moderate stages of PD based on spatiotemporal gait features at different walking speeds. A total of 178 participants were recruited, including 103 individuals with PD (61 early-stage, 42 moderate-stage) and 75 healthy controls. Participants performed a walking test on a 24-meter walkway at three speeds: preferred walking speed (PWS), 20% faster (HWS), and 20% slower (LWS). Key features&amp;mdash;walking speed at PWS, stride length at HWS, and the coefficient of variation (CV) of stride length at LWS&amp;mdash;achieved a classification accuracy of 78.1% using the random forest algorithm. For early PD detection, stride length at HWS and CV at LWS provided 67.3% accuracy with Na&amp;iuml;ve Bayes. Walking speed at PWS was the most critical feature for distinguishing early from moderate PD, with an accuracy of 69.8%. These findings suggest that assessing gait over consecutive steps under different speed conditions may improve early detection and severity assessment of people of PD.


---
# Association between Geriatric Nutritional Risk Index and Cognitive Function: National Health and Nutrition Examination Survey

## 老年营养风险指数与认知功能的关系: 全国健康和营养检查调查

Link: https://www.researchsquare.com/article/rs-5017881/latest

Background: Population aging is increasing annually, and cognitive dysfunction is a prevalent issue among the elderly.
Aims:This study aims to investigate the association between the Geriatric Nutritional Risk Index (GNRI) and cognitive function.
Methods:The study included 2,653 participants aged 60 years and older, who had complete valid data from the 2011-2014 National Health and Nutrition Examination Survey (NHANES). The assessment utilized the CERAD Word Learning subtest (CERAD WL), the Animal Fluency Test, and the Digit Symbol Substitution Test (DSST) to evaluate cognitive function, subsequently categorizing participants into normal cognitive function and cognitive impairment groups. Logistic regression analysis was conducted individually based on a control risk factor model to investigate the relationship between the elderly nutritional risk index and cognitive function.
Results: Multifactorial logistic regression analysis revealed that older adults, those with a partner, individuals with low educational attainment, and those with diabetes mellitus were significantly associated with an increased risk of cognitive impairment (P &amp;lt; 0.05). Conversely, a low nutritional risk index in older adults was significantly linked to a reduced risk of cognitive impairment (P &amp;lt; 0.05). In contrast, both low to moderate nutritional risk and high nutritional risk did not show significant associations with cognitive impairment risk when compared to no nutritional risk (P &amp;gt; 0.05).
Conclusion: Moderate to high nutritional risk (low GNRI levels) was independently associated with cognitive decline related to processing speed, sustained attention, and executive function.


---
# A Noval RUL Prediction Method for Rolling Bearing: TcLstmNet-CBAM

## 滚动轴承的一种新的RUL预测方法: tclstmnet-cbam

Link: https://www.researchsquare.com/article/rs-5294683/latest

Rolling bearings are pivotal components within rotating mechanical systems, and accurately predicting their remaining service life holds significant practical importance. This paper addresses issues prevalent in common deep learning methods for predicting remaining useful life (RUL), notably inadequate feature extraction and low prediction accuracy resulting from reliance solely on short-term or long-term dependent features.In this paper, we introduce a residual useful life prediction method for bearings, named TcLstmNet-CBAM. This method integrates CBAM attention alongside parallel Temporal Convolutional Network (TCN) and Long Short-Term Memory (LSTM). Specifically, it employs a parallel network architecture for feature extraction, TCN extracts long-term temporal relationships and quickly mines deep spatial features to capture short-term time series relationships using LSTM. Additionally, the method incorporates the CBAM attention mechanism to assign weights to features across various dimensions, emphasizing the significance of important features.This approach not only achieves a more comprehensive feature distribution but also enhances the representation of crucial features, consequently leading to improved accuracy in predicting RUL. Finally, to validate the effectiveness of the proposed approach, we conducted experiments on the PHM2012 and XJTU-SY rolling bearing datasets, comparing its performance against several other prevalent deep learning prediction methods. The results demonstrate the robustness and generalization capability of the proposed method.


---
# A combined soft X-ray and theoretical investigation discloses the water harvesting behaviour of Mg MOF-74 at the crystal surface

## 软x射线和理论研究相结合，揭示了Mg MOF-74在晶体表面的集水行为

Link: https://www.researchsquare.com/article/rs-5433792/latest

Metal-organic frameworks (MOFs) are receiving growing interest as permanently porous, highly tunable materials for real-world atmospheric water harvesting applications. Although it is becoming clear that surface effects are key to initiating and regulating MOF water uptake, obtaining molecular-level details on this issue has proven to be elusive. Here, we present a novel methodology based on ambient pressure soft X-ray absorption spectroscopy, machine learning-assisted theoretical spectroscopy and molecular dynamics (MD) simulations to gain quantitative and selective insights into the structural and dynamical behaviour of water confined at a MOF crystal surface. We applied our combined experimental and theoretical method to investigate the properties of wa- ter at the surface of Mg-MOF-74, while obtaining complementary information on the water uptake and release from the bulk by synchrotron powder X-ray diffraction. MD simulations and state-of-the-art theoretical simulations of the spectroscopic data were then employed to describe the water/MOF interface with molecular detail, evidencing that water molecules directly bound to the framework Mg sites first give rise to one-dimensional water chains by establishing a dense hydrogen-bond network with an additional water molecule per metal site, and subsequently nucleate porous channel filling, with the water layers found in the center of the MOF channels exhibiting higher mobility and reduced reorientational ability. The developed method can inform the rational optimization of MOF interfaces for water harvesting.


---
# Empirical Techniques For Effort Estimation in Designing Effective ML Models

## 在设计有效的ML模型时用于工作量估计的经验技术

Link: https://www.researchsquare.com/article/rs-5425832/latest

Machine Learning Research often involves the use of diverse libraries, modules, and pseudocodes for data processing, cleaning, filtering, pattern recognition, and computer intelligence. Quantization of Effort Required for the above cumulative processes is rarely discussed in the existing works &amp; The time to reach the desired level of the model&rsquo;s functionality is essential to gauge the environment training for the model training &amp; pre-deployment testing. In this study, we empirically defined the manual-cum-computational effort required for the model development in terms of 2-time factors: time-to-live(time until 1st code modification) and time-for-modification(time between 2 codebase changes) taken together in a mathematical model to compute Effort Factor(quantitative measure of determining effort needed to design ML algorithms). The study is novel in terms of how the effort required to create ML models is calculated with a particular focus on the manual effort direction. The results and the findings obtained can be used for determining the total time needed to synthesize ML models &amp; frameworks in terms of code change cycles and implementation strategies marking a 25% performance increase in the current method above the Standard Pipeline.


---
# Improving Explainability in Machine Learning: A Cluster-Driven Approach to Feature Importance

## 提高机器学习的可解释性: 一种聚类驱动的特征重要性方法

Link: https://www.researchsquare.com/article/rs-5454576/latest

Machine learning (ML) models are increasingly being deployed in critical domains such as healthcare, finance, marketing, autonomous vehicles, and energy. As these models become more accurate and capable, concerns about the trustworthiness of their decisions grow. Trust in ML models is essential, particularly in high-stakes applications, and depends on both the transparency and fairness of the models. Transparency is achieved when an ML model can clearly explain its decision-making process, especially by identifying the key features that influence its predictions. In this paper, we introduce a novel technique, cluster-based feature importance, which identifies feature importance by analyzing localized regions within the dataset. This approach provides deeper insights into the features the model relies on for its predictions. We also compare our method to established explainability techniques, such as LIME and SHAP, to assess its effectiveness.


---
# Learning Operators with NEAT for Boolean Composition in Reinforcement Learning

## 强化学习中布尔组合的NEAT学习运算符

Link: https://www.researchsquare.com/article/rs-5455533/latest

Skill composition is a growing area of interest within reinforcement learningresearch. This approach promotes efficient use of knowledge and represents arealistic, human-like style of learning. Existing work has demonstrated how simple skills can be composed using Boolean operators to solve new, unseen taskswithout further learning. However, this approach assumes that the learned value functions for each atomic skill are optimal, an assumption which is violated in most practical cases. We propose a method that instead learns operators forcomposition using evolutionary strategies. We empirically verify our approach in tabular and high-dimensional environments. Results demonstrate that our approach outperforms existing composition methods when faced with learned,suboptimal behaviours, while also promoting robust agents and allowing for transfer between domains.&nbsp;

